{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vQc4FFKXeWYt"
   },
   "source": [
    "\n",
    "# Twitter Toxicity Detection Project\n",
    "\n",
    "> This notebook documents the end-to-end Twitter toxicity detection project, starting with deterministic data preparation and culminating in deployable artifacts. It begins by cleaning and splitting the Twitter tweet corpus, persisting split IDs so every experiment baseline or advanced evaluates on identical examples. Classic baselines (TF-IDF + Logistic Regression) anchor performance expectations before the workflow escalates to transformer fine-tuning with BERT-base-uncased.\n",
    ">\n",
    "> The transformer track covers tokenization, automated hyperparameter tuning (grid and random search), and early stopping, ultimately selecting the best checkpoint via validation macro-F1. Detailed evaluation follows: confusion matrices, per-class reports, ROC-AUC and PR-AUC curves, and exportable tables compare validation/test splits, while metric logs capture training dynamics.\n",
    ">\n",
    "> The project implements a dual-model approach: a baseline TF-IDF + Logistic Regression model for interpretability and computational efficiency, and a fine-tuned BERT-base-uncased model for superior accuracy and context-aware understanding of informal language, sarcasm, and subtle toxicity patterns in Twitter posts.\n",
    ">\n",
    "> Final cells translate the strongest transformer into deployment formats, exporting quantized PyTorch weights, consolidated logs, and spreadsheet summaries. Together with saved checkpoints, tokenizer files, and experiment logs, these outputs guarantee that classmates and graders can reproduce, audit, and extend every stage of the workflow without rerunning training from scratch.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H9zdyBWkeWYt"
   },
   "source": [
    "# **Setup, imports, dataset load, and split**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xpz7RvUTeWYt"
   },
   "source": [
    "**`Purpose`**\n",
    "\n",
    "This block prepares the environment, ensures required libraries are available, and loads the Twitter Comment Dataset into memory in a clean, consistent format. It also establishes a reproducible 70/15/15 train-validation-test split so that all later experiments evaluate on the same examples. The goal is to make each downstream step predictable and to keep results comparable across runs and team members.\n",
    "\n",
    "**`Input`**\n",
    "\n",
    "The cell expects either a local copy of TwitterToxicity.csv in the current working directory or, if absent, a file that will be provided through the upload dialog. The CSV must contain at least two columns named review and label, which represent the input text and its sentiment class. Labels should be in the format: -1 (negative/toxic), 0 (neutral), 1 (positive). No other inputs are required at this stage, and any additional columns are ignored.\n",
    "\n",
    "**`Output`**\n",
    "\n",
    "The cell produces three pandas DataFrames, train_df, val_df, and test_df, with stratified class proportions and a new id column to uniquely identify each row. It also writes three small files, train_ids.csv, val_ids.csv, and test_ids.csv, which store the chosen row IDs for reuse. The printed device line indicates whether a GPU is available. Three proportion tables are printed as a quick check that label ratios are closely matched across splits.\n",
    "\n",
    "**`Details`**\n",
    "\n",
    "The cell installs the core NLP stack, imports common utilities, and detects the runtime device. It then loads the CSV, normalizes column names to lowercase, removes empty rows, and casts labels to integers. A simple id index is added so that split membership can be saved and reused. A stratified split holds label balance constant, which is printed to confirm the split is fair. Finally, the selected IDs are saved to disk so that all later training and evaluation use the same records, which supports consistent comparison across hyperparameter sweeps and models.\n",
    "\n",
    "**`Line-by-line Description.`**\n",
    "\n",
    "`!pip -q install transformers datasets accelerate scikit-learn openpyxl optuna -U` installs or upgrades the libraries needed for tokenization, training, metrics, hyperparameter tuning, and spreadsheet export.\n",
    "\n",
    "`import os, numpy as np, pandas as pd, torch` pulls in filesystem helpers, numerical tools, data frames, and the deep learning backend.\n",
    "\n",
    "`from sklearn.model_selection import train_test_split` and `from sklearn.metrics import accuracy_score, f1_score` load utilities for splitting and scoring.\n",
    "`try: from google.colab import files ...` sets up an optional upload path that only activates when running in Colab.\n",
    "\n",
    "`device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')` detects whether a GPU is present and prints the choice so training expectations are clear.\n",
    "\n",
    "`if not os.path.exists('TwitterToxicity.csv') and files is not None: files.upload()` requests an upload when the CSV is missing, which keeps the workflow flexible.\n",
    "\n",
    "`df = pd.read_csv('TwitterToxicity.csv')` loads the data, and `df.columns = [c.lower() for c in df.columns]` enforces lowercase names so downstream code can assume consistent headers.\n",
    "\n",
    "`df = df.dropna(subset=['review','label']).copy()` removes incomplete rows to avoid errors and noisy training examples.\n",
    "`df['label'] = df['label'].astype(int)` fixes the label type so models receive proper integers.\n",
    "\n",
    "`df['id'] = np.arange(len(df))` assigns a stable identifier to each row so the split can be persisted.\n",
    "\n",
    "The branch that checks for `train_ids.csv`, `val_ids.csv`, and `test_ids.csv` either reuses an existing split or creates a new stratified split with 70/15/15 ratio using `train_test_split(... stratify=df['label'])`.\n",
    "\n",
    "`train_df[['id']].to_csv('train_ids.csv', index=False)` and the matching lines for validation and test serialize the split for later reuse.\n",
    "\n",
    "The final `print(...)` lines show dataset sizes and class ratios so the split can be visually inspected.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 368
    },
    "id": "UVdmDjx4eWYt",
    "outputId": "a5ee3f08-1d82-402e-ca48-a25051003855"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ torch already installed\n",
      "✓ transformers already installed\n",
      "✓ datasets already installed\n",
      "✓ accelerate already installed\n",
      "Installing optuna...\n",
      "✓ optuna installed successfully\n",
      "✓ scikit-learn already installed\n",
      "✓ pandas already installed\n",
      "✓ numpy already installed\n",
      "✓ matplotlib already installed\n",
      "✓ openpyxl already installed\n",
      "Using device: cuda\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "     <input type=\"file\" id=\"files-2ed513eb-2c5d-4f49-a3f2-8b7287727bcc\" name=\"files[]\" multiple disabled\n",
       "        style=\"border:none\" />\n",
       "     <output id=\"result-2ed513eb-2c5d-4f49-a3f2-8b7287727bcc\">\n",
       "      Upload widget is only available when the cell has been executed in the\n",
       "      current browser session. Please rerun this cell to enable.\n",
       "      </output>\n",
       "      <script>// Copyright 2017 Google LLC\n",
       "//\n",
       "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
       "// you may not use this file except in compliance with the License.\n",
       "// You may obtain a copy of the License at\n",
       "//\n",
       "//      http://www.apache.org/licenses/LICENSE-2.0\n",
       "//\n",
       "// Unless required by applicable law or agreed to in writing, software\n",
       "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
       "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
       "// See the License for the specific language governing permissions and\n",
       "// limitations under the License.\n",
       "\n",
       "/**\n",
       " * @fileoverview Helpers for google.colab Python module.\n",
       " */\n",
       "(function(scope) {\n",
       "function span(text, styleAttributes = {}) {\n",
       "  const element = document.createElement('span');\n",
       "  element.textContent = text;\n",
       "  for (const key of Object.keys(styleAttributes)) {\n",
       "    element.style[key] = styleAttributes[key];\n",
       "  }\n",
       "  return element;\n",
       "}\n",
       "\n",
       "// Max number of bytes which will be uploaded at a time.\n",
       "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
       "\n",
       "function _uploadFiles(inputId, outputId) {\n",
       "  const steps = uploadFilesStep(inputId, outputId);\n",
       "  const outputElement = document.getElementById(outputId);\n",
       "  // Cache steps on the outputElement to make it available for the next call\n",
       "  // to uploadFilesContinue from Python.\n",
       "  outputElement.steps = steps;\n",
       "\n",
       "  return _uploadFilesContinue(outputId);\n",
       "}\n",
       "\n",
       "// This is roughly an async generator (not supported in the browser yet),\n",
       "// where there are multiple asynchronous steps and the Python side is going\n",
       "// to poll for completion of each step.\n",
       "// This uses a Promise to block the python side on completion of each step,\n",
       "// then passes the result of the previous step as the input to the next step.\n",
       "function _uploadFilesContinue(outputId) {\n",
       "  const outputElement = document.getElementById(outputId);\n",
       "  const steps = outputElement.steps;\n",
       "\n",
       "  const next = steps.next(outputElement.lastPromiseValue);\n",
       "  return Promise.resolve(next.value.promise).then((value) => {\n",
       "    // Cache the last promise value to make it available to the next\n",
       "    // step of the generator.\n",
       "    outputElement.lastPromiseValue = value;\n",
       "    return next.value.response;\n",
       "  });\n",
       "}\n",
       "\n",
       "/**\n",
       " * Generator function which is called between each async step of the upload\n",
       " * process.\n",
       " * @param {string} inputId Element ID of the input file picker element.\n",
       " * @param {string} outputId Element ID of the output display.\n",
       " * @return {!Iterable<!Object>} Iterable of next steps.\n",
       " */\n",
       "function* uploadFilesStep(inputId, outputId) {\n",
       "  const inputElement = document.getElementById(inputId);\n",
       "  inputElement.disabled = false;\n",
       "\n",
       "  const outputElement = document.getElementById(outputId);\n",
       "  outputElement.innerHTML = '';\n",
       "\n",
       "  const pickedPromise = new Promise((resolve) => {\n",
       "    inputElement.addEventListener('change', (e) => {\n",
       "      resolve(e.target.files);\n",
       "    });\n",
       "  });\n",
       "\n",
       "  const cancel = document.createElement('button');\n",
       "  inputElement.parentElement.appendChild(cancel);\n",
       "  cancel.textContent = 'Cancel upload';\n",
       "  const cancelPromise = new Promise((resolve) => {\n",
       "    cancel.onclick = () => {\n",
       "      resolve(null);\n",
       "    };\n",
       "  });\n",
       "\n",
       "  // Wait for the user to pick the files.\n",
       "  const files = yield {\n",
       "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
       "    response: {\n",
       "      action: 'starting',\n",
       "    }\n",
       "  };\n",
       "\n",
       "  cancel.remove();\n",
       "\n",
       "  // Disable the input element since further picks are not allowed.\n",
       "  inputElement.disabled = true;\n",
       "\n",
       "  if (!files) {\n",
       "    return {\n",
       "      response: {\n",
       "        action: 'complete',\n",
       "      }\n",
       "    };\n",
       "  }\n",
       "\n",
       "  for (const file of files) {\n",
       "    const li = document.createElement('li');\n",
       "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
       "    li.append(span(\n",
       "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
       "        `last modified: ${\n",
       "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
       "                                    'n/a'} - `));\n",
       "    const percent = span('0% done');\n",
       "    li.appendChild(percent);\n",
       "\n",
       "    outputElement.appendChild(li);\n",
       "\n",
       "    const fileDataPromise = new Promise((resolve) => {\n",
       "      const reader = new FileReader();\n",
       "      reader.onload = (e) => {\n",
       "        resolve(e.target.result);\n",
       "      };\n",
       "      reader.readAsArrayBuffer(file);\n",
       "    });\n",
       "    // Wait for the data to be ready.\n",
       "    let fileData = yield {\n",
       "      promise: fileDataPromise,\n",
       "      response: {\n",
       "        action: 'continue',\n",
       "      }\n",
       "    };\n",
       "\n",
       "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
       "    let position = 0;\n",
       "    do {\n",
       "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
       "      const chunk = new Uint8Array(fileData, position, length);\n",
       "      position += length;\n",
       "\n",
       "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
       "      yield {\n",
       "        response: {\n",
       "          action: 'append',\n",
       "          file: file.name,\n",
       "          data: base64,\n",
       "        },\n",
       "      };\n",
       "\n",
       "      let percentDone = fileData.byteLength === 0 ?\n",
       "          100 :\n",
       "          Math.round((position / fileData.byteLength) * 100);\n",
       "      percent.textContent = `${percentDone}% done`;\n",
       "\n",
       "    } while (position < fileData.byteLength);\n",
       "  }\n",
       "\n",
       "  // All done.\n",
       "  yield {\n",
       "    response: {\n",
       "      action: 'complete',\n",
       "    }\n",
       "  };\n",
       "}\n",
       "\n",
       "scope.google = scope.google || {};\n",
       "scope.google.colab = scope.google.colab || {};\n",
       "scope.google.colab._files = {\n",
       "  _uploadFiles,\n",
       "  _uploadFilesContinue,\n",
       "};\n",
       "})(self);\n",
       "</script> "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving TwitterToxicity.csv to TwitterToxicity.csv\n",
      "Dataset sizes: train=21114, val=4525, test=4525\n",
      "\n",
      "Label ratios (train): {-1: 0.2867765463673392, 0: 0.40025575447570333, 1: 0.3129676991569575}\n",
      "Label ratios (val):   {-1: 0.28685082872928175, 0: 0.40022099447513815, 1: 0.3129281767955801}\n",
      "Label ratios (test):  {-1: 0.28685082872928175, 0: 0.40022099447513815, 1: 0.3129281767955801}\n"
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "import sys\n",
    "\n",
    "packages_map = [\n",
    "    (\"torch\", \"torch\"),\n",
    "    (\"transformers\", \"transformers\"),\n",
    "    (\"datasets\", \"datasets\"),\n",
    "    (\"accelerate\", \"accelerate\"),\n",
    "    (\"optuna\", \"optuna\"),\n",
    "    (\"scikit-learn\", \"sklearn\"),\n",
    "    (\"pandas\", \"pandas\"),\n",
    "    (\"numpy\", \"numpy\"),\n",
    "    (\"matplotlib\", \"matplotlib\"),\n",
    "    (\"openpyxl\", \"openpyxl\"),\n",
    "]\n",
    "\n",
    "for pip_name, import_name in packages_map:\n",
    "    try:\n",
    "        __import__(import_name)\n",
    "        print(f\"✓ {pip_name} already installed\")\n",
    "    except ImportError:\n",
    "        print(f\"Installing {pip_name}...\")\n",
    "        try:\n",
    "            subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"-q\", pip_name],\n",
    "                                stdout=subprocess.DEVNULL, stderr=subprocess.PIPE)\n",
    "            print(f\"✓ {pip_name} installed successfully\")\n",
    "        except subprocess.CalledProcessError as e:\n",
    "            print(f\"⚠ Warning: Could not install {pip_name}. You may need to install it manually.\")\n",
    "\n",
    "import os, numpy as np, pandas as pd, torch, json, inspect, optuna\n",
    "from pathlib import Path\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "import optuna\n",
    "\n",
    "try:\n",
    "    from google.colab import files\n",
    "    IN_COLAB = True\n",
    "except ImportError:\n",
    "    IN_COLAB = False\n",
    "    files = None\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "if not os.path.exists(\"TwitterToxicity.csv\"):\n",
    "    if IN_COLAB and files is not None:\n",
    "        uploaded = files.upload()\n",
    "    else:\n",
    "        raise FileNotFoundError(\"TwitterToxicity.csv not found. Please run export_dataset.py first or ensure the file is in the current directory.\")\n",
    "df = pd.read_csv(\"TwitterToxicity.csv\")\n",
    "\n",
    "df = df.rename(columns={c:c.lower() for c in df.columns})\n",
    "assert {'review','label'} <= set(df.columns), \"CSV must have 'review' and 'label' columns.\"\n",
    "\n",
    "df = df.dropna(subset=['review','label']).copy()\n",
    "df['label'] = df['label'].astype(int)\n",
    "df['id'] = np.arange(len(df))\n",
    "\n",
    "# 70/15/15 split (per proposal Section V.B: training 70%, validation 15%, testing 15%)\n",
    "RANDOM_SEED = 42\n",
    "if not {'train_ids.csv','val_ids.csv','test_ids.csv'} <= set(os.listdir('.')):\n",
    "    df_train, df_temp = train_test_split(\n",
    "        df, test_size=0.3, random_state=RANDOM_SEED, stratify=df['label']\n",
    "    )\n",
    "    df_val, df_test = train_test_split(\n",
    "        df_temp, test_size=0.5, random_state=RANDOM_SEED, stratify=df_temp['label']\n",
    "    )\n",
    "    df_train[['id']].to_csv('train_ids.csv', index=False)\n",
    "    df_val[['id']].to_csv('val_ids.csv', index=False)\n",
    "    df_test[['id']].to_csv('test_ids.csv', index=False)\n",
    "else:\n",
    "    ids_tr = set(pd.read_csv('train_ids.csv')['id'].tolist())\n",
    "    ids_va = set(pd.read_csv('val_ids.csv')['id'].tolist())\n",
    "    ids_te = set(pd.read_csv('test_ids.csv')['id'].tolist())\n",
    "    df_train = df[df['id'].isin(ids_tr)].copy()\n",
    "    df_val   = df[df['id'].isin(ids_va)].copy()\n",
    "    df_test  = df[df['id'].isin(ids_te)].copy()\n",
    "\n",
    "print(f\"Dataset sizes: train={len(df_train)}, val={len(df_val)}, test={len(df_test)}\")\n",
    "print(\"\\nLabel ratios (train):\", df_train['label'].value_counts(normalize=True).sort_index().to_dict())\n",
    "print(\"Label ratios (val):  \", df_val['label'].value_counts(normalize=True).sort_index().to_dict())\n",
    "print(\"Label ratios (test): \", df_test['label'].value_counts(normalize=True).sort_index().to_dict())\n",
    "\n",
    "# Export ground-truth test set BEFORE any downsampling\n",
    "# This ensures the exported file always contains the full test set (required deliverable)\n",
    "# The ground_truth_test_set.csv should match the test_ids.csv exactly\n",
    "# This file is required as Deliverable 2: Ground-Truth Test Set (Final Version)\n",
    "if 'test_ids.csv' in os.listdir('.'):\n",
    "    # Load full test set from test_ids.csv to ensure consistency\n",
    "    test_ids = pd.read_csv('test_ids.csv')['id'].tolist()\n",
    "    df_test_full = df[df['id'].isin(test_ids)].copy()\n",
    "    ground_truth_test_set = df_test_full[['review', 'label']].copy()\n",
    "    ground_truth_test_set.to_csv('ground_truth_test_set.csv', index=False)\n",
    "    print(f\"✓ Exported ground-truth test set: ground_truth_test_set.csv ({len(ground_truth_test_set)} samples)\")\n",
    "    print(f\"  Label distribution: {ground_truth_test_set['label'].value_counts().sort_index().to_dict()}\")\n",
    "    # Verify the export\n",
    "    if os.path.exists('ground_truth_test_set.csv'):\n",
    "        verify_df = pd.read_csv('ground_truth_test_set.csv')\n",
    "        assert len(verify_df) == len(ground_truth_test_set), \"Export verification failed\"\n",
    "        assert list(verify_df.columns) == ['review', 'label'], \"Export columns incorrect\"\n",
    "        print(f\"  ✓ Verification passed: File contains {len(verify_df)} samples with 'review' and 'label' columns\")\n",
    "else:\n",
    "    # If test_ids.csv doesn't exist yet, export from current df_test\n",
    "    ground_truth_test_set = df_test[['review', 'label']].copy()\n",
    "    ground_truth_test_set.to_csv('ground_truth_test_set.csv', index=False)\n",
    "    print(f\"✓ Exported ground-truth test set: ground_truth_test_set.csv ({len(ground_truth_test_set)} samples)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v__4Mz7peWYu"
   },
   "source": [
    "# Data cleaning and preprocessing\n",
    "\n",
    "This cell applies comprehensive preprocessing suitable for Twitter text and prepares reproducible 70/15/15 stratified splits. We:\n",
    "- Remove non-textual elements (numbers, punctuation, URLs)\n",
    "- Remove user identifiers, hashtags, mentions (privacy protection)\n",
    "- Eliminate stopwords and unnecessary whitespace\n",
    "- Convert all text to lowercase\n",
    "- Apply lemmatization and stemming (normalize to root forms)\n",
    "- Handle imbalanced data (oversampling/undersampling/SMOTE if needed)\n",
    "- Drop empty rows and exact duplicates\n",
    "- Persist `train_ids.csv`, `val_ids.csv`, `test_ids.csv` to reuse the same split across runs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hrkwFicseWYu"
   },
   "source": [
    "**`Purpose`**\n",
    "\n",
    "This block implements comprehensive data preprocessing per proposal Section V.B to prepare the Twitter dataset for machine learning and deep learning tasks. The preprocessing phase includes data cleaning, text normalization, tokenization preparation, and handling of imbalanced data to improve model performance.\n",
    "\n",
    "**`Input`**\n",
    "\n",
    "The inputs are the raw DataFrames (df_train, df_val, df_test) created earlier. Only the review and label columns are used. The preprocessing functions apply Twitter-specific cleaning to remove noise while preserving meaningful textual content.\n",
    "\n",
    "**`Output`**\n",
    "\n",
    "The block produces cleaned DataFrames with normalized text, balanced class distribution (if needed), and prints statistics about the preprocessing steps. It also ensures the 70/15/15 split is maintained with saved IDs.\n",
    "\n",
    "**`Details`**\n",
    "\n",
    "The preprocessing follows the proposal methodology exactly:\n",
    "- **Data Cleaning**: Removes non-textual elements, user identifiers, hashtags, mentions, URLs, stopwords\n",
    "- **Text Normalization**: Lowercase conversion, lemmatization, stemming\n",
    "- **Imbalanced Data Handling**: Checks class distribution and applies SMOTE/oversampling if needed\n",
    "- **Quality Control**: Removes duplicates, empty rows, and validates data integrity\n",
    "\n",
    "**`Line-by-line Description.`**\n",
    "\n",
    "`import re, html` imports regular expressions for pattern matching and HTML entity unescaping.\n",
    "\n",
    "`from nltk.corpus import stopwords` and `from nltk.stem import PorterStemmer, WordNetLemmatizer` loads NLTK utilities for stopword removal, stemming, and lemmatization.\n",
    "\n",
    "`nltk.download('stopwords', quiet=True)` downloads required NLTK data files if not already present.\n",
    "\n",
    "`stemmer = PorterStemmer()` and `lemmatizer = WordNetLemmatizer()` initializes stemmer and lemmatizer objects for text normalization.\n",
    "\n",
    "`stop_words = set(stopwords.words('english'))` loads English stopwords into a set for efficient lookup.\n",
    "\n",
    "`CTRL_RE = re.compile(r\"[\\x00-\\x08\\x0B\\x0C\\x0E-\\x1F]\")` and `REPEAT_RE = re.compile(r\"(\\w)\\1{2,}\")` compile regex patterns for removing control characters and elongated word repeats.\n",
    "\n",
    "`def strip_html(text: str) -> str:` defines a function to remove HTML tags and unescape HTML entities from text.\n",
    "\n",
    "`def remove_urls_mentions_hashtags(text: str) -> str:` defines a function to remove URLs, user mentions, and hashtags (per proposal: privacy protection), keeping hashtag words.\n",
    "\n",
    "`def normalize_text(text: str) -> str:` defines a function to lowercase text, tokenize, remove stopwords, and apply lemmatization and stemming.\n",
    "\n",
    "`def basic_clean(text: str) -> str:` defines the main cleaning function that combines HTML stripping, URL/mention/hashtag removal, control character removal, whitespace normalization, and elongated repeat capping.\n",
    "\n",
    "`print(\"Cleaning dataset...\")` provides user feedback about the cleaning process starting.\n",
    "\n",
    "`df = df.copy()` creates a copy of the dataframe to avoid modifying the original.\n",
    "\n",
    "`df['review'] = df['review'].astype(str).map(basic_clean)` applies the basic cleaning function to all review text, converting to string type first.\n",
    "\n",
    "`df = df[(df['review'].str.len() > 0)].drop_duplicates(subset=['review','label']).reset_index(drop=True)` removes empty rows and exact duplicates based on review text and label.\n",
    "\n",
    "`print(\"Normalizing text (lemmatization and stemming)...\")` provides user feedback about normalization starting.\n",
    "\n",
    "`df['review'] = df['review'].map(normalize_text)` applies text normalization (lowercase, lemmatization, stemming) to all reviews.\n",
    "\n",
    "`label_counts = df['label'].value_counts().sort_index()` counts occurrences of each label and sorts by label value.\n",
    "\n",
    "`print(f\"  {label} ({label_name}): {count} ({count/len(df)*100:.2f}%)\")` displays class distribution statistics with percentages.\n",
    "\n",
    "`min_class_ratio = label_counts.min() / len(df)` calculates the minimum class ratio to check for imbalance.\n",
    "\n",
    "`if min_class_ratio < 0.25:` checks if data is imbalanced (any class has less than 25% of data).\n",
    "\n",
    "`vectorizer = TfidfVectorizer(max_features=1000)` creates a TF-IDF vectorizer for SMOTE (if needed), limiting features to 1000.\n",
    "\n",
    "`smote = SMOTE(random_state=RANDOM_SEED)` initializes SMOTE oversampler with random seed for reproducibility.\n",
    "\n",
    "`if not {'train_ids.csv','val_ids.csv','test_ids.csv'} <= set(os.listdir('.')):` checks if split ID files exist to determine whether to create new splits or reuse existing ones.\n",
    "\n",
    "`df_train, df_temp = train_test_split(df, test_size=0.3, random_state=RANDOM_SEED, stratify=df['label'])` creates initial 70/30 train-temp split with stratified sampling.\n",
    "\n",
    "`df_val, df_test = train_test_split(df_temp, test_size=0.5, random_state=RANDOM_SEED, stratify=df_temp['label'])` splits temp data into 50/50 validation and test sets (15% each of total).\n",
    "\n",
    "`df_train[['id']].to_csv('train_ids.csv', index=False)` saves training split IDs to disk for reproducibility.\n",
    "\n",
    "`print(f\"\\nFinal split sizes: train={len(df_train)}, val={len(df_val)}, test={len(df_test)}\")` displays final split sizes after preprocessing.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "G9mZl-JueWYu",
    "outputId": "6786209d-45ca-4e2f-be2c-47f07122440f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaning dataset...\n",
      "Cleaned dataset: kept 30140/30164 rows\n",
      "Normalizing text (lemmatization and stemming)...\n",
      "After normalization: 29756 rows\n",
      "\n",
      "Class distribution:\n",
      "  -1 (negative/toxic): 8573 (28.81%)\n",
      "  0 (neutral): 11826 (39.74%)\n",
      "  1 (positive): 9357 (31.45%)\n",
      "\n",
      "✓ Data is reasonably balanced. No resampling needed.\n",
      "\n",
      "Final split sizes: train=20824, val=4456, test=4476\n",
      "Label ratios (train): {-1: 0.2877929312331925, 0: 0.39766615443718784, 1: 0.31454091432961967}\n",
      "Label ratios (val):   {-1: 0.289048473967684, 0: 0.39587073608617596, 1: 0.31508078994614}\n",
      "Label ratios (test):  {-1: 0.28865058087578194, 0: 0.3978999106344951, 1: 0.31344950848972297}\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import html\n",
    "from collections import Counter\n",
    "from sklearn.model_selection import train_test_split\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "import nltk\n",
    "\n",
    "try:\n",
    "    nltk.download('stopwords', quiet=True)\n",
    "    nltk.download('punkt', quiet=True)\n",
    "    nltk.download('wordnet', quiet=True)\n",
    "except:\n",
    "    pass\n",
    "\n",
    "# Initialize stemmer and lemmatizer\n",
    "stemmer = PorterStemmer()\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "# Get stopwords\n",
    "try:\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "except:\n",
    "    stop_words = set()\n",
    "\n",
    "CTRL_RE = re.compile(r\"[\\x00-\\x08\\x0B\\x0C\\x0E-\\x1F]\")\n",
    "REPEAT_RE = re.compile(r\"(\\w)\\1{2,}\")\n",
    "\n",
    "def strip_html(text: str) -> str:\n",
    "    \"\"\"Remove HTML tags and entities\"\"\"\n",
    "    if not isinstance(text, str):\n",
    "        return \"\"\n",
    "    t = html.unescape(text)\n",
    "    t = re.sub(r\"<[^>]+>\", \" \", t)\n",
    "    return t\n",
    "\n",
    "def remove_urls_mentions_hashtags(text: str) -> str:\n",
    "    \"\"\"Remove URLs, mentions, and hashtags (per proposal: privacy protection)\"\"\"\n",
    "    # Remove URLs\n",
    "    text = re.sub(r'http\\S+|www\\.\\S+', '', text)\n",
    "    # Remove mentions\n",
    "    text = re.sub(r'@\\w+', '', text)\n",
    "    # Remove hashtags (but keep the word)\n",
    "    text = re.sub(r'#(\\w+)', r'\\1', text)\n",
    "    return text\n",
    "\n",
    "def normalize_text(text: str) -> str:\n",
    "    \"\"\"Normalize text: lowercase, lemmatization, stemming (per proposal)\"\"\"\n",
    "    if not isinstance(text, str):\n",
    "        return \"\"\n",
    "    text = text.lower()\n",
    "    try:\n",
    "        tokens = word_tokenize(text)\n",
    "    except:\n",
    "        tokens = text.split()\n",
    "    tokens = [lemmatizer.lemmatize(stemmer.stem(word)) for word in tokens\n",
    "              if word.isalpha() and word not in stop_words]\n",
    "    return ' '.join(tokens)\n",
    "\n",
    "def basic_clean(text: str) -> str:\n",
    "    \"\"\"Main cleaning function\"\"\"\n",
    "    if not isinstance(text, str):\n",
    "        return \"\"\n",
    "    t = str(text)\n",
    "    t = strip_html(t)\n",
    "    t = remove_urls_mentions_hashtags(t)\n",
    "    t = CTRL_RE.sub(\" \", t)\n",
    "    t = re.sub(r\"\\s+\", \" \", t).strip()\n",
    "    t = REPEAT_RE.sub(r\"\\1\\1\", t)  # Cap elongated repeats\n",
    "    return t\n",
    "\n",
    "print(\"Cleaning dataset...\")\n",
    "df = df.copy()\n",
    "df['review'] = df['review'].astype(str).map(basic_clean)\n",
    "before = len(df)\n",
    "df = df[(df['review'].str.len() > 0)].drop_duplicates(subset=['review','label']).reset_index(drop=True)\n",
    "after = len(df)\n",
    "print(f\"Cleaned dataset: kept {after}/{before} rows\")\n",
    "\n",
    "print(\"Normalizing text (lemmatization and stemming)...\")\n",
    "df['review'] = df['review'].map(normalize_text)\n",
    "\n",
    "df = df[(df['review'].str.len() > 0)].reset_index(drop=True)\n",
    "print(f\"After normalization: {len(df)} rows\")\n",
    "\n",
    "print(\"\\nClass distribution:\")\n",
    "label_counts = df['label'].value_counts().sort_index()\n",
    "for label, count in label_counts.items():\n",
    "    label_name = {-1: \"negative/toxic\", 0: \"neutral\", 1: \"positive\"}[label]\n",
    "    print(f\"  {label} ({label_name}): {count} ({count/len(df)*100:.2f}%)\")\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "min_class_ratio = label_counts.min() / len(df)\n",
    "if min_class_ratio < 0.25:\n",
    "    print(f\"\\n⚠ Imbalanced data detected (min class ratio: {min_class_ratio:.2f})\")\n",
    "    print(\"Applying SMOTE for balancing...\")\n",
    "    try:\n",
    "        vectorizer = TfidfVectorizer(max_features=1000)\n",
    "        X = vectorizer.fit_transform(df['review'])\n",
    "        y = df['label'].values\n",
    "\n",
    "        smote = SMOTE(random_state=RANDOM_SEED)\n",
    "        X_resampled, y_resampled = smote.fit_resample(X, y)\n",
    "\n",
    "        print(\"Note: SMOTE creates synthetic samples. Consider manual review.\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"SMOTE failed: {e}. Proceeding with original data.\")\n",
    "else:\n",
    "    print(\"\\n✓ Data is reasonably balanced. No resampling needed.\")\n",
    "\n",
    "if not {'train_ids.csv','val_ids.csv','test_ids.csv'} <= set(os.listdir('.')):\n",
    "    df_train, df_temp = train_test_split(\n",
    "        df, test_size=0.3, random_state=RANDOM_SEED, stratify=df['label']\n",
    "    )\n",
    "    df_val, df_test = train_test_split(\n",
    "        df_temp, test_size=0.5, random_state=RANDOM_SEED, stratify=df_temp['label']\n",
    "    )\n",
    "    df_train[['id']].to_csv('train_ids.csv', index=False)\n",
    "    df_val[['id']].to_csv('val_ids.csv', index=False)\n",
    "    df_test[['id']].to_csv('test_ids.csv', index=False)\n",
    "else:\n",
    "    ids_tr = set(pd.read_csv('train_ids.csv')['id'].tolist())\n",
    "    ids_va = set(pd.read_csv('val_ids.csv')['id'].tolist())\n",
    "    ids_te = set(pd.read_csv('test_ids.csv')['id'].tolist())\n",
    "    df_train = df[df['id'].isin(ids_tr)].copy()\n",
    "    df_val   = df[df['id'].isin(ids_va)].copy()\n",
    "    df_test  = df[df['id'].isin(ids_te)].copy()\n",
    "\n",
    "print(f\"\\nFinal split sizes: train={len(df_train)}, val={len(df_val)}, test={len(df_test)}\")\n",
    "print('Label ratios (train):', df_train['label'].value_counts(normalize=True).sort_index().to_dict())\n",
    "print('Label ratios (val):  ', df_val['label'].value_counts(normalize=True).sort_index().to_dict())\n",
    "print('Label ratios (test): ', df_test['label'].value_counts(normalize=True).sort_index().to_dict())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mm0xDaYJeWYv"
   },
   "source": [
    "# Fast mode toggle\n",
    "\n",
    "Set `FAST_MODE` to `True` to downsample the training split (40%) for quicker CPU experiments.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "z-eJoKydeWYv",
    "outputId": "67c4c75a-60bd-40a8-c9f5-34e0835d4bf7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[FAST_MODE ENABLED] Using 40% of training data\n",
      "  Train: 8330 samples8330 (~40%), val=4456, test=4476\n"
     ]
    }
   ],
   "source": [
    "FAST_MODE = True  # Set to True for faster training (40% data), False for full dataset\n",
    "TRAIN_FRACTION = 0.40 if FAST_MODE else 1.0\n",
    "VAL_FRACTION = 1.0  # Keep full validation/test by default\n",
    "\n",
    "if FAST_MODE and TRAIN_FRACTION < 1.0:\n",
    "    df_train = (df_train\n",
    "                .sample(frac=TRAIN_FRACTION, random_state=RANDOM_SEED)\n",
    "                .sort_values('id')\n",
    "                .reset_index(drop=True))\n",
    "    if VAL_FRACTION < 1.0:\n",
    "        df_val = (df_val\n",
    "                  .sample(frac=VAL_FRACTION, random_state=RANDOM_SEED)\n",
    "                  .sort_values('id')\n",
    "                  .reset_index(drop=True))\n",
    "        df_test = (df_test\n",
    "                   .sample(frac=VAL_FRACTION, random_state=RANDOM_SEED)\n",
    "                   .sort_values('id')\n",
    "                   .reset_index(drop=True))\n",
    "    print(f\"[FAST_MODE ENABLED] Using {TRAIN_FRACTION*100:.0f}% of training data\\n  Train: {len(df_train)} samples{len(df_train)} (~{TRAIN_FRACTION*100:.0f}%), val={len(df_val)}, test={len(df_test)}\")\n",
    "else:\n",
    "    print(\"FAST_MODE disabled: using full train/val/test splits\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VfeP5HgAeWYv"
   },
   "source": [
    "# **Baseline TF-IDF + Logistic Regression (per proposal Section V.C)**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VZbXOHuVeWYv"
   },
   "source": [
    "**`Purpose`**\n",
    "\n",
    "This block builds a baseline model using TF-IDF vectorization and Logistic Regression as a reference point per proposal Section V.C. The baseline model acts as a foundation for measuring improvements from more complex deep learning methods. It uses traditional machine learning techniques that are simple, interpretable, and computationally efficient.\n",
    "\n",
    "**`Input`**\n",
    "\n",
    "The inputs are the train_df and val_df frames created earlier. Only the review and label columns are used. The TF-IDF vectorizer is configured with word 1-2 ngrams and a vocabulary limit to cap memory and training time. The labels are taken directly as integer classes (-1, 0, 1).\n",
    "\n",
    "**`Output`**\n",
    "\n",
    "The block prints a compact dictionary that contains baseline accuracy, precision, recall, and F1-score (per proposal Section VI.A). It also appends a structured row to runs_log.csv so that the baseline appears in the experiment ledger with model name, scores, and notes. These outputs provide both an on-screen summary and a durable record for later tables and charts.\n",
    "\n",
    "**`Details`**\n",
    "\n",
    "A TF-IDF vectorizer is fit on the training text and applied to the validation text, producing sparse matrices. A Logistic Regression model is trained with hyperparameter tuning via grid search and cross-validation (per proposal Section VI.B). Predictions for the validation set are compared against the gold labels to compute accuracy, precision, recall, and F1-score, where macro-F1 treats all classes equally. The metrics are printed and then written to the log file with consistent column names.\n",
    "\n",
    "**`Line-by-line Description.`**\n",
    "\n",
    "`from sklearn.feature_extraction.text import TfidfVectorizer` imports the TF-IDF vectorizer for converting text to numerical features.\n",
    "\n",
    "`from sklearn.linear_model import LogisticRegression` imports Logistic Regression classifier for baseline model.\n",
    "\n",
    "`from sklearn.model_selection import GridSearchCV, StratifiedKFold` imports grid search and stratified K-fold cross-validation utilities.\n",
    "\n",
    "`tfidf = TfidfVectorizer(max_features=100000, ngram_range=(1,3), ...)` creates a TF-IDF vectorizer with 1-3 ngrams, max 100k features, and sublinear term frequency scaling.\n",
    "\n",
    "`X_tr = df_train['review'].tolist()` and `y_tr = df_train['label'].values` extracts training text and labels into lists/arrays.\n",
    "\n",
    "`X_va = df_val['review'].tolist()` and `y_va = df_val['label'].values` extracts validation text and labels.\n",
    "\n",
    "`X_tr_tfidf = tfidf.fit_transform(X_tr)` fits the TF-IDF vectorizer on training text and transforms it to a sparse feature matrix.\n",
    "\n",
    "`X_va_tfidf = tfidf.transform(X_va)` transforms validation text using the fitted vectorizer.\n",
    "\n",
    "`param_grid = {'C': [0.1, 0.5, 1.0, 2.0, 4.0, 8.0], ...}` defines hyperparameter search space including regularization strength (C), class weights, max iterations, and penalty type.\n",
    "\n",
    "`logreg_base = LogisticRegression(solver='liblinear', random_state=RANDOM_SEED)` creates base Logistic Regression model with liblinear solver.\n",
    "\n",
    "`skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=RANDOM_SEED)` creates 5-fold stratified cross-validation splitter.\n",
    "\n",
    "`grid_search = GridSearchCV(logreg_base, param_grid=param_grid, cv=skf, scoring='f1_macro', ...)` creates grid search object configured to maximize macro-F1 score.\n",
    "\n",
    "`grid_search.fit(X_tr_tfidf, y_tr)` runs grid search with cross-validation to find best hyperparameters.\n",
    "\n",
    "`logreg = grid_search.best_estimator_` extracts the best model from grid search results.\n",
    "\n",
    "`preds = logreg.predict(X_va_tfidf)` generates predictions on validation set using best model.\n",
    "\n",
    "`acc_base = accuracy_score(y_va, preds)` calculates validation accuracy.\n",
    "\n",
    "`prec_base = precision_score(y_va, preds, average='macro', zero_division=0)` calculates macro-averaged precision.\n",
    "\n",
    "`rec_base = recall_score(y_va, preds, average='macro', zero_division=0)` calculates macro-averaged recall.\n",
    "\n",
    "`f1_base = f1_score(y_va, preds, average='macro', zero_division=0)` calculates macro-averaged F1-score.\n",
    "\n",
    "`print(classification_report(y_va, preds, ...))` generates and displays detailed per-class classification report.\n",
    "\n",
    "`row = {...}` creates a dictionary row with model metadata and performance metrics for logging.\n",
    "\n",
    "`pd.DataFrame([row]).to_csv(\"runs_log.csv\", mode=\"a\", ...)` appends the row to experiment log file.\n",
    "\n",
    "`joblib.dump(logreg, \"models/baseline_tfidf_logreg.joblib\")` saves the trained model to disk for later use.\n",
    "\n",
    "`joblib.dump(tfidf, \"models/baseline_tfidf_vectorizer.joblib\")` saves the fitted vectorizer to disk for consistent feature extraction.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-ZU6dColeWYv",
    "outputId": "1b9ec7eb-d980-4a31-b025-665adfc39f27"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting TF-IDF vectorizer...\n",
      "\n",
      "Performing hyperparameter tuning with GridSearchCV...\n",
      "Fitting 5 folds for each of 72 candidates, totalling 360 fits\n",
      "\n",
      "Best parameters: {'C': 2.0, 'class_weight': {-1: 1.2, 0: 0.8, 1: 1.2}, 'max_iter': 2000, 'penalty': 'l1'}\n",
      "Best CV score (F1-macro): 0.6390\n",
      "\n",
      "Baseline Model Performance (Validation Set):\n",
      "{'model': 'tfidf-logreg', 'accuracy': 0.6364452423698385, 'precision': 0.6419309572443174, 'recall': 0.6337474541408289, 'f1_macro': 0.6368850204779207}\n",
      "\n",
      "Classification Report:\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "negative/toxic       0.63      0.56      0.59      1288\n",
      "       neutral       0.59      0.64      0.62      1764\n",
      "      positive       0.71      0.69      0.70      1404\n",
      "\n",
      "      accuracy                           0.64      4456\n",
      "     macro avg       0.64      0.63      0.64      4456\n",
      "  weighted avg       0.64      0.64      0.64      4456\n",
      "\n",
      "\n",
      "✓ Baseline model saved to models/baseline_tfidf_logreg.joblib\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold\n",
    "from sklearn.metrics import classification_report, precision_score, recall_score\n",
    "\n",
    "\n",
    "tfidf = TfidfVectorizer(\n",
    "    max_features=100000,\n",
    "    ngram_range=(1,3),\n",
    "    lowercase=True,\n",
    "    min_df=2,\n",
    "    max_df=0.95,\n",
    "    sublinear_tf=True\n",
    ")\n",
    "\n",
    "X_tr = df_train['review'].tolist()\n",
    "y_tr = df_train['label'].values\n",
    "X_va = df_val['review'].tolist()\n",
    "y_va = df_val['label'].values\n",
    "\n",
    "print(\"Fitting TF-IDF vectorizer...\")\n",
    "X_tr_tfidf = tfidf.fit_transform(X_tr)\n",
    "X_va_tfidf = tfidf.transform(X_va)\n",
    "\n",
    "print(\"\\nPerforming hyperparameter tuning with GridSearchCV...\")\n",
    "param_grid = {\n",
    "    'C': [0.1, 0.5, 1.0, 2.0, 4.0, 8.0],\n",
    "    'class_weight': [None, 'balanced', {-1: 1.2, 0: 0.8, 1: 1.2}],\n",
    "    'max_iter': [2000, 3000],\n",
    "    'penalty': ['l1', 'l2']\n",
    "}\n",
    "\n",
    "logreg_base = LogisticRegression(solver='liblinear', random_state=RANDOM_SEED)\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=RANDOM_SEED)\n",
    "\n",
    "grid_search = GridSearchCV(\n",
    "    logreg_base,\n",
    "    param_grid=param_grid,\n",
    "    cv=skf,\n",
    "    scoring='f1_macro',\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "grid_search.fit(X_tr_tfidf, y_tr)\n",
    "print(f\"\\nBest parameters: {grid_search.best_params_}\")\n",
    "print(f\"Best CV score (F1-macro): {grid_search.best_score_:.4f}\")\n",
    "\n",
    "logreg = grid_search.best_estimator_\n",
    "preds = logreg.predict(X_va_tfidf)\n",
    "\n",
    "acc_base = accuracy_score(y_va, preds)\n",
    "prec_base = precision_score(y_va, preds, average='macro', zero_division=0)\n",
    "rec_base = recall_score(y_va, preds, average='macro', zero_division=0)\n",
    "f1_base = f1_score(y_va, preds, average='macro', zero_division=0)\n",
    "\n",
    "print(\"\\nBaseline Model Performance (Validation Set):\")\n",
    "print({\n",
    "    \"model\": \"tfidf-logreg\",\n",
    "    \"accuracy\": acc_base,\n",
    "    \"precision\": prec_base,\n",
    "    \"recall\": rec_base,\n",
    "    \"f1_macro\": f1_base\n",
    "})\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_va, preds,\n",
    "                          target_names=['negative/toxic', 'neutral', 'positive'],\n",
    "                          zero_division=0))\n",
    "\n",
    "row = {\n",
    "    \"member\": \"baseline\",\n",
    "    \"model\": \"tfidf-logreg\",\n",
    "    \"num_train_epochs\": None,\n",
    "    \"per_device_train_batch_size\": None,\n",
    "    \"learning_rate\": None,\n",
    "    \"weight_decay\": None,\n",
    "    \"warmup_steps\": None,\n",
    "    \"lr_scheduler_type\": None,\n",
    "    \"gradient_accumulation_steps\": None,\n",
    "    \"max_seq_length\": None,\n",
    "    \"seed\": RANDOM_SEED,\n",
    "    \"fp16\": False,\n",
    "    \"accuracy\": acc_base,\n",
    "    \"precision\": prec_base,\n",
    "    \"recall\": rec_base,\n",
    "    \"f1_macro\": f1_base,\n",
    "    \"notes\": f\"TF-IDF + LogReg baseline with GridSearchCV. Best params: {grid_search.best_params_}\"\n",
    "}\n",
    "\n",
    "pd.DataFrame([row]).to_csv(\"runs_log.csv\", mode=\"a\",\n",
    "                           index=False, header=not os.path.exists(\"runs_log.csv\"))\n",
    "\n",
    "os.makedirs(\"models\", exist_ok=True)\n",
    "import joblib\n",
    "joblib.dump(logreg, \"models/baseline_tfidf_logreg.joblib\")\n",
    "joblib.dump(tfidf, \"models/baseline_tfidf_vectorizer.joblib\")\n",
    "print(\"\\n✓ Baseline model saved to models/baseline_tfidf_logreg.joblib\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CJq3QwG-eWYw"
   },
   "source": [
    "# Baseline Evaluation on Test Set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KTm73amEeWYw",
    "outputId": "3481176d-0866-4b1c-9ca5-571261e24586"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using models from previous cell...\n",
      "Baseline Model Performance (Test Set):\n",
      "{'model': 'tfidf-logreg', 'accuracy': 0.6224307417336908, 'precision': 0.6293671945894598, 'recall': 0.6196908253354203, 'f1_macro': 0.6233782959331148}\n",
      "\n",
      "Test Set Classification Report:\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "negative/toxic       0.62      0.56      0.59      1292\n",
      "       neutral       0.58      0.63      0.60      1781\n",
      "      positive       0.69      0.67      0.68      1403\n",
      "\n",
      "      accuracy                           0.62      4476\n",
      "     macro avg       0.63      0.62      0.62      4476\n",
      "  weighted avg       0.62      0.62      0.62      4476\n",
      "\n",
      "\n",
      "✓ Confusion matrix saved to exports/confusion_matrices/baseline_cm_test.png\n"
     ]
    }
   ],
   "source": [
    "\n",
    "try:\n",
    "    _ = tfidf\n",
    "    _ = logreg\n",
    "    print(\"Using models from previous cell...\")\n",
    "except NameError:\n",
    "\n",
    "    import joblib\n",
    "    import os\n",
    "    model_path = \"models/baseline_tfidf_logreg.joblib\"\n",
    "    vectorizer_path = \"models/baseline_tfidf_vectorizer.joblib\"\n",
    "\n",
    "    if os.path.exists(model_path) and os.path.exists(vectorizer_path):\n",
    "        print(\"Loading baseline models from disk...\")\n",
    "        tfidf = joblib.load(vectorizer_path)\n",
    "        logreg = joblib.load(model_path)\n",
    "        print(\"✓ Models loaded successfully\")\n",
    "    else:\n",
    "        raise NameError(\n",
    "            \"Baseline models not found. Please run Cell 12 (Baseline TF-IDF + Logistic Regression training) first to train and save the models.\"\n",
    "        )\n",
    "\n",
    "X_te = df_test['review'].tolist()\n",
    "y_te = df_test['label'].values\n",
    "X_te_tfidf = tfidf.transform(X_te)\n",
    "\n",
    "test_preds = logreg.predict(X_te_tfidf)\n",
    "\n",
    "test_acc = accuracy_score(y_te, test_preds)\n",
    "test_prec = precision_score(y_te, test_preds, average='macro', zero_division=0)\n",
    "test_rec = recall_score(y_te, test_preds, average='macro', zero_division=0)\n",
    "test_f1 = f1_score(y_te, test_preds, average='macro', zero_division=0)\n",
    "\n",
    "print(\"Baseline Model Performance (Test Set):\")\n",
    "print({\n",
    "    \"model\": \"tfidf-logreg\",\n",
    "    \"accuracy\": test_acc,\n",
    "    \"precision\": test_prec,\n",
    "    \"recall\": test_rec,\n",
    "    \"f1_macro\": test_f1\n",
    "})\n",
    "\n",
    "print(\"\\nTest Set Classification Report:\")\n",
    "print(classification_report(y_te, test_preds,\n",
    "                          target_names=['negative/toxic', 'neutral', 'positive'],\n",
    "                          zero_division=0))\n",
    "\n",
    "os.makedirs(\"exports\", exist_ok=True)\n",
    "pd.DataFrame({\n",
    "    'review': X_te,\n",
    "    'gold': y_te,\n",
    "    'pred': test_preds\n",
    "}).to_csv('exports/baseline_predictions_test.csv', index=False)\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "cm = confusion_matrix(y_te, test_preds, labels=[-1, 0, 1])\n",
    "fig, ax = plt.subplots(figsize=(6, 5))\n",
    "ConfusionMatrixDisplay(cm, display_labels=['negative/toxic', 'neutral', 'positive']).plot(ax=ax, colorbar=False)\n",
    "plt.title('Baseline Model - Test Set Confusion Matrix')\n",
    "plt.tight_layout()\n",
    "os.makedirs(\"exports/confusion_matrices\", exist_ok=True)\n",
    "plt.savefig('exports/confusion_matrices/baseline_cm_test.png', dpi=150)\n",
    "plt.show()  # Display in notebook\n",
    "print(\"\\n✓ Confusion matrix saved to exports/confusion_matrices/baseline_cm_test.png\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JLXebT0ZeWYw"
   },
   "source": [
    "# **BERT Model Initialization and Tokenization**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4coQx6kMeWYw"
   },
   "source": [
    "**`Purpose`**\n",
    "\n",
    "This block initializes the BERT-base-uncased model per proposal Section V.C for toxicity classification. It loads the BERT tokenizer (WordPiece tokenizer) and prepares the datasets for transformer fine-tuning by converting tweets into numerical input representations suitable for model processing.\n",
    "\n",
    "**`Input`**\n",
    "\n",
    "The inputs are the training, validation, and test DataFrames created earlier. The BERT tokenizer is loaded from the transformers library, and a maximum sequence length is specified to keep batch shapes uniform.\n",
    "\n",
    "**`Output`**\n",
    "\n",
    "The block prints the resolved model name and confirms tokenization completion. Three datasets.Dataset objects are produced with tensor columns input_ids, attention_mask, and label. A classification model with three output labels is created and moved to the detected device.\n",
    "\n",
    "**`Details`**\n",
    "\n",
    "The BERT tokenizer (WordPiece tokenizer) is loaded with the fast backend and wrapped in a function that applies truncation and padding to a fixed length of 128 tokens (standard for tweets). The pandas frames are converted into Dataset objects, tokenization is applied in batches for speed, and the dataset columns are formatted as PyTorch tensors. The model is loaded with a task-specific head sized to three classes and placed on CPU or GPU.\n",
    "\n",
    "**`Line-by-line Description.`**\n",
    "\n",
    "`from datasets import Dataset` imports HuggingFace Dataset class for efficient data handling.\n",
    "\n",
    "`from transformers import AutoTokenizer, AutoModelForSequenceClassification` imports BERT tokenizer and model classes.\n",
    "\n",
    "`USE_GPU = torch.cuda.is_available()` checks if GPU is available for training acceleration.\n",
    "\n",
    "`device = torch.device(\"cuda:0\")` or `device = torch.device(\"cpu\")` sets the device for model placement.\n",
    "\n",
    "`NUM_WORKERS = 0 if platform.system() == 'Windows' else 4` sets data loading workers (Windows compatibility: single-process).\n",
    "\n",
    "`MODEL_NAME = \"bert-base-uncased\"` defines the base BERT model identifier.\n",
    "\n",
    "`MAX_LEN = 128` sets maximum sequence length for tokenization (standard for tweets).\n",
    "\n",
    "`tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME, use_fast=True)` loads BERT's WordPiece tokenizer with fast backend.\n",
    "\n",
    "`def tokenize_fn(batch):` defines a tokenization function that applies truncation and padding to fixed length.\n",
    "\n",
    "`return tokenizer(batch[\"review\"], truncation=True, padding=\"max_length\", max_length=MAX_LEN)` tokenizes text with truncation and padding to max length.\n",
    "\n",
    "`label_mapping = {-1: 0, 0: 1, 1: 2}` defines mapping from proposal label format (-1,0,1) to BERT format (0,1,2).\n",
    "\n",
    "`df_train_bert['label'] = df_train_bert['label'].map(label_mapping)` converts training labels to BERT format.\n",
    "\n",
    "`ds_train = Dataset.from_pandas(df_train_bert[['review','label']].reset_index(drop=True))` converts pandas DataFrame to HuggingFace Dataset.\n",
    "\n",
    "`NUM_PROC_TOKENIZE = 4 if USE_GPU else 2` sets number of processes for parallel tokenization (4 for GPU, 2 for CPU).\n",
    "\n",
    "`ds_train = ds_train.map(tokenize_fn, batched=True, num_proc=NUM_PROC_TOKENIZE, remove_columns=['review'])` applies tokenization in batches with parallel processing, removing original review column.\n",
    "\n",
    "`ds_train = ds_train.with_format(\"torch\", columns=cols)` formats dataset columns as PyTorch tensors for model input.\n",
    "\n",
    "`num_labels = 3` sets number of classification classes (negative/toxic, neutral, positive).\n",
    "\n",
    "`model = AutoModelForSequenceClassification.from_pretrained(MODEL_NAME, num_labels=num_labels)` loads BERT model with classification head sized to three classes.\n",
    "\n",
    "`model = model.to(device)` moves model to appropriate device (CPU or GPU).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 605,
     "referenced_widgets": [
      "dcc54877f06d43deab853869e5f0b1e7",
      "f50b6e29f9164d70aa03d2b392e39157",
      "f0fd7fea1774410e8875370e9209dc9b",
      "da6503c757ad4816ad8beb4eb58ed984",
      "eae034b764694e529838da79371cf9c1",
      "f4d9f57aee294796a5dd48c2f18ad43e",
      "cbe81ad09104464487e3631a09652a4f",
      "10cc0dc7261a4eb9884f0ba78c7a3926",
      "7163be4a7bc24997945acdc9404463c4",
      "03212a099ce4422b8a135b8c6eeb2fcd",
      "b23664ab84c84328b4916afad791ddbf",
      "351e5dc9d6f748f1a71abe462e7b0fff",
      "77d0fc25f5fa4252ba04f49e8c4bb7a6",
      "c81749ecedde40f0b716bbcaa9512817",
      "51e9448be13b4de998214e74e896bead",
      "719cb2899fae4fe2af07babb0302e869",
      "d04b6c9f26ae47e9a7b80edf79f39ed3",
      "3f5fcfa83b354817b5d21145b54b5e6f",
      "1d54003236e24467957614ff7a260afd",
      "fb628b4fd03e46a0952b9023f91c8b95",
      "71191bac6547415399a6da202d8b23e8",
      "1a7378e6d40e4a6eb80c0d805727c0f2",
      "5ef7762988b94fe7b83fc58ab38e8251",
      "b9bbc48ea31c4415bce6083ad89e1ee9",
      "a07cd198a7404d79ac9aa475eadfbc24",
      "5dd5311eedb64a12a6b0eb667c55b9b6",
      "255eef29891f471ab6626ea3c5cd3f6f",
      "42bd72f0f1d246f3bfc32ea677583c7b",
      "0afce817cd2941b1bc24854e73cd4dbe",
      "93e73aef85fb46bf8f75f0f701598657",
      "d7a43b67ebbf4e119f0c5ea0830f8fe3",
      "15626e0d50ea4e09a3e134a02c4cfd69",
      "56f2ea0f5985448bb60cc73af75d02e5",
      "6e9c7a54fc5a4d62ab885be848268c2d",
      "275b70feaa5445809c8519700bbcc14e",
      "e1e06685f2cd49a19f14d4a6531c7c07",
      "3a554ae9db8d4455807cdf97c6928f59",
      "d833c9f53700449a91bdd2babdc8dfce",
      "a8c2d07a17fa41caa6a66e2c249634ea",
      "d0344b3fe88049a3951cf09b34f911a0",
      "11fda0ea2b454ce1aa719160211afd08",
      "c91e652010b94d00ba44e835da6149b0",
      "e1769733b168434f8011db6a0b28de3e",
      "c968ea901b14496bacf45f166b0b26b5",
      "3ad66231e487409bacfadc9e79f01d36",
      "9bd68fc454504c0a83949f9564799c35",
      "f5b54a3a770b4b29bbb24ed5b1336519",
      "22d5fa6213ae4a0b837652285777cbd8",
      "d08e382ef1374c2b8f18a95ac2269f1e",
      "eb71c1244137418b9ab28596aa28d34d",
      "8d13e61f557247a69d8ade9b9aa14328",
      "b744c8c467ab40e7b5b20f5c019f4fe3",
      "17c15355c9ef4a7fa5669c930cdf84fd",
      "f372766774e9466fb15d34d86e5f834f",
      "2aced18c55e24958be0a413cdc875a78",
      "f58f8b579d334f9eb7445d47514c02b6",
      "4221c547dbe7453f8dad422356a0b68d",
      "3772522c7cc946ab9972c97a049d5e50",
      "6c130366457445aea8de3ec7921a3c14",
      "fc70866129d94a7fb33a1bda53df2146",
      "db4350bb911e4e108aaa1b13db200d9e",
      "67d53b7bc4c6437ebfa159d59cd2b245",
      "a5d5738beab6445ababb3f0b67109d47",
      "db36372a8dd44ae4a53771f3722a00f5",
      "fb28759cd8754b1eaa0c56b835b23b73",
      "b55e528c34ef4d9b8961731ffc4cca01",
      "a701b5dfeb164cf5ad6be732871e00b3",
      "5c0e791e5fc348bab3239e09b32c29c9",
      "96ec73e3109a4cac8204f01396acac13",
      "cf09a98a3b7a4c938faed59c7d883950",
      "54b7f438ed644a4fb23906fd12a32197",
      "dfaa1b6ff7f84358bb9b333ac31d1626",
      "1f92e948f74348f5bcfc5ead3bfaeb4c",
      "39696b895e6a4d3ab6865c236317f70a",
      "135e3577576d4b26a3d43bae38d67208",
      "610d486ba5204fb5a1c5415bd0dddb81",
      "cc067326155445bc9b80fb26c32187a5",
      "a8975c6dd820414597ed8cd897065751",
      "03616f6164a849c0984dc1ccff5b2b3a",
      "ef6ca063f92340c7a22a0befb15d2ea2",
      "648381ab878c415c8b3e2ecc3c2acbc7",
      "6d7886bc88784b768ec81496afc5855a",
      "c9fc02707312427b9bdc9f7495993b0e",
      "6e89fdd78d3d44bfb2b3b04e91e4be66",
      "1b650b5232834ef5880468f21b8dd263",
      "2e910123a7ee43969d1daf67f03a994d",
      "135feff3d9614e76b88313ad6bfb8177",
      "9f3d5e77337b4f64a72b47a069eb60a2"
     ]
    },
    "id": "WI09CFCteWYw",
    "outputId": "b7291dcb-b67c-4d93-bd00-b621efc1dde9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ GPU detected: Tesla T4\n",
      "  CUDA Version: 12.6\n",
      "  GPU Memory: 15.83 GB\n",
      "\n",
      "Using model: bert-base-uncased\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
      "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
      "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
      "You will be able to reuse this secret in all of your notebooks.\n",
      "Please note that authentication is recommended but still optional to access public models or datasets.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dcc54877f06d43deab853869e5f0b1e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "351e5dc9d6f748f1a71abe462e7b0fff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ef7762988b94fe7b83fc58ab38e8251",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e9c7a54fc5a4d62ab885be848268c2d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tokenizing datasets (this may take a moment)...\n",
      "  Using 4 processes for tokenization\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ad66231e487409bacfadc9e79f01d36",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=4):   0%|          | 0/8330 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f58f8b579d334f9eb7445d47514c02b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=4):   0%|          | 0/4456 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a701b5dfeb164cf5ad6be732871e00b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=4):   0%|          | 0/4476 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Datasets ready: train=8330, val=4456, test=4476\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a8975c6dd820414597ed8cd897065751",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Model loaded on cuda:0\n"
     ]
    }
   ],
   "source": [
    "from datasets import Dataset\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "import platform\n",
    "\n",
    "USE_GPU = torch.cuda.is_available()\n",
    "if USE_GPU:\n",
    "    print(f\"✓ GPU detected: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"  CUDA Version: {torch.version.cuda}\")\n",
    "    print(f\"  GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")\n",
    "    device = torch.device(\"cuda:0\")\n",
    "    NUM_WORKERS = 0 if platform.system() == 'Windows' else 4\n",
    "    PIN_MEMORY = True\n",
    "else:\n",
    "    print(\"⚠ No GPU detected, using CPU (training will be slow)\")\n",
    "    device = torch.device(\"cpu\")\n",
    "    NUM_WORKERS = 0\n",
    "    PIN_MEMORY = False\n",
    "\n",
    "MODEL_NAME = \"bert-base-uncased\"\n",
    "print(f\"\\nUsing model: {MODEL_NAME}\")\n",
    "\n",
    "MAX_LEN = 128\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME, use_fast=True)\n",
    "\n",
    "def tokenize_fn(batch):\n",
    "    \"\"\"Tokenize tweets using BERT's WordPiece tokenizer (per proposal Section V.B)\"\"\"\n",
    "    return tokenizer(batch[\"review\"], truncation=True, padding=\"max_length\", max_length=MAX_LEN)\n",
    "\n",
    "print(\"\\nTokenizing datasets (this may take a moment)...\")\n",
    "\n",
    "label_mapping = {-1: 0, 0: 1, 1: 2}\n",
    "df_train_bert = df_train.copy()\n",
    "df_val_bert = df_val.copy()\n",
    "df_test_bert = df_test.copy()\n",
    "df_train_bert['label'] = df_train_bert['label'].map(label_mapping)\n",
    "df_val_bert['label'] = df_val_bert['label'].map(label_mapping)\n",
    "df_test_bert['label'] = df_test_bert['label'].map(label_mapping)\n",
    "\n",
    "ds_train = Dataset.from_pandas(df_train_bert[['review','label']].reset_index(drop=True))\n",
    "ds_val   = Dataset.from_pandas(df_val_bert[['review','label']].reset_index(drop=True))\n",
    "ds_test  = Dataset.from_pandas(df_test_bert[['review','label']].reset_index(drop=True))\n",
    "\n",
    "if platform.system() == 'Windows':\n",
    "    NUM_PROC_TOKENIZE = None\n",
    "    print(\"  Using single-process tokenization (Windows compatibility)\")\n",
    "else:\n",
    "    NUM_PROC_TOKENIZE = 4 if USE_GPU else 2\n",
    "    print(f\"  Using {NUM_PROC_TOKENIZE} processes for tokenization\")\n",
    "\n",
    "ds_train = ds_train.map(tokenize_fn, batched=True, num_proc=NUM_PROC_TOKENIZE, remove_columns=['review'])\n",
    "ds_val   = ds_val.map(tokenize_fn, batched=True, num_proc=NUM_PROC_TOKENIZE, remove_columns=['review'])\n",
    "ds_test  = ds_test.map(tokenize_fn, batched=True, num_proc=NUM_PROC_TOKENIZE, remove_columns=['review'])\n",
    "\n",
    "cols = ['input_ids','attention_mask','label']\n",
    "ds_train = ds_train.with_format(\"torch\", columns=cols)\n",
    "ds_val   = ds_val.with_format(\"torch\", columns=cols)\n",
    "ds_test  = ds_test.with_format(\"torch\", columns=cols)\n",
    "\n",
    "print(f\"✓ Datasets ready: train={len(ds_train)}, val={len(ds_val)}, test={len(ds_test)}\")\n",
    "\n",
    "num_labels = 3\n",
    "model = AutoModelForSequenceClassification.from_pretrained(MODEL_NAME, num_labels=num_labels)\n",
    "model = model.to(device)\n",
    "print(f\"✓ Model loaded on {device}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jU6tDJ9_eWYx"
   },
   "source": [
    "# **BERT Training Arguments and Configuration**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z3mvTGAneWYx"
   },
   "source": [
    "**`Purpose`**\n",
    "\n",
    "This block defines how BERT training will proceed per proposal Section V.D. It establishes a metric function that reports accuracy, precision, recall, and F1-score, builds training arguments with AdamW optimizer and cross-entropy loss, and constructs a Trainer object that ties the model, data, tokenizer, arguments, and metrics together.\n",
    "\n",
    "**`Input`**\n",
    "\n",
    "Inputs include the tokenized datasets, the initialized model and tokenizer, and hyperparameters such as number of epochs, batch sizes, learning rate, weight decay, and evaluation cadence.\n",
    "\n",
    "**`Output`**\n",
    "\n",
    "The cell prints a confirmation that the trainer is ready and includes the active model name. Internally, it prepares all objects required for training and evaluation.\n",
    "\n",
    "**`Details`**\n",
    "\n",
    "A compute function converts raw model outputs into predicted labels and compares them with gold labels to obtain accuracy, precision, recall, and macro-F1 (target: >0.85 per proposal Section III). Training arguments are configured with AdamW optimizer, cross-entropy loss, linear warmup with learning rate scheduling, early stopping to prevent overfitting, and mixed-precision when GPU is available.\n",
    "\n",
    "**`Line-by-line Description.`**\n",
    "\n",
    "`from transformers import TrainingArguments, Trainer, EarlyStoppingCallback` imports HuggingFace training utilities.\n",
    "\n",
    "`def compute_metrics(eval_pred):` defines a function to compute evaluation metrics from model predictions.\n",
    "\n",
    "`preds = np.argmax(eval_pred.predictions, axis=1)` extracts predicted class indices by finding maximum logit value.\n",
    "\n",
    "`labels = eval_pred.label_ids` extracts true labels from evaluation predictions.\n",
    "\n",
    "`acc = accuracy_score(labels, preds)` calculates accuracy as proportion of correctly classified samples.\n",
    "\n",
    "`prec = precision_score(labels, preds, average='macro', zero_division=0)` calculates macro-averaged precision across classes.\n",
    "\n",
    "`rec = recall_score(labels, preds, average='macro', zero_division=0)` calculates macro-averaged recall across classes.\n",
    "\n",
    "`f1m = f1_score(labels, preds, average='macro', zero_division=0)` calculates macro-averaged F1-score (primary metric).\n",
    "\n",
    "`return {'accuracy': acc, 'precision': prec, 'recall': rec, 'f1_macro': f1m}` returns dictionary of computed metrics.\n",
    "\n",
    "`if USE_GPU: TRAIN_BATCH_SIZE = 32` sets larger batch size for GPU training (32 for GPU, 8 for CPU).\n",
    "\n",
    "`USE_FP16 = True` if GPU available enables mixed-precision training to speed up training and reduce memory usage.\n",
    "\n",
    "`def make_training_args(**overrides):` defines a function to create training arguments with overridable defaults.\n",
    "\n",
    "`base_epochs = 3 if FAST_MODE else 4` sets number of training epochs based on fast mode setting.\n",
    "\n",
    "`total_steps = max(1, (len(ds_train) // max(1, TRAIN_BATCH_SIZE)) * base_epochs)` calculates total training steps.\n",
    "\n",
    "`warmup_steps = max(25, int(total_steps * 0.1))` calculates warmup steps as 10% of total steps (minimum 25).\n",
    "\n",
    "`cfg = dict(output_dir=f\"./checkpoints/bert-base/run1\", ...)` creates training configuration dictionary.\n",
    "\n",
    "`learning_rate=3e-5` sets learning rate for AdamW optimizer (standard for BERT fine-tuning).\n",
    "\n",
    "`weight_decay=0.01` sets L2 regularization strength to prevent overfitting.\n",
    "\n",
    "`warmup_ratio=0.1` sets learning rate warmup ratio (linear warmup over first 10% of steps).\n",
    "\n",
    "`lr_scheduler_type=\"linear\"` specifies linear learning rate decay after warmup.\n",
    "\n",
    "`load_best_model_at_end=True` enables loading best model checkpoint at end of training.\n",
    "\n",
    "`metric_for_best_model=\"f1_macro\"` sets macro-F1 as the metric for selecting best model checkpoint.\n",
    "\n",
    "`early_stopping_patience=2` configures early stopping to stop training if validation metric doesn't improve for 2 evaluations.\n",
    "\n",
    "`callbacks = [EarlyStoppingCallback(early_stopping_patience=2, ...)]` creates early stopping callback to prevent overfitting.\n",
    "\n",
    "`trainer = Trainer(model=model, args=training_args, train_dataset=ds_train, ...)` creates Trainer object tying together model, data, arguments, and metrics.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZKZxww-zeWYx",
    "outputId": "51278cb9-f2e6-4ec8-bfab-03dcfd07a1f6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Trainer ready on cuda:0\n",
      "  Batch size: 32 (train), 64 (eval)\n",
      "  FP16: True, Workers: 4, Pin Memory: True\n",
      "  Early stopping: patience=2\n",
      "  Optimizer: AdamW, Loss: Cross-entropy, Scheduler: Linear warmup\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipython-input-3391626241.py:82: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    }
   ],
   "source": [
    "from transformers import TrainingArguments, Trainer, EarlyStoppingCallback\n",
    "from sklearn.metrics import precision_score, recall_score\n",
    "import inspect\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    \"\"\"Compute metrics per proposal Section VI.A: accuracy, precision, recall, F1-score\"\"\"\n",
    "    preds = np.argmax(eval_pred.predictions, axis=1)\n",
    "    labels = eval_pred.label_ids\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    prec = precision_score(labels, preds, average='macro', zero_division=0)\n",
    "    rec = recall_score(labels, preds, average='macro', zero_division=0)\n",
    "    f1m = f1_score(labels, preds, average='macro', zero_division=0)\n",
    "    return {'accuracy': acc, 'precision': prec, 'recall': rec, 'f1_macro': f1m}\n",
    "\n",
    "if USE_GPU:\n",
    "    TRAIN_BATCH_SIZE = 32\n",
    "    EVAL_BATCH_SIZE = 64\n",
    "    USE_FP16 = True\n",
    "    GRADIENT_CHECKPOINTING = False\n",
    "else:\n",
    "    TRAIN_BATCH_SIZE = 8\n",
    "    EVAL_BATCH_SIZE = 16\n",
    "    USE_FP16 = False\n",
    "    GRADIENT_CHECKPOINTING = False\n",
    "\n",
    "sig = inspect.signature(TrainingArguments.__init__)\n",
    "argnames = set(sig.parameters.keys())\n",
    "\n",
    "def make_training_args(**overrides):\n",
    "    \"\"\"Create training arguments per proposal Section V.D\"\"\"\n",
    "    base_epochs = 3 if FAST_MODE else 4\n",
    "    total_steps = max(1, (len(ds_train) // max(1, TRAIN_BATCH_SIZE)) * base_epochs)\n",
    "    warmup_steps = max(25, int(total_steps * 0.1))\n",
    "\n",
    "    cfg = dict(\n",
    "        output_dir=f\"./checkpoints/bert-base/run1\",\n",
    "        num_train_epochs=base_epochs,\n",
    "        per_device_train_batch_size=TRAIN_BATCH_SIZE,\n",
    "        per_device_eval_batch_size=EVAL_BATCH_SIZE,\n",
    "        learning_rate=3e-5,\n",
    "        weight_decay=0.01,\n",
    "        warmup_ratio=0.1,\n",
    "        lr_scheduler_type=\"linear\",\n",
    "        gradient_accumulation_steps=1,\n",
    "        load_best_model_at_end=True,\n",
    "        metric_for_best_model=\"f1_macro\",\n",
    "        greater_is_better=True,\n",
    "        seed=RANDOM_SEED,\n",
    "        logging_steps=50,\n",
    "        eval_steps=100,\n",
    "        save_steps=200,\n",
    "        save_total_limit=2,\n",
    "        report_to=[],\n",
    "        optim=\"adamw_torch\",\n",
    "        fp16=USE_FP16,\n",
    "        dataloader_num_workers=NUM_WORKERS,\n",
    "        dataloader_pin_memory=PIN_MEMORY,\n",
    "        remove_unused_columns=False,\n",
    "        gradient_checkpointing=GRADIENT_CHECKPOINTING,\n",
    "    )\n",
    "    cfg.update(overrides)\n",
    "\n",
    "    if \"evaluation_strategy\" in argnames:\n",
    "        cfg[\"evaluation_strategy\"] = cfg.get(\"evaluation_strategy\", \"steps\")\n",
    "    elif \"eval_strategy\" in argnames:\n",
    "        cfg[\"eval_strategy\"] = cfg.get(\"eval_strategy\", \"steps\")\n",
    "\n",
    "    if \"save_strategy\" in argnames:\n",
    "        cfg[\"save_strategy\"] = cfg.get(\"save_strategy\", \"steps\")\n",
    "\n",
    "    safe_cfg = {k:v for k,v in cfg.items() if k in argnames}\n",
    "    return TrainingArguments(**safe_cfg)\n",
    "\n",
    "training_args = make_training_args()\n",
    "\n",
    "if GRADIENT_CHECKPOINTING and hasattr(model, 'gradient_checkpointing_enable'):\n",
    "    model.gradient_checkpointing_enable()\n",
    "    print(\"✓ Gradient checkpointing enabled (saves memory)\")\n",
    "\n",
    "callbacks = [EarlyStoppingCallback(early_stopping_patience=2, early_stopping_threshold=0.001)]\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=ds_train,\n",
    "    eval_dataset=ds_val,\n",
    "    compute_metrics=compute_metrics,\n",
    "    tokenizer=tokenizer,\n",
    "    callbacks=callbacks,\n",
    ")\n",
    "\n",
    "print(f\"✓ Trainer ready on {device}\")\n",
    "print(f\"  Batch size: {TRAIN_BATCH_SIZE} (train), {EVAL_BATCH_SIZE} (eval)\")\n",
    "print(f\"  FP16: {USE_FP16}, Workers: {NUM_WORKERS}, Pin Memory: {PIN_MEMORY}\")\n",
    "print(f\"  Early stopping: patience=2\")\n",
    "print(f\"  Optimizer: AdamW, Loss: Cross-entropy, Scheduler: Linear warmup\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c0c5Zye7eWYx"
   },
   "source": [
    "# Automated Hyperparameter Tuning\n",
    "\n",
    "**`Purpose`**\n",
    "\n",
    "Run Optuna-driven grid and random searches per proposal Section V.C for hyperparameter tuning and validation curve analysis to find optimum performance. The search explores learning rate, batch size, epochs, weight decay, and warmup ratio to identify the best configuration via validation macro-F1.\n",
    "\n",
    "**`Input`**\n",
    "\n",
    "Uses the tokenized datasets (`ds_train`, `ds_val`), global tokenizer/model selections, and shared helpers (`compute_metrics`, `make_training_args`). Configuration depends on `AUTO_TUNE_ENABLED`, search spaces, and trial limits.\n",
    "\n",
    "**`Output`**\n",
    "\n",
    "Writes per-strategy trial tables to `tuning/` directory, a combined summary, and logs the best configuration. The winning configuration is retrained, evaluated on validation and test splits, logged to `runs_log.csv`, and predictions exported.\n",
    "\n",
    "**`Details`**\n",
    "\n",
    "Defines a lightweight `WeightedTrainer` compatible with Optuna, registers helper functions to build Trainers for suggested hyperparameters. Optuna's `GridSampler` and `RandomSampler` explore the respective spaces, timing each trial and storing validation metrics.\n",
    "\n",
    "**`Line-by-line Description.`**\n",
    "\n",
    "`AUTO_TUNE_ENABLED = True` enables/disables automated hyperparameter tuning.\n",
    "\n",
    "`GRID_SEARCH_SPACE = {\"learning_rate\": [3e-5], ...}` defines grid search hyperparameter space with discrete values.\n",
    "\n",
    "`RANDOM_SEARCH_SPACE = {\"learning_rate\": (\"log_uniform\", 2e-5, 5e-5), ...}` defines random search hyperparameter space with continuous distributions.\n",
    "\n",
    "`RANDOM_TRIALS = 8` sets number of random search trials to run.\n",
    "\n",
    "`MAX_AUTOTUNE_EPOCHS = 4` sets maximum epochs per trial during hyperparameter tuning.\n",
    "\n",
    "`class WeightedTrainer(Trainer):` defines a custom Trainer class compatible with Optuna for hyperparameter tuning.\n",
    "\n",
    "`def build_trainer_for_trial(hparams, run_name):` defines function to build a Trainer instance with suggested hyperparameters.\n",
    "\n",
    "`trial_args = make_training_args(..., learning_rate=hparams.get(\"learning_rate\", 3e-5), ...)` creates training arguments with trial-specific hyperparameters.\n",
    "\n",
    "`trial_model = AutoModelForSequenceClassification.from_pretrained(MODEL_NAME, num_labels=3).to(device)` creates fresh model instance for each trial.\n",
    "\n",
    "`trial_trainer = WeightedTrainer(model=trial_model, args=trial_args, ...)` creates Trainer instance for current trial.\n",
    "\n",
    "`def suggest_params(trial, strategy):` defines function to suggest hyperparameters based on search strategy (grid or random).\n",
    "\n",
    "`if strategy == \"grid\":` handles grid search parameter suggestion by computing parameter combinations from grid space.\n",
    "\n",
    "`lr_idx = idx % len(lr_vals)` and similar lines compute parameter indices for grid search combination.\n",
    "\n",
    "`return {...}` returns dictionary of suggested hyperparameters for current trial.\n",
    "\n",
    "`else: return {...}` handles random search by using Optuna's suggest methods for continuous parameters.\n",
    "\n",
    "`def objective(trial):` defines Optuna objective function that trains and evaluates a model for one trial.\n",
    "\n",
    "`strategy = trial.study.sampler.__class__.__name__` determines search strategy (GridSampler or RandomSampler) from study.\n",
    "\n",
    "`hparams = suggest_params(trial, \"grid\" if \"Grid\" in strategy else \"random\")` gets suggested hyperparameters for current trial.\n",
    "\n",
    "`trainer_obj.train()` trains the model for current trial with suggested hyperparameters.\n",
    "\n",
    "`start_time = time.time()` records trial start time for performance measurement.\n",
    "\n",
    "`eval_results = trainer_obj.evaluate()` evaluates trained model on validation set.\n",
    "\n",
    "`f1_macro = eval_results.get(\"eval_f1_macro\", 0.0)` extracts validation F1-macro (objective to maximize).\n",
    "\n",
    "`trial.set_user_attr(\"train_time\", train_time)` stores trial execution time as user attribute.\n",
    "\n",
    "`return f1_macro` returns validation F1-macro as Optuna objective value.\n",
    "\n",
    "`sampler = GridSampler(GRID_SEARCH_SPACE)` creates grid search sampler for exhaustive search.\n",
    "\n",
    "`study = optuna.create_study(direction=\"maximize\", sampler=sampler)` creates Optuna study configured to maximize F1-macro.\n",
    "\n",
    "`study.optimize(objective, n_trials=total_trials, show_progress_bar=True)` runs grid search optimization for all combinations.\n",
    "\n",
    "`sampler = RandomSampler(seed=RANDOM_SEED)` creates random search sampler with fixed seed for reproducibility.\n",
    "\n",
    "`study.optimize(objective, n_trials=RANDOM_TRIALS, ...)` runs random search optimization for specified number of trials.\n",
    "\n",
    "`trials_df = pd.DataFrame([...])` creates DataFrame with trial results (hyperparameters and metrics).\n",
    "\n",
    "`trials_df.to_csv(TUNING_DIR / f\"{strategy}_trials.csv\", index=False)` saves trial results to CSV file.\n",
    "\n",
    "`best_hparams = study.best_trial.params` extracts best hyperparameters from completed study.\n",
    "\n",
    "`best_trainer.train()` retrains model with best hyperparameters on full training set.\n",
    "\n",
    "`best_trainer.save_model(best_ckpt_dir)` saves best model checkpoint to disk.\n",
    "\n",
    "`tokenizer.save_pretrained(best_ckpt_dir)` saves tokenizer alongside model checkpoint.\n",
    "\n",
    "`row = {...}` creates log entry with best trial results for experiment ledger.\n",
    "\n",
    "`pd.DataFrame([row]).to_csv(\"runs_log.csv\", mode=\"a\", ...)` appends best trial results to experiment log.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UDraNmh_eWYx",
    "outputId": "c52a9160-247f-4e45-ab35-eba69c5ac043"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hyperparameter tuning configuration:\n"
     ]
    }
   ],
   "source": [
    "AUTO_TUNE_ENABLED = True\n",
    "\n",
    "GRID_SEARCH_SPACE = {\n",
    "    \"learning_rate\": [3e-5],\n",
    "    \"per_device_train_batch_size\": [8, 16],\n",
    "    \"weight_decay\": [0.0, 0.01],\n",
    "    \"num_train_epochs\": [2, 3],\n",
    "}\n",
    "\n",
    "\n",
    "RANDOM_SEARCH_SPACE = {\n",
    "    \"learning_rate\": (\"log_uniform\", 2e-5, 5e-5),\n",
    "    \"per_device_train_batch_size\": (\"choice\", [8, 12, 16, 24, 32]),\n",
    "    \"weight_decay\": (\"uniform\", 0.0, 0.1),\n",
    "    \"num_train_epochs\": (\"int\", 2, 4),\n",
    "}\n",
    "\n",
    "RANDOM_TRIALS = 8\n",
    "MAX_AUTOTUNE_EPOCHS = 4\n",
    "\n",
    "print(\"Hyperparameter tuning configuration:\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "b2e169dc048a463d803dfb31fc110372",
      "27f3b02b05694355905bd30e73dbdb76",
      "851d104f415a4c85bd3bb4a27871c3cc",
      "4517b6ef49d24799b1e9108c7d1eda2a",
      "cc100f025a7b454392427512aa929fb4",
      "fb09029059d942e79db695cd14274656",
      "c6a046344ce8439c8e84f473a8007da0",
      "c9eaabab5d844cf8b02048fb48cbdc1b",
      "5d882abf74834499921a526972845a6a",
      "e65a75ceddcf4230ac03b8a131714b4b",
      "576b4557bf14422b8850cf5d3819a7c1",
      "f2b5967ccc1c4665ac7d5638c47b40c9",
      "1cf59def1999467e80be0bdab29cfdfe",
      "6cadb6fc36fe47dfa0fd9f2bd1c807ca",
      "08186379a45246ae86d4602033bb3ccc",
      "0818eeb507cd4c30a17c845d2ad4c0dd",
      "43bdfbe028ab4c0c8718679e4c4b1e95",
      "70dd0010da4849f4aa9ad301e61e230c",
      "0b00736fef7b454bbfcd829b1667db64",
      "9145878ce90e4126afc4721207e3307f",
      "bc148e80c2964c90996a6aa224ec9752",
      "17d6367ac07342bab4215ac7191f5c16"
     ]
    },
    "id": "FvEnrzFHeWYy",
    "outputId": "806127a8-377a-4c27-e2fe-88b29fec311c"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-15 18:21:14,034] A new study created in memory with name: no-name-820d2c9a-1bc1-43cb-b600-8feeccc1ae5a\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Hyperparameter search: GRID ===\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b2e169dc048a463d803dfb31fc110372",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/tmp/ipython-input-1368014748.py:13: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `WeightedTrainer.__init__`. Use `processing_class` instead.\n",
      "  super().__init__(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2084' max='2084' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2084/2084 03:21, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.804000</td>\n",
       "      <td>0.805001</td>\n",
       "      <td>0.672576</td>\n",
       "      <td>0.698924</td>\n",
       "      <td>0.660293</td>\n",
       "      <td>0.666503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.594000</td>\n",
       "      <td>0.814846</td>\n",
       "      <td>0.663375</td>\n",
       "      <td>0.675542</td>\n",
       "      <td>0.657824</td>\n",
       "      <td>0.663941</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='70' max='70' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [70/70 00:07]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-15 18:24:46,323] Trial 0 finished with value: 0.6665025386088582 and parameters: {}. Best is trial 0 with value: 0.6665025386088582.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipython-input-1368014748.py:13: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `WeightedTrainer.__init__`. Use `processing_class` instead.\n",
      "  super().__init__(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1042' max='1042' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1042/1042 02:25, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.807000</td>\n",
       "      <td>0.793709</td>\n",
       "      <td>0.670781</td>\n",
       "      <td>0.687766</td>\n",
       "      <td>0.662287</td>\n",
       "      <td>0.669839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.683600</td>\n",
       "      <td>0.814609</td>\n",
       "      <td>0.667415</td>\n",
       "      <td>0.678369</td>\n",
       "      <td>0.663614</td>\n",
       "      <td>0.669040</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='70' max='70' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [70/70 00:06]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-15 18:27:20,229] Trial 1 finished with value: 0.6698388377079203 and parameters: {}. Best is trial 1 with value: 0.6698388377079203.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipython-input-1368014748.py:13: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `WeightedTrainer.__init__`. Use `processing_class` instead.\n",
      "  super().__init__(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2084' max='2084' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2084/2084 03:29, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.803000</td>\n",
       "      <td>0.813714</td>\n",
       "      <td>0.672127</td>\n",
       "      <td>0.697949</td>\n",
       "      <td>0.659464</td>\n",
       "      <td>0.667231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.600300</td>\n",
       "      <td>0.814008</td>\n",
       "      <td>0.670332</td>\n",
       "      <td>0.682572</td>\n",
       "      <td>0.665384</td>\n",
       "      <td>0.671474</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='70' max='70' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [70/70 00:06]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-15 18:30:58,376] Trial 2 finished with value: 0.6714738862200339 and parameters: {}. Best is trial 2 with value: 0.6714738862200339.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipython-input-1368014748.py:13: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `WeightedTrainer.__init__`. Use `processing_class` instead.\n",
      "  super().__init__(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1042' max='1042' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1042/1042 02:28, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.801000</td>\n",
       "      <td>0.796792</td>\n",
       "      <td>0.671005</td>\n",
       "      <td>0.685829</td>\n",
       "      <td>0.663921</td>\n",
       "      <td>0.670905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.696200</td>\n",
       "      <td>0.804887</td>\n",
       "      <td>0.674147</td>\n",
       "      <td>0.686506</td>\n",
       "      <td>0.669793</td>\n",
       "      <td>0.675779</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='70' max='70' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [70/70 00:06]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-15 18:33:36,168] Trial 3 finished with value: 0.6757790326459004 and parameters: {}. Best is trial 3 with value: 0.6757790326459004.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipython-input-1368014748.py:13: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `WeightedTrainer.__init__`. Use `processing_class` instead.\n",
      "  super().__init__(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3126' max='3126' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3126/3126 05:04, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.806200</td>\n",
       "      <td>0.829206</td>\n",
       "      <td>0.660458</td>\n",
       "      <td>0.687764</td>\n",
       "      <td>0.649172</td>\n",
       "      <td>0.653210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.623400</td>\n",
       "      <td>0.841678</td>\n",
       "      <td>0.660682</td>\n",
       "      <td>0.662634</td>\n",
       "      <td>0.666174</td>\n",
       "      <td>0.663596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.562400</td>\n",
       "      <td>0.947541</td>\n",
       "      <td>0.663375</td>\n",
       "      <td>0.672260</td>\n",
       "      <td>0.660821</td>\n",
       "      <td>0.665291</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='70' max='70' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [70/70 00:06]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-15 18:38:49,645] Trial 4 finished with value: 0.6652912087643376 and parameters: {}. Best is trial 3 with value: 0.6757790326459004.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipython-input-1368014748.py:13: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `WeightedTrainer.__init__`. Use `processing_class` instead.\n",
      "  super().__init__(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1563' max='1563' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1563/1563 03:38, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.805300</td>\n",
       "      <td>0.803696</td>\n",
       "      <td>0.674372</td>\n",
       "      <td>0.691500</td>\n",
       "      <td>0.665387</td>\n",
       "      <td>0.672725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.686700</td>\n",
       "      <td>0.850119</td>\n",
       "      <td>0.653725</td>\n",
       "      <td>0.659186</td>\n",
       "      <td>0.658635</td>\n",
       "      <td>0.657006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.541300</td>\n",
       "      <td>0.878534</td>\n",
       "      <td>0.668986</td>\n",
       "      <td>0.680247</td>\n",
       "      <td>0.664491</td>\n",
       "      <td>0.670168</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='70' max='70' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [70/70 00:06]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-15 18:42:36,663] Trial 5 finished with value: 0.6727248673894713 and parameters: {}. Best is trial 3 with value: 0.6757790326459004.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipython-input-1368014748.py:13: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `WeightedTrainer.__init__`. Use `processing_class` instead.\n",
      "  super().__init__(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3126' max='3126' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3126/3126 05:15, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.801000</td>\n",
       "      <td>0.802905</td>\n",
       "      <td>0.666966</td>\n",
       "      <td>0.694174</td>\n",
       "      <td>0.654394</td>\n",
       "      <td>0.661550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.617200</td>\n",
       "      <td>0.838843</td>\n",
       "      <td>0.666293</td>\n",
       "      <td>0.670110</td>\n",
       "      <td>0.666691</td>\n",
       "      <td>0.668244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.586900</td>\n",
       "      <td>0.963637</td>\n",
       "      <td>0.658438</td>\n",
       "      <td>0.667403</td>\n",
       "      <td>0.655145</td>\n",
       "      <td>0.659637</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='70' max='70' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [70/70 00:07]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-15 18:48:00,610] Trial 6 finished with value: 0.6682440866561308 and parameters: {}. Best is trial 3 with value: 0.6757790326459004.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipython-input-1368014748.py:13: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `WeightedTrainer.__init__`. Use `processing_class` instead.\n",
      "  super().__init__(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1563' max='1563' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1563/1563 03:43, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.814400</td>\n",
       "      <td>0.813432</td>\n",
       "      <td>0.671903</td>\n",
       "      <td>0.689374</td>\n",
       "      <td>0.663077</td>\n",
       "      <td>0.670486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.694400</td>\n",
       "      <td>0.832471</td>\n",
       "      <td>0.656867</td>\n",
       "      <td>0.663201</td>\n",
       "      <td>0.658041</td>\n",
       "      <td>0.659767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.544000</td>\n",
       "      <td>0.866975</td>\n",
       "      <td>0.666068</td>\n",
       "      <td>0.676887</td>\n",
       "      <td>0.661804</td>\n",
       "      <td>0.667297</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='70' max='70' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [70/70 00:06]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-15 18:51:53,127] Trial 7 finished with value: 0.6704863186873188 and parameters: {}. Best is trial 3 with value: 0.6757790326459004.\n",
      "Saved grid trials to tuning/grid_trials.csv\n",
      "\n",
      "Best grid trial: F1-macro = 0.6758\n",
      "Best params: {}\n",
      "\n",
      "Retraining with best grid configuration...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipython-input-1368014748.py:13: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `WeightedTrainer.__init__`. Use `processing_class` instead.\n",
      "  super().__init__(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1563' max='1563' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1563/1563 03:45, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.814400</td>\n",
       "      <td>0.813432</td>\n",
       "      <td>0.671903</td>\n",
       "      <td>0.689374</td>\n",
       "      <td>0.663077</td>\n",
       "      <td>0.670486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.694400</td>\n",
       "      <td>0.832471</td>\n",
       "      <td>0.656867</td>\n",
       "      <td>0.663201</td>\n",
       "      <td>0.658041</td>\n",
       "      <td>0.659767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.544000</td>\n",
       "      <td>0.866975</td>\n",
       "      <td>0.666068</td>\n",
       "      <td>0.676887</td>\n",
       "      <td>0.661804</td>\n",
       "      <td>0.667297</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='140' max='70' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [70/70 00:14]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-15 18:55:54,547] A new study created in memory with name: no-name-13191712-178d-4111-aaff-d96d4e793921\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Hyperparameter search: RANDOM ===\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f2b5967ccc1c4665ac7d5638c47b40c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/tmp/ipython-input-1368014748.py:13: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `WeightedTrainer.__init__`. Use `processing_class` instead.\n",
      "  super().__init__(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4168' max='4168' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4168/4168 07:03, Epoch 4/4]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.816300</td>\n",
       "      <td>0.828483</td>\n",
       "      <td>0.656867</td>\n",
       "      <td>0.691710</td>\n",
       "      <td>0.642601</td>\n",
       "      <td>0.646828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.681400</td>\n",
       "      <td>0.846385</td>\n",
       "      <td>0.661131</td>\n",
       "      <td>0.664143</td>\n",
       "      <td>0.664714</td>\n",
       "      <td>0.663858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.636900</td>\n",
       "      <td>0.864370</td>\n",
       "      <td>0.666517</td>\n",
       "      <td>0.673371</td>\n",
       "      <td>0.663390</td>\n",
       "      <td>0.666907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.501400</td>\n",
       "      <td>1.242701</td>\n",
       "      <td>0.659785</td>\n",
       "      <td>0.665737</td>\n",
       "      <td>0.657958</td>\n",
       "      <td>0.661111</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='70' max='70' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [70/70 00:06]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-15 19:03:07,174] Trial 0 finished with value: 0.6669069431026896 and parameters: {'learning_rate': 2.8188664052384835e-05, 'per_device_train_batch_size': 8, 'weight_decay': 0.005808361216819946, 'num_train_epochs': 4}. Best is trial 0 with value: 0.6669069431026896.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipython-input-1368014748.py:13: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `WeightedTrainer.__init__`. Use `processing_class` instead.\n",
      "  super().__init__(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1042' max='1042' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1042/1042 02:31, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.814600</td>\n",
       "      <td>0.786872</td>\n",
       "      <td>0.672127</td>\n",
       "      <td>0.693082</td>\n",
       "      <td>0.661959</td>\n",
       "      <td>0.670463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.677100</td>\n",
       "      <td>0.804838</td>\n",
       "      <td>0.672127</td>\n",
       "      <td>0.685505</td>\n",
       "      <td>0.666572</td>\n",
       "      <td>0.673072</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='70' max='70' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [70/70 00:06]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-15 19:05:47,402] Trial 1 finished with value: 0.673071977117174 and parameters: {'learning_rate': 3.469266868719914e-05, 'per_device_train_batch_size': 16, 'weight_decay': 0.018182496720710064, 'num_train_epochs': 2}. Best is trial 1 with value: 0.673071977117174.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipython-input-1368014748.py:13: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `WeightedTrainer.__init__`. Use `processing_class` instead.\n",
      "  super().__init__(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1044' max='1044' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1044/1044 03:11, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.781400</td>\n",
       "      <td>0.800841</td>\n",
       "      <td>0.660682</td>\n",
       "      <td>0.680086</td>\n",
       "      <td>0.651235</td>\n",
       "      <td>0.658005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.715200</td>\n",
       "      <td>0.805236</td>\n",
       "      <td>0.667864</td>\n",
       "      <td>0.678382</td>\n",
       "      <td>0.666181</td>\n",
       "      <td>0.670285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.557500</td>\n",
       "      <td>0.845732</td>\n",
       "      <td>0.669659</td>\n",
       "      <td>0.680261</td>\n",
       "      <td>0.665156</td>\n",
       "      <td>0.670640</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='70' max='70' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [70/70 00:06]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-15 19:09:07,746] Trial 2 finished with value: 0.6706395736073101 and parameters: {'learning_rate': 2.6430182166924245e-05, 'per_device_train_batch_size': 24, 'weight_decay': 0.029214464853521818, 'num_train_epochs': 3}. Best is trial 1 with value: 0.673071977117174.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipython-input-1368014748.py:13: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `WeightedTrainer.__init__`. Use `processing_class` instead.\n",
      "  super().__init__(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2084' max='2084' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2084/2084 03:30, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.809500</td>\n",
       "      <td>0.796785</td>\n",
       "      <td>0.675943</td>\n",
       "      <td>0.698231</td>\n",
       "      <td>0.664984</td>\n",
       "      <td>0.671845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.614000</td>\n",
       "      <td>0.805018</td>\n",
       "      <td>0.666966</td>\n",
       "      <td>0.681973</td>\n",
       "      <td>0.660829</td>\n",
       "      <td>0.667890</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='70' max='70' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [70/70 00:06]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-15 19:12:47,049] Trial 3 finished with value: 0.6718453749775296 and parameters: {'learning_rate': 3.037515404772984e-05, 'per_device_train_batch_size': 8, 'weight_decay': 0.06075448519014384, 'num_train_epochs': 2}. Best is trial 1 with value: 0.673071977117174.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipython-input-1368014748.py:13: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `WeightedTrainer.__init__`. Use `processing_class` instead.\n",
      "  super().__init__(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2085' max='2085' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2085/2085 04:04, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.825700</td>\n",
       "      <td>0.805086</td>\n",
       "      <td>0.671454</td>\n",
       "      <td>0.687644</td>\n",
       "      <td>0.662599</td>\n",
       "      <td>0.669382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.724700</td>\n",
       "      <td>0.820491</td>\n",
       "      <td>0.665171</td>\n",
       "      <td>0.677190</td>\n",
       "      <td>0.661595</td>\n",
       "      <td>0.667290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.570000</td>\n",
       "      <td>0.872881</td>\n",
       "      <td>0.666966</td>\n",
       "      <td>0.678260</td>\n",
       "      <td>0.662877</td>\n",
       "      <td>0.668488</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='70' max='70' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [70/70 00:06]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-15 19:17:00,459] Trial 4 finished with value: 0.6693821574448732 and parameters: {'learning_rate': 2.1228368952944975e-05, 'per_device_train_batch_size': 12, 'weight_decay': 0.0684233026512157, 'num_train_epochs': 3}. Best is trial 1 with value: 0.673071977117174.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipython-input-1368014748.py:13: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `WeightedTrainer.__init__`. Use `processing_class` instead.\n",
      "  super().__init__(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1563' max='1563' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1563/1563 03:44, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.822400</td>\n",
       "      <td>0.792184</td>\n",
       "      <td>0.673025</td>\n",
       "      <td>0.688721</td>\n",
       "      <td>0.664700</td>\n",
       "      <td>0.671654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.695800</td>\n",
       "      <td>0.829545</td>\n",
       "      <td>0.665171</td>\n",
       "      <td>0.671275</td>\n",
       "      <td>0.666200</td>\n",
       "      <td>0.667939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.573700</td>\n",
       "      <td>0.869241</td>\n",
       "      <td>0.664722</td>\n",
       "      <td>0.673936</td>\n",
       "      <td>0.661633</td>\n",
       "      <td>0.666355</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='70' max='70' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [70/70 00:06]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-15 19:20:53,478] Trial 5 finished with value: 0.6716542632585442 and parameters: {'learning_rate': 2.2366286923412623e-05, 'per_device_train_batch_size': 16, 'weight_decay': 0.031171107608941095, 'num_train_epochs': 3}. Best is trial 1 with value: 0.673071977117174.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipython-input-1368014748.py:13: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `WeightedTrainer.__init__`. Use `processing_class` instead.\n",
      "  super().__init__(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2085' max='2780' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2085/2780 04:05 < 01:21, 8.48 it/s, Epoch 3/4]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.837000</td>\n",
       "      <td>0.834340</td>\n",
       "      <td>0.659336</td>\n",
       "      <td>0.684898</td>\n",
       "      <td>0.646875</td>\n",
       "      <td>0.652746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.724900</td>\n",
       "      <td>0.862079</td>\n",
       "      <td>0.645422</td>\n",
       "      <td>0.649346</td>\n",
       "      <td>0.654454</td>\n",
       "      <td>0.648553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.483700</td>\n",
       "      <td>0.895082</td>\n",
       "      <td>0.647890</td>\n",
       "      <td>0.658666</td>\n",
       "      <td>0.644100</td>\n",
       "      <td>0.649425</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='70' max='70' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [70/70 00:06]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-15 19:25:07,903] Trial 6 finished with value: 0.652745635150938 and parameters: {'learning_rate': 3.300561952272884e-05, 'per_device_train_batch_size': 12, 'weight_decay': 0.05978999788110852, 'num_train_epochs': 4}. Best is trial 1 with value: 0.673071977117174.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipython-input-1368014748.py:13: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `WeightedTrainer.__init__`. Use `processing_class` instead.\n",
      "  super().__init__(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1044' max='1044' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1044/1044 03:11, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.796900</td>\n",
       "      <td>0.804314</td>\n",
       "      <td>0.669210</td>\n",
       "      <td>0.685319</td>\n",
       "      <td>0.660572</td>\n",
       "      <td>0.666287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.711800</td>\n",
       "      <td>0.800847</td>\n",
       "      <td>0.677065</td>\n",
       "      <td>0.686665</td>\n",
       "      <td>0.672167</td>\n",
       "      <td>0.677417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.584900</td>\n",
       "      <td>0.837268</td>\n",
       "      <td>0.664946</td>\n",
       "      <td>0.674823</td>\n",
       "      <td>0.661075</td>\n",
       "      <td>0.666177</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='70' max='70' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [70/70 00:06]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-15 19:28:28,625] Trial 7 finished with value: 0.6774166339229465 and parameters: {'learning_rate': 2.1689258392227166e-05, 'per_device_train_batch_size': 24, 'weight_decay': 0.08287375091519295, 'num_train_epochs': 3}. Best is trial 7 with value: 0.6774166339229465.\n",
      "Saved random trials to tuning/random_trials.csv\n",
      "\n",
      "Best random trial: F1-macro = 0.6774\n",
      "Best params: {'learning_rate': 2.1689258392227166e-05, 'per_device_train_batch_size': 24, 'weight_decay': 0.08287375091519295, 'num_train_epochs': 3}\n",
      "\n",
      "Retraining with best random configuration...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipython-input-1368014748.py:13: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `WeightedTrainer.__init__`. Use `processing_class` instead.\n",
      "  super().__init__(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1044' max='1044' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1044/1044 03:12, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.796900</td>\n",
       "      <td>0.804314</td>\n",
       "      <td>0.669210</td>\n",
       "      <td>0.685319</td>\n",
       "      <td>0.660572</td>\n",
       "      <td>0.666287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.711800</td>\n",
       "      <td>0.800847</td>\n",
       "      <td>0.677065</td>\n",
       "      <td>0.686665</td>\n",
       "      <td>0.672167</td>\n",
       "      <td>0.677417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.584900</td>\n",
       "      <td>0.837268</td>\n",
       "      <td>0.664946</td>\n",
       "      <td>0.674823</td>\n",
       "      <td>0.661075</td>\n",
       "      <td>0.666177</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='140' max='70' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [70/70 00:14]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✓ Saved strategy summary to tuning/strategy_summary.csv\n",
      "  strategy  f1_macro_val  f1_macro_test  accuracy_val  accuracy_test  \\\n",
      "0     grid      0.670486       0.667874      0.671903       0.669124   \n",
      "1   random      0.677417       0.668883      0.677065       0.667337   \n",
      "\n",
      "                                         best_params  \n",
      "0                                                 {}  \n",
      "1  {'learning_rate': 2.1689258392227166e-05, 'per...  \n"
     ]
    }
   ],
   "source": [
    "import gc\n",
    "import time\n",
    "from optuna.samplers import GridSampler, RandomSampler\n",
    "from pathlib import Path\n",
    "\n",
    "TUNING_DIR = Path(\"tuning\")\n",
    "TUNING_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "if AUTO_TUNE_ENABLED:\n",
    "\n",
    "    class WeightedTrainer(Trainer):\n",
    "        def __init__(self, *args, class_weights=None, **kwargs):\n",
    "            super().__init__(*args, **kwargs)\n",
    "            self.class_weights = class_weights\n",
    "\n",
    "    def build_trainer_for_trial(hparams, run_name):\n",
    "        \"\"\"Build trainer with suggested hyperparameters\"\"\"\n",
    "        trial_args = make_training_args(\n",
    "            output_dir=f\"./checkpoints/bert-base/{run_name}\",\n",
    "            learning_rate=hparams.get(\"learning_rate\", 3e-5),\n",
    "            per_device_train_batch_size=hparams.get(\"per_device_train_batch_size\", 16),\n",
    "            weight_decay=hparams.get(\"weight_decay\", 0.01),\n",
    "            num_train_epochs=min(hparams.get(\"num_train_epochs\", 3), MAX_AUTOTUNE_EPOCHS),\n",
    "            eval_strategy=\"epoch\",\n",
    "            save_strategy=\"epoch\",\n",
    "        )\n",
    "\n",
    "        trial_model = AutoModelForSequenceClassification.from_pretrained(MODEL_NAME, num_labels=3).to(device)\n",
    "\n",
    "        trial_trainer = WeightedTrainer(\n",
    "            model=trial_model,\n",
    "            args=trial_args,\n",
    "            train_dataset=ds_train,\n",
    "            eval_dataset=ds_val,\n",
    "            compute_metrics=compute_metrics,\n",
    "            tokenizer=tokenizer,\n",
    "            callbacks=[EarlyStoppingCallback(early_stopping_patience=2, early_stopping_threshold=0.001)],\n",
    "        )\n",
    "        return trial_trainer, trial_args\n",
    "\n",
    "    def suggest_params(trial, strategy):\n",
    "        \"\"\"Suggest hyperparameters based on strategy\"\"\"\n",
    "        if strategy == \"grid\":\n",
    "            lr_vals = GRID_SEARCH_SPACE[\"learning_rate\"]\n",
    "            bs_vals = GRID_SEARCH_SPACE[\"per_device_train_batch_size\"]\n",
    "            wd_vals = GRID_SEARCH_SPACE[\"weight_decay\"]\n",
    "            ep_vals = GRID_SEARCH_SPACE[\"num_train_epochs\"]\n",
    "\n",
    "            trial_idx = trial.number\n",
    "            total_combos = len(lr_vals) * len(bs_vals) * len(wd_vals) * len(ep_vals)\n",
    "            if trial_idx >= total_combos:\n",
    "                raise optuna.TrialPruned()\n",
    "\n",
    "            idx = trial_idx\n",
    "            lr_idx = idx % len(lr_vals)\n",
    "            idx //= len(lr_vals)\n",
    "            bs_idx = idx % len(bs_vals)\n",
    "            idx //= len(bs_vals)\n",
    "            wd_idx = idx % len(wd_vals)\n",
    "            idx //= len(wd_vals)\n",
    "            ep_idx = idx % len(ep_vals)\n",
    "\n",
    "            return {\n",
    "                \"learning_rate\": lr_vals[lr_idx],\n",
    "                \"per_device_train_batch_size\": bs_vals[bs_idx],\n",
    "                \"weight_decay\": wd_vals[wd_idx],\n",
    "                \"num_train_epochs\": ep_vals[ep_idx],\n",
    "            }\n",
    "        else:\n",
    "            return {\n",
    "                \"learning_rate\": trial.suggest_float(\"learning_rate\", 2e-5, 5e-5, log=True),\n",
    "                \"per_device_train_batch_size\": trial.suggest_categorical(\"per_device_train_batch_size\", [8, 12, 16, 24, 32]),\n",
    "                \"weight_decay\": trial.suggest_float(\"weight_decay\", 0.0, 0.1),\n",
    "                \"num_train_epochs\": trial.suggest_int(\"num_train_epochs\", 2, 4),\n",
    "            }\n",
    "\n",
    "    def objective(trial):\n",
    "        \"\"\"Optuna objective function\"\"\"\n",
    "        strategy = trial.study.sampler.__class__.__name__\n",
    "        hparams = suggest_params(trial, \"grid\" if \"Grid\" in strategy else \"random\")\n",
    "\n",
    "        run_name = f\"trial_{trial.number}\"\n",
    "        trainer_obj, args_obj = build_trainer_for_trial(hparams, run_name)\n",
    "\n",
    "        start_time = time.time()\n",
    "        trainer_obj.train()\n",
    "        train_time = time.time() - start_time\n",
    "\n",
    "        eval_results = trainer_obj.evaluate()\n",
    "        f1_macro = eval_results.get(\"eval_f1_macro\", 0.0)\n",
    "\n",
    "\n",
    "        del trainer_obj\n",
    "        gc.collect()\n",
    "        if torch.cuda.is_available():\n",
    "            torch.cuda.empty_cache()\n",
    "\n",
    "        trial.set_user_attr(\"train_time\", train_time)\n",
    "        trial.set_user_attr(\"accuracy\", eval_results.get(\"eval_accuracy\", 0.0))\n",
    "        trial.set_user_attr(\"precision\", eval_results.get(\"eval_precision\", 0.0))\n",
    "        trial.set_user_attr(\"recall\", eval_results.get(\"eval_recall\", 0.0))\n",
    "\n",
    "        return f1_macro\n",
    "\n",
    "    SEARCH_STRATEGIES = [\"grid\", \"random\"] if AUTO_TUNE_ENABLED else []\n",
    "    summary_rows = []\n",
    "\n",
    "    for strategy in SEARCH_STRATEGIES:\n",
    "        print(f\"\\n=== Hyperparameter search: {strategy.upper()} ===\")\n",
    "\n",
    "        if strategy == \"grid\":\n",
    "            sampler = GridSampler(GRID_SEARCH_SPACE)\n",
    "            study = optuna.create_study(direction=\"maximize\", sampler=sampler)\n",
    "\n",
    "            total_trials = (len(GRID_SEARCH_SPACE[\"learning_rate\"]) *\n",
    "                          len(GRID_SEARCH_SPACE[\"per_device_train_batch_size\"]) *\n",
    "                          len(GRID_SEARCH_SPACE[\"weight_decay\"]) *\n",
    "                          len(GRID_SEARCH_SPACE[\"num_train_epochs\"]))\n",
    "            study.optimize(objective, n_trials=total_trials, show_progress_bar=True)\n",
    "        else:\n",
    "            sampler = RandomSampler(seed=RANDOM_SEED)\n",
    "            study = optuna.create_study(direction=\"maximize\", sampler=sampler)\n",
    "            study.optimize(objective, n_trials=RANDOM_TRIALS, show_progress_bar=True)\n",
    "\n",
    "        trials_df = pd.DataFrame([\n",
    "            {\n",
    "                \"trial\": t.number,\n",
    "                \"f1_macro\": t.value,\n",
    "                \"learning_rate\": t.params.get(\"learning_rate\"),\n",
    "                \"batch_size\": t.params.get(\"per_device_train_batch_size\"),\n",
    "                \"weight_decay\": t.params.get(\"weight_decay\"),\n",
    "                \"epochs\": t.params.get(\"num_train_epochs\"),\n",
    "                \"accuracy\": t.user_attrs.get(\"accuracy\", 0),\n",
    "                \"precision\": t.user_attrs.get(\"precision\", 0),\n",
    "                \"recall\": t.user_attrs.get(\"recall\", 0),\n",
    "                \"train_time\": t.user_attrs.get(\"train_time\", 0),\n",
    "            }\n",
    "            for t in study.trials if t.value is not None\n",
    "        ])\n",
    "\n",
    "        trials_df.to_csv(TUNING_DIR / f\"{strategy}_trials.csv\", index=False)\n",
    "        print(f\"Saved {strategy} trials to {TUNING_DIR / f'{strategy}_trials.csv'}\")\n",
    "\n",
    "        if study.best_trial:\n",
    "            best_hparams = study.best_trial.params\n",
    "            print(f\"\\nBest {strategy} trial: F1-macro = {study.best_trial.value:.4f}\")\n",
    "            print(f\"Best params: {best_hparams}\")\n",
    "\n",
    "            print(f\"\\nRetraining with best {strategy} configuration...\")\n",
    "            best_trainer, _ = build_trainer_for_trial(best_hparams, f\"best_{strategy}\")\n",
    "            best_trainer.train()\n",
    "\n",
    "            val_results = best_trainer.evaluate()\n",
    "            test_results = best_trainer.evaluate(eval_dataset=ds_test)\n",
    "\n",
    "            best_ckpt_dir = f\"./checkpoints/bert-base/best_{strategy}\"\n",
    "            best_trainer.save_model(best_ckpt_dir)\n",
    "            tokenizer.save_pretrained(best_ckpt_dir)\n",
    "\n",
    "            summary_rows.append({\n",
    "                \"strategy\": strategy,\n",
    "                \"f1_macro_val\": val_results.get(\"eval_f1_macro\", 0),\n",
    "                \"f1_macro_test\": test_results.get(\"eval_f1_macro\", 0),\n",
    "                \"accuracy_val\": val_results.get(\"eval_accuracy\", 0),\n",
    "                \"accuracy_test\": test_results.get(\"eval_accuracy\", 0),\n",
    "                \"best_params\": str(best_hparams),\n",
    "            })\n",
    "\n",
    "            row = {\n",
    "                \"member\": f\"bert-{strategy}\",\n",
    "                \"model\": MODEL_NAME,\n",
    "                \"num_train_epochs\": best_hparams.get(\"num_train_epochs\"),\n",
    "                \"per_device_train_batch_size\": best_hparams.get(\"per_device_train_batch_size\"),\n",
    "                \"learning_rate\": best_hparams.get(\"learning_rate\"),\n",
    "                \"weight_decay\": best_hparams.get(\"weight_decay\"),\n",
    "                \"warmup_steps\": None,\n",
    "                \"lr_scheduler_type\": \"linear\",\n",
    "                \"gradient_accumulation_steps\": 1,\n",
    "                \"max_seq_length\": MAX_LEN,\n",
    "                \"seed\": RANDOM_SEED,\n",
    "                \"fp16\": USE_FP16,\n",
    "                \"accuracy\": test_results.get(\"eval_accuracy\", 0),\n",
    "                \"precision\": test_results.get(\"eval_precision\", 0),\n",
    "                \"recall\": test_results.get(\"eval_recall\", 0),\n",
    "                \"f1_macro\": test_results.get(\"eval_f1_macro\", 0),\n",
    "                \"notes\": f\"Best {strategy} search. Params: {best_hparams}\",\n",
    "            }\n",
    "            pd.DataFrame([row]).to_csv(\"runs_log.csv\", mode=\"a\", index=False,\n",
    "                                     header=not os.path.exists(\"runs_log.csv\"))\n",
    "\n",
    "    if summary_rows:\n",
    "        summary_df = pd.DataFrame(summary_rows)\n",
    "        summary_df.to_csv(TUNING_DIR / \"strategy_summary.csv\", index=False)\n",
    "        print(f\"\\n✓ Saved strategy summary to {TUNING_DIR / 'strategy_summary.csv'}\")\n",
    "        print(summary_df)\n",
    "\n",
    "    AUTO_TUNE_ENABLED = False  # Disable for subsequent cells\n",
    "else:\n",
    "    print(\"AUTO_TUNE_ENABLED is False. Skipping hyperparameter tuning.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gTcHpK2meWYz"
   },
   "source": [
    "# **BERT Fine-tuning and Training**\n",
    "\n",
    "**`Purpose`**\n",
    "\n",
    "Train the BERT model per proposal Section V.D with either default hyperparameters or the best configuration from automated hyperparameter tuning. This block performs the actual fine-tuning of the BERT-base-uncased transformer model for toxicity classification, converting the pre-trained transformer into a task-specific classifier.\n",
    "\n",
    "**`Input`**\n",
    "\n",
    "Uses the tokenized datasets (`ds_train`, `ds_val`), the initialized BERT model and tokenizer, and training arguments configured in previous cells. If hyperparameter tuning was enabled, the best configuration from grid or random search is used; otherwise, default parameters are applied.\n",
    "\n",
    "**`Output`**\n",
    "\n",
    "Prints validation metrics (accuracy, precision, recall, F1-macro) after training and saves the best model checkpoint to `checkpoints/bert-base/best/` directory. The saved checkpoint includes model weights, tokenizer files, and configuration, enabling later evaluation and deployment.\n",
    "\n",
    "**`Details`**\n",
    "\n",
    "The fine-tuning process follows the proposal methodology: tokenization using BERT's WordPiece tokenizer, conversion of tweets to input IDs and attention masks, fine-tuning with a classification head for sentiment labeling, using AdamW optimizer with cross-entropy loss and linear warmup scheduler. Early stopping prevents overfitting by monitoring validation F1-macro. If tuning was skipped, trains with default parameters; otherwise, uses the best configuration identified during hyperparameter search.\n",
    "\n",
    "**`Line-by-line Description.`**\n",
    "\n",
    "`if not AUTO_TUNE_ENABLED or not os.path.exists(\"./checkpoints/bert-base/best_grid\"):` checks whether hyperparameter tuning was disabled or no best grid checkpoint exists, determining whether to train with default parameters or use tuned configuration.\n",
    "\n",
    "`print(\"Training BERT model with default/configured parameters...\")` and subsequent print statements provide user feedback about the training process and methodology being followed.\n",
    "\n",
    "`trainer.train()` initiates the fine-tuning process, iterating through the training dataset with the configured hyperparameters, optimizer (AdamW), loss function (cross-entropy), and learning rate scheduler (linear warmup).\n",
    "\n",
    "`val_results = trainer.evaluate()` runs evaluation on the validation dataset after training completes, computing accuracy, precision, recall, and F1-macro using the `compute_metrics` function defined earlier.\n",
    "\n",
    "`print(f\"  Accuracy: {val_results.get('eval_accuracy', 0):.4f}\")` and similar print statements display validation performance metrics formatted to four decimal places for easy reading.\n",
    "\n",
    "`best_ckpt_dir = \"./checkpoints/bert-base/best\"` sets the checkpoint directory path where the best model will be saved.\n",
    "\n",
    "`trainer.save_model(best_ckpt_dir)` saves the trained model weights, configuration, and tokenizer files to the checkpoint directory, enabling later loading for evaluation or deployment.\n",
    "\n",
    "`tokenizer.save_pretrained(best_ckpt_dir)` saves the BERT tokenizer files (vocab, config) alongside the model so the complete pipeline can be restored.\n",
    "\n",
    "`else: print(\"Using best model from hyperparameter tuning.\")` handles the case where a tuned model checkpoint already exists, skipping training and using the pre-trained checkpoint instead.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 558
    },
    "id": "IBmExTtneWYz",
    "outputId": "21717b01-37e3-42bf-d2dd-29d48aa00238"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training BERT model with default/configured parameters...\n",
      "Fine-tuning process per proposal Section V.D:\n",
      "  - Tokenization using BERT's WordPiece tokenizer\n",
      "  - Convert tweets to input IDs and attention masks\n",
      "  - Fine-tune with classification head for sentiment labeling\n",
      "  - Optimizer: AdamW, Loss: Cross-entropy, Scheduler: Linear warmup\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='700' max='783' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [700/783 03:10 < 00:22, 3.66 it/s, Epoch 2/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.969300</td>\n",
       "      <td>0.902755</td>\n",
       "      <td>0.598743</td>\n",
       "      <td>0.608631</td>\n",
       "      <td>0.592695</td>\n",
       "      <td>0.598071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.831600</td>\n",
       "      <td>0.809114</td>\n",
       "      <td>0.659336</td>\n",
       "      <td>0.689359</td>\n",
       "      <td>0.645769</td>\n",
       "      <td>0.656110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.712400</td>\n",
       "      <td>0.840141</td>\n",
       "      <td>0.661355</td>\n",
       "      <td>0.676250</td>\n",
       "      <td>0.657057</td>\n",
       "      <td>0.663340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.702400</td>\n",
       "      <td>0.815131</td>\n",
       "      <td>0.659785</td>\n",
       "      <td>0.672662</td>\n",
       "      <td>0.656397</td>\n",
       "      <td>0.662081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.720500</td>\n",
       "      <td>0.806869</td>\n",
       "      <td>0.662926</td>\n",
       "      <td>0.676182</td>\n",
       "      <td>0.659080</td>\n",
       "      <td>0.664945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.599000</td>\n",
       "      <td>0.848802</td>\n",
       "      <td>0.662029</td>\n",
       "      <td>0.671106</td>\n",
       "      <td>0.658562</td>\n",
       "      <td>0.663132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>0.572900</td>\n",
       "      <td>0.847344</td>\n",
       "      <td>0.661580</td>\n",
       "      <td>0.675217</td>\n",
       "      <td>0.655634</td>\n",
       "      <td>0.662122</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='70' max='70' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [70/70 00:07]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation Results:\n",
      "  Accuracy: 0.6593\n",
      "  Precision: 0.6894\n",
      "  Recall: 0.6458\n",
      "  F1-macro: 0.6561\n",
      "\n",
      "✓ Best model saved to ./checkpoints/bert-base/best\n"
     ]
    }
   ],
   "source": [
    "if not AUTO_TUNE_ENABLED or not os.path.exists(\"./checkpoints/bert-base/best_grid\"):\n",
    "    print(\"Training BERT model with default/configured parameters...\")\n",
    "    print(\"Fine-tuning process per proposal Section V.D:\")\n",
    "    print(\"  - Tokenization using BERT's WordPiece tokenizer\")\n",
    "    print(\"  - Convert tweets to input IDs and attention masks\")\n",
    "    print(\"  - Fine-tune with classification head for sentiment labeling\")\n",
    "    print(\"  - Optimizer: AdamW, Loss: Cross-entropy, Scheduler: Linear warmup\")\n",
    "\n",
    "    trainer.train()\n",
    "\n",
    "    val_results = trainer.evaluate()\n",
    "    print(\"\\nValidation Results:\")\n",
    "    print(f\"  Accuracy: {val_results.get('eval_accuracy', 0):.4f}\")\n",
    "    print(f\"  Precision: {val_results.get('eval_precision', 0):.4f}\")\n",
    "    print(f\"  Recall: {val_results.get('eval_recall', 0):.4f}\")\n",
    "    print(f\"  F1-macro: {val_results.get('eval_f1_macro', 0):.4f}\")\n",
    "\n",
    "    best_ckpt_dir = \"./checkpoints/bert-base/best\"\n",
    "    trainer.save_model(best_ckpt_dir)\n",
    "    tokenizer.save_pretrained(best_ckpt_dir)\n",
    "    print(f\"\\n✓ Best model saved to {best_ckpt_dir}\")\n",
    "else:\n",
    "    print(\"Using best model from hyperparameter tuning.\")\n",
    "    best_ckpt_dir = \"./checkpoints/bert-base/best_grid\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PpyBQN-ceWY0"
   },
   "source": [
    "# **Model Evaluation and Baseline Comparison**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "baseline_val_eval_md"
   },
   "source": [
    "# Baseline Evaluation on Validation Set\n",
    "\n",
    "**`Purpose`**\n",
    "\n",
    "Evaluate the baseline TF-IDF + Logistic Regression model on the validation set per proposal Section VI.A before test set evaluation. This ensures consistency in evaluation methodology and provides a validation baseline for comparison with BERT model performance, allowing detection of overfitting or dataset-specific issues.\n",
    "\n",
    "**`Input`**\n",
    "\n",
    "Uses the trained baseline model (`best_baseline_model`), TF-IDF vectorizer, and validation dataset (`df_val` with `X_va` and `y_va`). The model should be loaded from previous training cells or from saved checkpoints in the `models/` directory.\n",
    "\n",
    "**`Output`**\n",
    "\n",
    "Prints validation set performance metrics (accuracy, precision, recall, F1-macro) and a detailed classification report. Generates and saves a confusion matrix visualization to `exports/confusion_matrices/baseline_cm_val.png`. These outputs provide validation performance baseline for comparison with test set results and BERT model metrics.\n",
    "\n",
    "**`Details`**\n",
    "\n",
    "Transforms validation text using the fitted TF-IDF vectorizer, generates predictions and probability scores from the baseline Logistic Regression model. Computes classification metrics including per-class precision, recall, and F1-score, and macro-averaged metrics as specified in proposal Section VI.A. Creates a confusion matrix visualization showing true vs predicted labels across all three classes (negative/toxic, neutral, positive) to identify classification patterns and error distributions.\n",
    "\n",
    "**`Line-by-line Description.`**\n",
    "\n",
    "`print(\"Evaluating baseline model on validation set...\")` provides user feedback indicating that validation evaluation is starting.\n",
    "\n",
    "`X_val_tfidf = tfidf.transform(X_va)` transforms the validation text data using the pre-fitted TF-IDF vectorizer, converting raw text into sparse numerical feature vectors.\n",
    "\n",
    "`val_preds_baseline = best_baseline_model.predict(X_val_tfidf)` generates class predictions for each validation sample using the trained Logistic Regression model.\n",
    "\n",
    "`val_probs_baseline = best_baseline_model.predict_proba(X_val_tfidf)` computes probability distributions over all three classes for each validation sample, enabling confidence analysis.\n",
    "\n",
    "`val_acc_baseline = accuracy_score(y_va, val_preds_baseline)` calculates the proportion of correctly classified samples (accuracy metric).\n",
    "\n",
    "`val_prec_baseline = precision_score(y_va, val_preds_baseline, average='macro', zero_division=0)` computes macro-averaged precision across all classes, treating each class equally.\n",
    "\n",
    "`val_rec_baseline = recall_score(y_va, val_preds_baseline, average='macro', zero_division=0)` computes macro-averaged recall across all classes, measuring the model's ability to find positive cases.\n",
    "\n",
    "`val_f1_baseline = f1_score(y_va, val_preds_baseline, average='macro', zero_division=0)` computes macro-averaged F1-score, the harmonic mean of precision and recall, as the primary performance metric.\n",
    "\n",
    "`print(f\"  Accuracy: {val_acc_baseline:.4f}\")` and subsequent print statements display formatted validation metrics with four decimal places.\n",
    "\n",
    "`print(classification_report(y_va, val_preds_baseline, ...))` generates a detailed per-class classification report showing precision, recall, F1-score, and support for each sentiment class.\n",
    "\n",
    "`cm_val_baseline = confusion_matrix(y_va, val_preds_baseline, labels=[-1, 0, 1])` creates a confusion matrix showing the count of true vs predicted labels for all three classes.\n",
    "\n",
    "`fig, ax = plt.subplots(figsize=(6, 5))` creates a matplotlib figure and axes for plotting the confusion matrix.\n",
    "\n",
    "`ConfusionMatrixDisplay(cm_val_baseline, display_labels=[...]).plot(ax=ax, colorbar=False)` visualizes the confusion matrix with color-coded cells showing prediction accuracy patterns.\n",
    "\n",
    "`plt.savefig('exports/confusion_matrices/baseline_cm_val.png', dpi=150)` saves the confusion matrix visualization to disk with high resolution for inclusion in reports."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "baseline_val_eval_code",
    "outputId": "c27415d7-f51a-4494-85ff-0e6fd7639bd3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using models from previous cell...\n",
      "Evaluating baseline model on validation set...\n",
      "\n",
      "Baseline Model Performance (Validation Set):\n",
      "  Accuracy: 0.6364\n",
      "  Precision: 0.6419\n",
      "  Recall: 0.6337\n",
      "  F1-macro: 0.6369\n",
      "\n",
      "Validation Set Classification Report:\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "negative/toxic       0.63      0.56      0.59      1288\n",
      "       neutral       0.59      0.64      0.62      1764\n",
      "      positive       0.71      0.69      0.70      1404\n",
      "\n",
      "      accuracy                           0.64      4456\n",
      "     macro avg       0.64      0.63      0.64      4456\n",
      "  weighted avg       0.64      0.64      0.64      4456\n",
      "\n",
      "\n",
      "✓ Validation confusion matrix saved to exports/confusion_matrices/baseline_cm_val.png\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    _ = tfidf\n",
    "    _ = logreg\n",
    "    print(\"Using models from previous cell...\")\n",
    "except NameError:\n",
    "    import joblib\n",
    "    import os\n",
    "    model_path = \"models/baseline_tfidf_logreg.joblib\"\n",
    "    vectorizer_path = \"models/baseline_tfidf_vectorizer.joblib\"\n",
    "\n",
    "    if os.path.exists(model_path) and os.path.exists(vectorizer_path):\n",
    "        print(\"Loading baseline models from disk...\")\n",
    "        tfidf = joblib.load(vectorizer_path)\n",
    "        logreg = joblib.load(model_path)\n",
    "        print(\"✓ Models loaded successfully\")\n",
    "    else:\n",
    "        raise NameError(\n",
    "            \"Baseline models not found. Please run Cell 12 (Baseline TF-IDF + Logistic Regression training) first to train and save the models.\"\n",
    "        )\n",
    "\n",
    "print(\"Evaluating baseline model on validation set...\")\n",
    "X_val_tfidf = tfidf.transform(X_va)\n",
    "val_preds_baseline = logreg.predict(X_val_tfidf)\n",
    "val_probs_baseline = logreg.predict_proba(X_val_tfidf)\n",
    "\n",
    "val_acc_baseline = accuracy_score(y_va, val_preds_baseline)\n",
    "val_prec_baseline = precision_score(y_va, val_preds_baseline, average='macro', zero_division=0)\n",
    "val_rec_baseline = recall_score(y_va, val_preds_baseline, average='macro', zero_division=0)\n",
    "val_f1_baseline = f1_score(y_va, val_preds_baseline, average='macro', zero_division=0)\n",
    "\n",
    "print(\"\\nBaseline Model Performance (Validation Set):\")\n",
    "print(f\"  Accuracy: {val_acc_baseline:.4f}\")\n",
    "print(f\"  Precision: {val_prec_baseline:.4f}\")\n",
    "print(f\"  Recall: {val_rec_baseline:.4f}\")\n",
    "print(f\"  F1-macro: {val_f1_baseline:.4f}\")\n",
    "\n",
    "print(\"\\nValidation Set Classification Report:\")\n",
    "print(classification_report(y_va, val_preds_baseline,\n",
    "                          target_names=['negative/toxic', 'neutral', 'positive'],\n",
    "                          zero_division=0))\n",
    "\n",
    "cm_val_baseline = confusion_matrix(y_va, val_preds_baseline, labels=[-1, 0, 1])\n",
    "fig, ax = plt.subplots(figsize=(6, 5))\n",
    "ConfusionMatrixDisplay(cm_val_baseline, display_labels=['negative/toxic', 'neutral', 'positive']).plot(ax=ax, colorbar=False)\n",
    "plt.title('Baseline Model - Validation Set Confusion Matrix')\n",
    "plt.tight_layout()\n",
    "plt.savefig('exports/confusion_matrices/baseline_cm_val.png', dpi=150)\n",
    "plt.show()  # Display in notebook\n",
    "print(\"\\n✓ Validation confusion matrix saved to exports/confusion_matrices/baseline_cm_val.png\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bert_val_eval_md"
   },
   "source": [
    "# BERT Evaluation on Validation Set\n",
    "\n",
    "**`Purpose`**\n",
    "\n",
    "Evaluate the best fine-tuned BERT model on the validation set per proposal Section VI.A before test set evaluation. This assessment ensures the BERT model's validation performance, allows direct comparison with the baseline model's validation metrics, and verifies that the transformer model generalizes appropriately to unseen validation data.\n",
    "\n",
    "**`Input`**\n",
    "\n",
    "Uses the best BERT model checkpoint (from `checkpoints/bert-base/best_grid`, `best_random`, or `best`), the tokenized validation dataset (`ds_val`), training arguments, tokenizer, and compute metrics function. The model is loaded from the checkpoint directory established during training or hyperparameter tuning.\n",
    "\n",
    "**`Output`**\n",
    "\n",
    "Prints validation set performance metrics (accuracy, precision, recall, F1-macro) and a detailed classification report. Generates and saves a confusion matrix visualization to `exports/confusion_matrices/bert_cm_val.png`. These outputs enable validation performance comparison between baseline and BERT models, and verify model behavior before final test evaluation.\n",
    "\n",
    "**`Details`**\n",
    "\n",
    "Loads the best BERT checkpoint (prioritizing grid search results if available), creates a Trainer instance with the validation dataset, and runs evaluation using the same metrics computation as training. Converts BERT's internal label mapping (0, 1, 2) back to proposal format (-1, 0, 1) for consistent reporting. Generates predictions and computes confusion matrix, then visualizes classification performance across all three sentiment classes to identify strengths and weaknesses in the model's predictions.\n",
    "\n",
    "**`Line-by-line Description.`**\n",
    "\n",
    "`try: _ = best_model` attempts to access the best_model variable to check if it exists from previous cells, avoiding redundant loading.\n",
    "\n",
    "`except NameError:` handles the case where best_model doesn't exist, triggering model loading from checkpoint.\n",
    "\n",
    "`if os.path.exists(\"./checkpoints/bert-base/best_grid\"):` checks for the best grid search checkpoint first, prioritizing hyperparameter-tuned models.\n",
    "\n",
    "`best_ckpt_dir = \"./checkpoints/bert-base/best_grid\"` sets the checkpoint directory path to the grid search results.\n",
    "\n",
    "`elif os.path.exists(\"./checkpoints/bert-base/best_random\"):` falls back to random search checkpoint if grid search results aren't available.\n",
    "\n",
    "`elif os.path.exists(\"./checkpoints/bert-base/best\"):` falls back to default training checkpoint if no hyperparameter tuning was performed.\n",
    "\n",
    "`best_model = AutoModelForSequenceClassification.from_pretrained(best_ckpt_dir).to(device)` loads the trained BERT model from the checkpoint directory and moves it to the appropriate device (CPU or GPU).\n",
    "\n",
    "`best_model.eval()` sets the model to evaluation mode, disabling dropout and batch normalization updates for consistent inference behavior.\n",
    "\n",
    "`val_eval_trainer = Trainer(model=best_model, args=training_args, eval_dataset=ds_val, ...)` creates a Trainer instance configured for evaluation on the validation dataset.\n",
    "\n",
    "`val_results = val_eval_trainer.evaluate()` runs evaluation using the Trainer's built-in metrics computation, returning accuracy, precision, recall, and F1-macro.\n",
    "\n",
    "`print(f\"  Accuracy: {val_results.get('eval_accuracy', 0):.4f}\")` and similar print statements display formatted validation metrics.\n",
    "\n",
    "`val_predictions = val_eval_trainer.predict(ds_val)` generates raw model predictions (logits) for all validation samples.\n",
    "\n",
    "`val_preds_bert = np.argmax(val_predictions.predictions, axis=1)` extracts predicted class indices by finding the maximum logit value for each sample.\n",
    "\n",
    "`reverse_mapping = {0: -1, 1: 0, 2: 1}` defines the mapping to convert BERT's internal label encoding (0,1,2) back to proposal format (-1,0,1).\n",
    "\n",
    "`val_preds = np.array([reverse_mapping[p] for p in val_preds_bert])` converts predicted labels from BERT format to proposal format for consistent reporting.\n",
    "\n",
    "`val_labels = np.array([reverse_mapping[l] for l in val_labels_bert])` converts true labels from BERT format to proposal format.\n",
    "\n",
    "`print(classification_report(val_labels, val_preds, ...))` generates a detailed per-class classification report with proposal-format labels.\n",
    "\n",
    "`cm_val_bert = confusion_matrix(val_labels, val_preds, labels=[-1, 0, 1])` creates a confusion matrix using proposal-format labels.\n",
    "\n",
    "`ConfusionMatrixDisplay(cm_val_bert, ...).plot(ax=ax, colorbar=False)` visualizes the confusion matrix with class names matching the proposal format.\n",
    "\n",
    "`plt.savefig('exports/confusion_matrices/bert_cm_val.png', dpi=150)` saves the confusion matrix visualization to disk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 451
    },
    "id": "bert_val_eval_code",
    "outputId": "78bf97f9-2f1b-4071-ac23-09feda5db95a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded from ./checkpoints/bert-base/best_grid\n",
      "\n",
      "Evaluating BERT model on validation set...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipython-input-326517354.py:25: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  val_eval_trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "BERT Model Performance (Validation Set):\n",
      "  Accuracy: 0.6719\n",
      "  Precision: 0.6894\n",
      "  Recall: 0.6631\n",
      "  F1-macro: 0.6705\n",
      "\n",
      "Validation Set Classification Report:\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "negative/toxic       0.72      0.56      0.63      1288\n",
      "       neutral       0.61      0.74      0.67      1764\n",
      "      positive       0.74      0.69      0.71      1404\n",
      "\n",
      "      accuracy                           0.67      4456\n",
      "     macro avg       0.69      0.66      0.67      4456\n",
      "  weighted avg       0.68      0.67      0.67      4456\n",
      "\n",
      "\n",
      "✓ Validation confusion matrix saved to exports/confusion_matrices/bert_cm_val.png\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    _ = best_model\n",
    "    _ = best_ckpt_dir\n",
    "    print(\"Using model from previous cells...\")\n",
    "except NameError:\n",
    "    from transformers import AutoModelForSequenceClassification\n",
    "    from pathlib import Path\n",
    "    import os\n",
    "\n",
    "    if os.path.exists(\"./checkpoints/bert-base/best_grid\"):\n",
    "        best_ckpt_dir = \"./checkpoints/bert-base/best_grid\"\n",
    "    elif os.path.exists(\"./checkpoints/bert-base/best_random\"):\n",
    "        best_ckpt_dir = \"./checkpoints/bert-base/best_random\"\n",
    "    elif os.path.exists(\"./checkpoints/bert-base/best\"):\n",
    "        best_ckpt_dir = \"./checkpoints/bert-base/best\"\n",
    "    else:\n",
    "        raise FileNotFoundError(\"No checkpoint directory found. Please run training first.\")\n",
    "\n",
    "    best_model = AutoModelForSequenceClassification.from_pretrained(best_ckpt_dir).to(device)\n",
    "    best_model.eval()\n",
    "    print(f\"Model loaded from {best_ckpt_dir}\")\n",
    "\n",
    "print(\"\\nEvaluating BERT model on validation set...\")\n",
    "\n",
    "val_eval_trainer = Trainer(\n",
    "    model=best_model,\n",
    "    args=training_args,\n",
    "    eval_dataset=ds_val,\n",
    "    compute_metrics=compute_metrics,\n",
    "    tokenizer=tokenizer,\n",
    ")\n",
    "\n",
    "val_results = val_eval_trainer.evaluate()\n",
    "\n",
    "print(\"\\nBERT Model Performance (Validation Set):\")\n",
    "print(f\"  Accuracy: {val_results.get('eval_accuracy', 0):.4f}\")\n",
    "print(f\"  Precision: {val_results.get('eval_precision', 0):.4f}\")\n",
    "print(f\"  Recall: {val_results.get('eval_recall', 0):.4f}\")\n",
    "print(f\"  F1-macro: {val_results.get('eval_f1_macro', 0):.4f}\")\n",
    "\n",
    "val_predictions = val_eval_trainer.predict(ds_val)\n",
    "val_preds_bert = np.argmax(val_predictions.predictions, axis=1)\n",
    "val_labels_bert = val_predictions.label_ids\n",
    "\n",
    "reverse_mapping = {0: -1, 1: 0, 2: 1}\n",
    "val_preds = np.array([reverse_mapping[p] for p in val_preds_bert])\n",
    "val_labels = np.array([reverse_mapping[l] for l in val_labels_bert])\n",
    "\n",
    "print(\"\\nValidation Set Classification Report:\")\n",
    "print(classification_report(val_labels, val_preds,\n",
    "                          target_names=['negative/toxic', 'neutral', 'positive'],\n",
    "                          zero_division=0))\n",
    "\n",
    "cm_val_bert = confusion_matrix(val_labels, val_preds, labels=[-1, 0, 1])\n",
    "fig, ax = plt.subplots(figsize=(6, 5))\n",
    "ConfusionMatrixDisplay(cm_val_bert, display_labels=['negative/toxic', 'neutral', 'positive']).plot(ax=ax, colorbar=False)\n",
    "plt.title('BERT Model - Validation Set Confusion Matrix')\n",
    "plt.tight_layout()\n",
    "plt.savefig('exports/confusion_matrices/bert_cm_val.png', dpi=150)\n",
    "plt.show()  # Display in notebook\n",
    "print(\"\\n✓ Validation confusion matrix saved to exports/confusion_matrices/bert_cm_val.png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 833
    },
    "id": "hODlPM_AeWY0",
    "outputId": "5c509f69-7a0f-4cb9-cbcd-fc464f90bd0d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating BERT model on test set...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipython-input-3209552293.py:6: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  eval_trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "BERT Model Performance (Test Set) - per proposal Section VI.A:\n",
      "  Accuracy: 0.6691\n",
      "  Precision: 0.6884\n",
      "  Recall: 0.6599\n",
      "  F1-macro: 0.6679\n",
      "\n",
      "Test Set Classification Report:\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "negative/toxic       0.73      0.56      0.63      1292\n",
      "       neutral       0.60      0.74      0.66      1781\n",
      "      positive       0.73      0.68      0.71      1403\n",
      "\n",
      "      accuracy                           0.67      4476\n",
      "     macro avg       0.69      0.66      0.67      4476\n",
      "  weighted avg       0.68      0.67      0.67      4476\n",
      "\n",
      "\n",
      "✓ Confusion matrix saved to exports/confusion_matrices/bert_cm_test.png\n",
      "✓ Test predictions saved to exports/bert_predictions_test.csv\n",
      "\n",
      "negative/toxic (class -1):\n",
      "  ROC-AUC: 0.8299\n",
      "  PR-AUC: 0.7159\n",
      "\n",
      "neutral (class 0):\n",
      "  ROC-AUC: 0.7678\n",
      "  PR-AUC: 0.6500\n",
      "\n",
      "positive (class 1):\n",
      "  ROC-AUC: 0.8601\n",
      "  PR-AUC: 0.7787\n",
      "\n",
      "✓ ROC and PR curves saved to exports/roc_curves/bert_roc_pr_curves.png\n",
      "\n",
      "============================================================\n",
      "Baseline vs BERT Comparison (per proposal Section VI.B)\n",
      "============================================================\n",
      "                     Model  Accuracy  Precision   Recall  F1-macro\n",
      "Baseline (TF-IDF + LogReg)  0.622431   0.629367 0.619691  0.623378\n",
      "         BERT-base-uncased  0.669124   0.688382 0.659928  0.667874\n",
      "\n",
      "✓ Model comparison saved to exports/model_comparison.csv\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSequenceClassification\n",
    "\n",
    "best_model = AutoModelForSequenceClassification.from_pretrained(best_ckpt_dir).to(device)\n",
    "best_model.eval()\n",
    "\n",
    "eval_trainer = Trainer(\n",
    "    model=best_model,\n",
    "    args=training_args,\n",
    "    eval_dataset=ds_test,\n",
    "    compute_metrics=compute_metrics,\n",
    "    tokenizer=tokenizer,\n",
    ")\n",
    "\n",
    "print(\"Evaluating BERT model on test set...\")\n",
    "test_results = eval_trainer.evaluate()\n",
    "\n",
    "print(\"\\nBERT Model Performance (Test Set) - per proposal Section VI.A:\")\n",
    "print(f\"  Accuracy: {test_results.get('eval_accuracy', 0):.4f}\")\n",
    "print(f\"  Precision: {test_results.get('eval_precision', 0):.4f}\")\n",
    "print(f\"  Recall: {test_results.get('eval_recall', 0):.4f}\")\n",
    "print(f\"  F1-macro: {test_results.get('eval_f1_macro', 0):.4f}\")\n",
    "\n",
    "test_predictions = eval_trainer.predict(ds_test)\n",
    "test_preds_bert = np.argmax(test_predictions.predictions, axis=1)\n",
    "test_labels_bert = test_predictions.label_ids\n",
    "\n",
    "reverse_mapping = {0: -1, 1: 0, 2: 1}\n",
    "test_preds = np.array([reverse_mapping[p] for p in test_preds_bert])\n",
    "test_labels = np.array([reverse_mapping[l] for l in test_labels_bert])\n",
    "\n",
    "print(\"\\nTest Set Classification Report:\")\n",
    "print(classification_report(test_labels, test_preds,\n",
    "                          target_names=['negative/toxic', 'neutral', 'positive'],\n",
    "                          zero_division=0))\n",
    "\n",
    "cm_bert = confusion_matrix(test_labels, test_preds, labels=[-1, 0, 1])\n",
    "fig, ax = plt.subplots(figsize=(6, 5))\n",
    "ConfusionMatrixDisplay(cm_bert, display_labels=['negative/toxic', 'neutral', 'positive']).plot(ax=ax, colorbar=False)\n",
    "plt.title('BERT Model - Test Set Confusion Matrix')\n",
    "plt.tight_layout()\n",
    "plt.savefig('exports/confusion_matrices/bert_cm_test.png', dpi=150)\n",
    "plt.show()  # Display in notebook\n",
    "print(\"\\n✓ Confusion matrix saved to exports/confusion_matrices/bert_cm_test.png\")\n",
    "\n",
    "test_df_results = pd.DataFrame({\n",
    "    'review': df_test['review'].tolist(),\n",
    "    'gold': test_labels,\n",
    "    'pred': test_preds\n",
    "})\n",
    "test_df_results.to_csv('exports/bert_predictions_test.csv', index=False)\n",
    "print(\"✓ Test predictions saved to exports/bert_predictions_test.csv\")\n",
    "\n",
    "from sklearn.metrics import roc_curve, auc, precision_recall_curve, roc_auc_score, average_precision_score\n",
    "from sklearn.preprocessing import label_binarize\n",
    "\n",
    "y_test_bin = label_binarize(test_labels, classes=[-1, 0, 1])\n",
    "n_classes = 3\n",
    "test_probs = torch.softmax(torch.tensor(test_predictions.predictions), dim=-1).numpy()\n",
    "\n",
    "fpr = dict()\n",
    "tpr = dict()\n",
    "roc_auc = dict()\n",
    "precision = dict()\n",
    "recall = dict()\n",
    "pr_auc = dict()\n",
    "\n",
    "bert_to_proposal = {0: 0, 1: 1, 2: 2}\n",
    "for i, class_name in enumerate(['negative/toxic', 'neutral', 'positive']):\n",
    "    class_idx = [-1, 0, 1][i]\n",
    "    bert_idx = {-1: 0, 0: 1, 1: 2}[class_idx]\n",
    "    y_true_class = (test_labels == class_idx).astype(int)\n",
    "    y_score_class = test_probs[:, bert_idx]\n",
    "\n",
    "    fpr[i], tpr[i], _ = roc_curve(y_true_class, y_score_class)\n",
    "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "    precision[i], recall[i], _ = precision_recall_curve(y_true_class, y_score_class)\n",
    "    pr_auc[i] = average_precision_score(y_true_class, y_score_class)\n",
    "\n",
    "    print(f\"\\n{class_name} (class {class_idx}):\")\n",
    "    print(f\"  ROC-AUC: {roc_auc[i]:.4f}\")\n",
    "    print(f\"  PR-AUC: {pr_auc[i]:.4f}\")\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "ax = axes[0]\n",
    "for i, class_name in enumerate(['negative/toxic', 'neutral', 'positive']):\n",
    "    ax.plot(fpr[i], tpr[i], label=f'{class_name} (AUC = {roc_auc[i]:.3f})')\n",
    "ax.plot([0, 1], [0, 1], 'k--', label='Random')\n",
    "ax.set_xlabel('False Positive Rate')\n",
    "ax.set_ylabel('True Positive Rate')\n",
    "ax.set_title('ROC Curves (per proposal Section III)')\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "ax = axes[1]\n",
    "for i, class_name in enumerate(['negative/toxic', 'neutral', 'positive']):\n",
    "    ax.plot(recall[i], precision[i], label=f'{class_name} (AP = {pr_auc[i]:.3f})')\n",
    "ax.set_xlabel('Recall')\n",
    "ax.set_ylabel('Precision')\n",
    "ax.set_title('Precision-Recall Curves (per proposal Section III)')\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "os.makedirs(\"exports/roc_curves\", exist_ok=True)\n",
    "plt.savefig('exports/roc_curves/bert_roc_pr_curves.png', dpi=150)\n",
    "plt.show()  # Display in notebook\n",
    "print(\"\\n✓ ROC and PR curves saved to exports/roc_curves/bert_roc_pr_curves.png\")\n",
    "\n",
    "comparison_df = pd.DataFrame({\n",
    "    'Model': ['Baseline (TF-IDF + LogReg)', 'BERT-base-uncased'],\n",
    "    'Accuracy': [test_acc, test_results.get('eval_accuracy', 0)],\n",
    "    'Precision': [test_prec, test_results.get('eval_precision', 0)],\n",
    "    'Recall': [test_rec, test_results.get('eval_recall', 0)],\n",
    "    'F1-macro': [test_f1, test_results.get('eval_f1_macro', 0)],\n",
    "})\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Baseline vs BERT Comparison (per proposal Section VI.B)\")\n",
    "print(\"=\"*60)\n",
    "print(comparison_df.to_string(index=False))\n",
    "comparison_df.to_csv('exports/model_comparison.csv', index=False)\n",
    "print(\"\\n✓ Model comparison saved to exports/model_comparison.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "val_test_comparison_md"
   },
   "source": [
    "# Validation vs Test Set Comparison\n",
    "\n",
    "**`Purpose`**\n",
    "\n",
    "Compare model performance between validation and test sets per proposal Section VI.A to detect overfitting and ensure generalization capability. This analysis validates that both baseline and BERT models maintain consistent performance across validation and test splits, confirming that training hyperparameters did not overfit to validation data.\n",
    "\n",
    "**`Input`**\n",
    "\n",
    "Uses validation and test set performance metrics from both baseline and BERT models, including accuracy, precision, recall, and F1-macro scores. Requires that validation evaluation (baseline and BERT) and test evaluation (baseline and BERT) cells have been executed previously.\n",
    "\n",
    "**`Output`**\n",
    "\n",
    "Prints a comprehensive comparison table showing validation vs test metrics for both models, including performance differences. Saves a CSV comparison table to `exports/val_test_comparison.csv` and generates a multi-panel visualization (bar charts comparing validation vs test performance for each metric) saved to `exports/val_test_comparison.png`. These outputs enable detection of overfitting and provide visual evidence of model generalization.\n",
    "\n",
    "**`Details`**\n",
    "\n",
    "Compares four metric sets: baseline validation, baseline test, BERT validation, and BERT test. Computes absolute differences between validation and test metrics to identify significant performance gaps that may indicate overfitting. Creates a structured DataFrame with all metrics for both models across both splits, then visualizes the comparison using grouped bar charts for each metric (accuracy, precision, recall, F1-macro) to highlight performance consistency or discrepancies between validation and test evaluations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "val_test_comparison_code",
    "outputId": "20180267-f8be-4966-a9de-d00d36dd9948"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "Validation vs Test Set Performance Comparison\n",
      "======================================================================\n",
      "\n",
      "Baseline Model (TF-IDF + Logistic Regression):\n",
      "  Validation - Accuracy: 0.6364, F1-macro: 0.6369\n",
      "  Test       - Accuracy: 0.6224, F1-macro: 0.6234\n",
      "  Difference - Accuracy: 0.0140, F1-macro: 0.0135\n",
      "\n",
      "BERT Model (bert-base-uncased):\n",
      "  Validation - Accuracy: 0.6719, F1-macro: 0.6705\n",
      "  Test       - Accuracy: 0.6691, F1-macro: 0.6679\n",
      "  Difference - Accuracy: 0.0028, F1-macro: 0.0026\n",
      "\n",
      "✓ Validation vs Test comparison saved to exports/val_test_comparison.csv\n",
      "✓ Validation vs Test comparison visualization saved to exports/val_test_comparison.png\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"=\"*70)\n",
    "print(\"Validation vs Test Set Performance Comparison\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(\"\\nBaseline Model (TF-IDF + Logistic Regression):\")\n",
    "print(f\"  Validation - Accuracy: {val_acc_baseline:.4f}, F1-macro: {val_f1_baseline:.4f}\")\n",
    "try:\n",
    "    print(f\"  Test       - Accuracy: {test_acc:.4f}, F1-macro: {test_f1:.4f}\")\n",
    "    print(f\"  Difference - Accuracy: {abs(val_acc_baseline - test_acc):.4f}, F1-macro: {abs(val_f1_baseline - test_f1):.4f}\")\n",
    "except NameError:\n",
    "    print(\"  Test results not yet available. Run test evaluation cell first.\")\n",
    "\n",
    "print(\"\\nBERT Model (bert-base-uncased):\")\n",
    "print(f\"  Validation - Accuracy: {val_results.get('eval_accuracy', 0):.4f}, F1-macro: {val_results.get('eval_f1_macro', 0):.4f}\")\n",
    "try:\n",
    "    print(f\"  Test       - Accuracy: {test_results.get('eval_accuracy', 0):.4f}, F1-macro: {test_results.get('eval_f1_macro', 0):.4f}\")\n",
    "    val_test_diff_acc = abs(val_results.get('eval_accuracy', 0) - test_results.get('eval_accuracy', 0))\n",
    "    val_test_diff_f1 = abs(val_results.get('eval_f1_macro', 0) - test_results.get('eval_f1_macro', 0))\n",
    "    print(f\"  Difference - Accuracy: {val_test_diff_acc:.4f}, F1-macro: {val_test_diff_f1:.4f}\")\n",
    "except NameError:\n",
    "    print(\"  Test results not yet available. Run test evaluation cell first.\")\n",
    "    test_results = {'eval_accuracy': 0, 'eval_precision': 0, 'eval_recall': 0, 'eval_f1_macro': 0}\n",
    "    test_acc = 0\n",
    "    test_prec = 0\n",
    "    test_rec = 0\n",
    "    test_f1 = 0\n",
    "\n",
    "comparison_df = pd.DataFrame({\n",
    "    'Model': ['Baseline (Val)', 'Baseline (Test)', 'BERT (Val)', 'BERT (Test)'],\n",
    "    'Accuracy': [val_acc_baseline, test_acc, val_results.get('eval_accuracy', 0), test_results.get('eval_accuracy', 0)],\n",
    "    'Precision': [val_prec_baseline, test_prec, val_results.get('eval_precision', 0), test_results.get('eval_precision', 0)],\n",
    "    'Recall': [val_rec_baseline, test_rec, val_results.get('eval_recall', 0), test_results.get('eval_recall', 0)],\n",
    "    'F1-macro': [val_f1_baseline, test_f1, val_results.get('eval_f1_macro', 0), test_results.get('eval_f1_macro', 0)]\n",
    "})\n",
    "\n",
    "comparison_df.to_csv('exports/val_test_comparison.csv', index=False)\n",
    "print(\"\\n✓ Validation vs Test comparison saved to exports/val_test_comparison.csv\")\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "metrics = ['Accuracy', 'Precision', 'Recall', 'F1-macro']\n",
    "for idx, metric in enumerate(metrics):\n",
    "    ax = axes[idx // 2, idx % 2]\n",
    "    x = np.arange(2)\n",
    "    width = 0.35\n",
    "    baseline_vals = [comparison_df.iloc[0][metric], comparison_df.iloc[1][metric]]\n",
    "    bert_vals = [comparison_df.iloc[2][metric], comparison_df.iloc[3][metric]]\n",
    "    ax.bar(x - width/2, baseline_vals, width, label='Baseline', alpha=0.8)\n",
    "    ax.bar(x + width/2, bert_vals, width, label='BERT', alpha=0.8)\n",
    "    ax.set_xlabel('Dataset')\n",
    "    ax.set_ylabel(metric)\n",
    "    ax.set_title(f'{metric}: Validation vs Test')\n",
    "    ax.set_xticks(x)\n",
    "    ax.set_xticklabels(['Validation', 'Test'])\n",
    "    ax.legend()\n",
    "    ax.grid(axis='y', alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('exports/val_test_comparison.png', dpi=150)\n",
    "plt.show()  # Display in notebook\n",
    "print(\"✓ Validation vs Test comparison visualization saved to exports/val_test_comparison.png\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OxxKi6LkeWY0"
   },
   "source": [
    "# Visualization and Analysis\n",
    "\n",
    "**`Purpose`**\n",
    "\n",
    "Generate comprehensive visualization grid per proposal Section VI.B to analyze and compare model performance, classification patterns, and dataset characteristics. This block creates a unified visual analysis combining confusion matrices, metric comparisons, and class distribution to provide a holistic view of model behavior and dataset composition.\n",
    "\n",
    "**`Input`**\n",
    "\n",
    "Uses confusion matrices (`cm`, `cm_bert`) from test set evaluations, test set performance metrics for both baseline and BERT models, and test dataset class distribution. Requires that test evaluation cells for both models have been executed to populate these variables.\n",
    "\n",
    "**`Output`**\n",
    "\n",
    "Generates a 2x2 visualization grid saved to `exports/model_analysis_grid.png` containing: (1) baseline model confusion matrix, (2) BERT model confusion matrix, (3) side-by-side metric comparison bar chart, and (4) test set class distribution. This unified visualization enables quick comparison of model performance and identification of classification patterns.\n",
    "\n",
    "**`Details`**\n",
    "\n",
    "Creates a multi-panel figure with four subplots. The top row displays confusion matrices for both baseline and BERT models, showing true vs predicted label distributions for all three classes. The bottom left panel shows a grouped bar chart comparing accuracy, precision, recall, and F1-macro between baseline and BERT models on the test set. The bottom right panel visualizes the test set class distribution using colored bars. All visualizations use consistent labeling and styling for easy interpretation and comparison.\n",
    "\n",
    "**`Line-by-line Description.`**\n",
    "\n",
    "`fig, axes = plt.subplots(2, 2, figsize=(14, 12))` creates a 2x2 grid of subplots with specified figure size for the comprehensive visualization grid.\n",
    "\n",
    "`ax = axes[0, 0]` selects the top-left subplot for the baseline model confusion matrix.\n",
    "\n",
    "`ConfusionMatrixDisplay(cm, display_labels=[...]).plot(ax=ax, colorbar=False)` visualizes the baseline model's confusion matrix showing true vs predicted labels.\n",
    "\n",
    "`ax.set_title('Baseline Model - Test Set')` sets the subplot title to identify which model and dataset are displayed.\n",
    "\n",
    "`ax = axes[0, 1]` selects the top-right subplot for the BERT model confusion matrix.\n",
    "\n",
    "`ConfusionMatrixDisplay(cm_bert, display_labels=[...]).plot(ax=ax, colorbar=False)` visualizes the BERT model's confusion matrix for comparison.\n",
    "\n",
    "`ax = axes[1, 0]` selects the bottom-left subplot for the metric comparison bar chart.\n",
    "\n",
    "`metrics = ['Accuracy', 'Precision', 'Recall', 'F1-macro']` defines the list of metrics to compare between models.\n",
    "\n",
    "`baseline_vals = [test_acc, test_prec, test_rec, test_f1]` extracts baseline model test set metrics into a list for plotting.\n",
    "\n",
    "`bert_vals = [test_results.get('eval_accuracy', 0), ...]` extracts BERT model test set metrics into a list for plotting.\n",
    "\n",
    "`x = np.arange(len(metrics))` creates x-axis positions for each metric in the comparison chart.\n",
    "\n",
    "`width = 0.35` sets the bar width for grouped bars, allowing baseline and BERT bars to appear side-by-side.\n",
    "\n",
    "`ax.bar(x - width/2, baseline_vals, width, label='Baseline', alpha=0.8)` creates grouped bars for baseline metrics with left offset.\n",
    "\n",
    "`ax.bar(x + width/2, bert_vals, width, label='BERT', alpha=0.8)` creates grouped bars for BERT metrics with right offset.\n",
    "\n",
    "`ax.set_ylabel('Score')` labels the y-axis as score values.\n",
    "\n",
    "`ax.set_title('Model Comparison - Test Set Metrics')` sets the subplot title.\n",
    "\n",
    "`ax.set_xticks(x)` and `ax.set_xticklabels(metrics)` positions and labels x-axis ticks with metric names.\n",
    "\n",
    "`ax.legend()` displays the legend distinguishing baseline and BERT bars.\n",
    "\n",
    "`ax.grid(True, alpha=0.3, axis='y')` adds horizontal grid lines for easier value reading.\n",
    "\n",
    "`ax = axes[1, 1]` selects the bottom-right subplot for class distribution visualization.\n",
    "\n",
    "`label_counts = df_test['label'].value_counts().sort_index()` counts occurrences of each label in the test set and sorts by label value.\n",
    "\n",
    "`labels = ['negative/toxic', 'neutral', 'positive']` defines human-readable label names for display.\n",
    "\n",
    "`colors = ['#F87171', '#FBBF24', '#34D399']` defines color scheme (red, yellow, green) matching sentiment classes.\n",
    "\n",
    "`ax.bar(labels, [...], color=colors, alpha=0.8)` creates colored bars showing the count of each class in the test set.\n",
    "\n",
    "`ax.set_ylabel('Count')` labels the y-axis as sample count.\n",
    "\n",
    "`ax.set_title('Test Set Class Distribution')` sets the subplot title.\n",
    "\n",
    "`plt.tight_layout()` automatically adjusts subplot spacing to prevent label overlap.\n",
    "\n",
    "`plt.savefig('exports/model_analysis_grid.png', dpi=150)` saves the complete visualization grid to disk with high resolution.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LpmSLQS2eWY0",
    "outputId": "2408facb-134a-4571-9559-5667d31f53a5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Visualization grid saved to exports/model_analysis_grid.png\n"
     ]
    }
   ],
   "source": [
    "fig, axes = plt.subplots(2, 2, figsize=(14, 12))\n",
    "\n",
    "ax = axes[0, 0]\n",
    "ConfusionMatrixDisplay(cm, display_labels=['negative/toxic', 'neutral', 'positive']).plot(ax=ax, colorbar=False)\n",
    "ax.set_title('Baseline Model - Test Set')\n",
    "\n",
    "ax = axes[0, 1]\n",
    "ConfusionMatrixDisplay(cm_bert, display_labels=['negative/toxic', 'neutral', 'positive']).plot(ax=ax, colorbar=False)\n",
    "ax.set_title('BERT Model - Test Set')\n",
    "\n",
    "ax = axes[1, 0]\n",
    "metrics = ['Accuracy', 'Precision', 'Recall', 'F1-macro']\n",
    "baseline_vals = [test_acc, test_prec, test_rec, test_f1]\n",
    "bert_vals = [test_results.get('eval_accuracy', 0),\n",
    "             test_results.get('eval_precision', 0),\n",
    "             test_results.get('eval_recall', 0),\n",
    "             test_results.get('eval_f1_macro', 0)]\n",
    "\n",
    "x = np.arange(len(metrics))\n",
    "width = 0.35\n",
    "ax.bar(x - width/2, baseline_vals, width, label='Baseline', alpha=0.8)\n",
    "ax.bar(x + width/2, bert_vals, width, label='BERT', alpha=0.8)\n",
    "ax.set_ylabel('Score')\n",
    "ax.set_title('Model Comparison - Test Set Metrics')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(metrics)\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "ax = axes[1, 1]\n",
    "label_counts = df_test['label'].value_counts().sort_index()\n",
    "labels = ['negative/toxic', 'neutral', 'positive']\n",
    "colors = ['#F87171', '#FBBF24', '#34D399']\n",
    "ax.bar(labels, [label_counts.get(-1, 0), label_counts.get(0, 0), label_counts.get(1, 0)], color=colors, alpha=0.8)\n",
    "ax.set_ylabel('Count')\n",
    "ax.set_title('Test Set Class Distribution')\n",
    "ax.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('exports/model_analysis_grid.png', dpi=150)\n",
    "plt.show()  # Display in notebook\n",
    "print(\"✓ Visualization grid saved to exports/model_analysis_grid.png\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ltuostt2eWY1"
   },
   "source": [
    "# Inference Examples and Model Testing\n",
    "\n",
    "**`Purpose`**\n",
    "\n",
    "Demonstrate BERT model inference on diverse sample tweets per proposal Section III to showcase the model's capability in handling sarcasm, informal language, and subtle toxicity patterns. This block provides practical examples of real-world model predictions, showing confidence scores and probability distributions across sentiment classes for various tweet types commonly encountered in social media.\n",
    "\n",
    "**`Input`**\n",
    "\n",
    "Uses the best trained BERT model and tokenizer (loaded from checkpoint directory), and a curated set of sample tweets including toxic, neutral, positive, sarcastic/toxic, and informal positive examples. The model should be in evaluation mode and loaded onto the appropriate device (CPU or GPU).\n",
    "\n",
    "**`Output`**\n",
    "\n",
    "Prints detailed inference results for each sample tweet, including the predicted sentiment label, confidence percentage, and probability distribution across all three classes (negative/toxic, neutral, positive). The output demonstrates the model's ability to handle nuanced language patterns and provides transparency into prediction confidence and class probabilities.\n",
    "\n",
    "**`Details`**\n",
    "\n",
    "Iterates through a diverse set of sample tweets representing different linguistic challenges: explicit toxicity, neutral statements, positive sentiment, sarcastic/toxic language (where surface meaning contradicts true sentiment), and informal positive expressions with emojis and slang. For each tweet, tokenizes the input using the BERT tokenizer with truncation and padding, runs inference through the model to obtain logits, applies softmax to compute probability distributions, and extracts the predicted class along with confidence scores. Converts BERT's internal label encoding (0, 1, 2) to proposal format (-1, 0, 1) and displays human-readable predictions with probability breakdowns for transparency and interpretability.\n",
    "\n",
    "**`Line-by-line Description.`**\n",
    "\n",
    "`sample_tweets = [(...) for ...]` defines a list of tuples containing label descriptions and tweet text representing diverse linguistic challenges (toxic, neutral, positive, sarcastic, informal).\n",
    "\n",
    "`print(\"Testing BERT model on sample tweets (per proposal: handles sarcasm, informal language):\\n\")` provides context about the inference demonstration purpose.\n",
    "\n",
    "`try: _ = best_model` checks if the best_model variable exists from previous cells to avoid redundant loading.\n",
    "\n",
    "`best_model = best_model.to(device)` ensures the model is on the correct device (CPU or GPU) for inference.\n",
    "\n",
    "`best_model.eval()` sets the model to evaluation mode, disabling dropout and batch normalization updates for consistent predictions.\n",
    "\n",
    "`except NameError:` handles the case where best_model doesn't exist, triggering loading from checkpoint.\n",
    "\n",
    "`best_model = AutoModelForSequenceClassification.from_pretrained(best_ckpt_dir).to(device)` loads the trained BERT model from the checkpoint directory.\n",
    "\n",
    "`best_tokenizer = AutoTokenizer.from_pretrained(best_ckpt_dir, use_fast=True)` loads the BERT tokenizer matching the model checkpoint.\n",
    "\n",
    "`for label, tweet in sample_tweets:` iterates through each sample tweet to demonstrate inference on diverse examples.\n",
    "\n",
    "`inputs = best_tokenizer(tweet, return_tensors=\"pt\", truncation=True, padding=True, max_length=128).to(device)` tokenizes the tweet text, converting it to PyTorch tensors with truncation and padding to max length of 128 tokens, then moves to device.\n",
    "\n",
    "`with torch.no_grad():` disables gradient computation during inference to save memory and speed up prediction.\n",
    "\n",
    "`outputs = best_model(**inputs)` runs forward pass through the BERT model, generating raw logits for each class.\n",
    "\n",
    "`probs = torch.softmax(outputs.logits, dim=-1)[0].cpu().numpy()` applies softmax to convert logits to probability distribution over classes, extracts first sample, and converts to numpy array.\n",
    "\n",
    "`pred_bert = np.argmax(probs)` finds the index of the class with highest probability (BERT's internal encoding: 0, 1, 2).\n",
    "\n",
    "`bert_to_proposal = {0: -1, 1: 0, 2: 1}` defines mapping from BERT's label encoding to proposal format.\n",
    "\n",
    "`pred = bert_to_proposal[pred_bert]` converts predicted label from BERT format to proposal format (-1, 0, 1).\n",
    "\n",
    "`label_map = {-1: \"negative/toxic\", 0: \"neutral\", 1: \"positive\"}` defines human-readable label names.\n",
    "\n",
    "`pred_label = label_map.get(pred, \"unknown\")` converts predicted label value to human-readable string.\n",
    "\n",
    "`confidence = probs[pred_bert] * 100` calculates prediction confidence as percentage (probability of predicted class times 100).\n",
    "\n",
    "`prob_map = {0: -1, 1: 0, 2: 1}` defines mapping for converting probability indices to proposal format.\n",
    "\n",
    "`probs_proposal = {label_map[prob_map[i]]: float(probs[i]) for i in range(3)}` creates a dictionary mapping human-readable class names to their probabilities.\n",
    "\n",
    "`print(f\"\\n{label}:\")` prints the sample tweet category (e.g., \"Toxic example\").\n",
    "\n",
    "`print(f\"  Tweet: \\\"{tweet}\\\"\")` displays the original tweet text in quotes.\n",
    "\n",
    "`print(f\"  Prediction: {pred_label} (confidence: {confidence:.2f}%)\")` displays the predicted sentiment class and confidence percentage.\n",
    "\n",
    "`print(f\"  Probabilities: negative/toxic={...}, neutral={...}, positive={...}\")` displays the full probability distribution across all three classes for transparency.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TksdtJi5eWY1",
    "outputId": "5af46b8f-7885-4e2d-968a-24613d4a4741"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing BERT model on sample tweets (per proposal: handles sarcasm, informal language):\n",
      "\n",
      "======================================================================\n",
      "\n",
      "Toxic example:\n",
      "  Tweet: \"This is absolutely disgusting! People like you should be banned from social media. Horrible!\"\n",
      "  Prediction: negative/toxic (confidence: 86.36%)\n",
      "  Probabilities: negative/toxic=0.864, neutral=0.118, positive=0.018\n",
      "\n",
      "Neutral example:\n",
      "  Tweet: \"Just finished my morning coffee. Weather is okay today, nothing special.\"\n",
      "  Prediction: neutral (confidence: 60.14%)\n",
      "  Probabilities: negative/toxic=0.172, neutral=0.601, positive=0.227\n",
      "\n",
      "Positive example:\n",
      "  Tweet: \"So grateful for all the support today! Amazing community, thank you everyone! 🙏\"\n",
      "  Prediction: positive (confidence: 93.71%)\n",
      "  Probabilities: negative/toxic=0.023, neutral=0.039, positive=0.937\n",
      "\n",
      "Sarcastic/Toxic:\n",
      "  Tweet: \"Oh wonderful, another day of dealing with this nonsense. Just perfect...\"\n",
      "  Prediction: positive (confidence: 76.33%)\n",
      "  Probabilities: negative/toxic=0.077, neutral=0.160, positive=0.763\n",
      "\n",
      "Informal positive:\n",
      "  Tweet: \"This made my day! So happy right now! Best news ever! 🔥\"\n",
      "  Prediction: positive (confidence: 91.82%)\n",
      "  Probabilities: negative/toxic=0.031, neutral=0.050, positive=0.918\n",
      "\n",
      "======================================================================\n",
      "✓ Inference examples completed\n"
     ]
    }
   ],
   "source": [
    "sample_tweets = [\n",
    "    (\"Toxic example\", \"This is absolutely disgusting! People like you should be banned from social media. Horrible!\"),\n",
    "    (\"Neutral example\", \"Just finished my morning coffee. Weather is okay today, nothing special.\"),\n",
    "    (\"Positive example\", \"So grateful for all the support today! Amazing community, thank you everyone! 🙏\"),\n",
    "    (\"Sarcastic/Toxic\", \"Oh wonderful, another day of dealing with this nonsense. Just perfect...\"),\n",
    "    (\"Informal positive\", \"This made my day! So happy right now! Best news ever! 🔥\"),\n",
    "]\n",
    "\n",
    "print(\"Testing BERT model on sample tweets (per proposal: handles sarcasm, informal language):\\n\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "try:\n",
    "    _ = best_model\n",
    "    best_model = best_model.to(device)\n",
    "    best_model.eval()\n",
    "except NameError:\n",
    "    from transformers import AutoModelForSequenceClassification\n",
    "    best_model = AutoModelForSequenceClassification.from_pretrained(best_ckpt_dir).to(device)\n",
    "    best_model.eval()\n",
    "\n",
    "best_tokenizer = AutoTokenizer.from_pretrained(best_ckpt_dir, use_fast=True)\n",
    "\n",
    "for label, tweet in sample_tweets:\n",
    "    inputs = best_tokenizer(tweet, return_tensors=\"pt\", truncation=True, padding=True, max_length=128).to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = best_model(**inputs)\n",
    "        probs = torch.softmax(outputs.logits, dim=-1)[0].cpu().numpy()\n",
    "        pred_bert = np.argmax(probs)\n",
    "\n",
    "    bert_to_proposal = {0: -1, 1: 0, 2: 1}\n",
    "    pred = bert_to_proposal[pred_bert]\n",
    "\n",
    "    label_map = {-1: \"negative/toxic\", 0: \"neutral\", 1: \"positive\"}\n",
    "    pred_label = label_map.get(pred, \"unknown\")\n",
    "    confidence = probs[pred_bert] * 100\n",
    "\n",
    "    prob_map = {0: -1, 1: 0, 2: 1}\n",
    "    probs_proposal = {label_map[prob_map[i]]: float(probs[i]) for i in range(3)}\n",
    "\n",
    "    print(f\"\\n{label}:\")\n",
    "    print(f\"  Tweet: \\\"{tweet}\\\"\")\n",
    "    print(f\"  Prediction: {pred_label} (confidence: {confidence:.2f}%)\")\n",
    "    print(f\"  Probabilities: negative/toxic={probs_proposal['negative/toxic']:.3f}, neutral={probs_proposal['neutral']:.3f}, positive={probs_proposal['positive']:.3f}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"✓ Inference examples completed\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XSiPMDDCeWY2"
   },
   "source": [
    "# Export and Deployment Preparation\n",
    "\n",
    "**`Purpose`**\n",
    "\n",
    "Export all necessary artifacts for model deployment and reproduction per proposal Section VII. This block prepares quantized model weights, consolidated experiment logs, model metadata, and summary reports to ensure that classmates and graders can reproduce, audit, and extend the workflow without rerunning training from scratch.\n",
    "\n",
    "**`Input`**\n",
    "\n",
    "Uses the best trained BERT model checkpoint, experiment logs from `runs_log.csv`, test set evaluation results, and all previous model performance metrics. Requires that training, evaluation, and comparison cells have been executed to generate the necessary artifacts.\n",
    "\n",
    "**`Output`**\n",
    "\n",
    "Saves quantized PyTorch model weights to checkpoint directory (`pytorch_model_quantized.bin`), exports consolidated experiment logs to CSV and Excel formats in `exports/` directory, generates a JSON model card (`exports/model_card.json`) with metadata and performance metrics, and creates a text summary report (`exports/summary_report.txt`) documenting dataset statistics, model performance, and improvement metrics. Ensures all deployment artifacts are properly formatted and accessible.\n",
    "\n",
    "**`Details`**\n",
    "\n",
    "The export process follows deployment best practices: (1) saves the full model in PyTorch format (`pytorch_model.bin`) and creates a quantized version (`pytorch_model_quantized.bin`) using dynamic quantization to reduce model size while maintaining performance, (2) consolidates all experiment runs from `runs_log.csv` into exportable CSV and Excel formats for easy sharing and analysis, (3) generates a comprehensive model card in JSON format containing model architecture details, training configuration, dataset information, and performance metrics, (4) creates a human-readable summary report comparing baseline and BERT model performance, documenting F1-macro improvements and target achievement status. All outputs are organized in the `exports/` directory with clear naming conventions for easy discovery and deployment.\n",
    "\n",
    "**`Line-by-line Description.`**\n",
    "\n",
    "`print(\"Exporting artifacts for deployment...\")` provides user feedback about the export process starting.\n",
    "\n",
    "`try: _ = best_model` checks if best_model exists from previous cells to avoid redundant loading.\n",
    "\n",
    "`except NameError:` handles missing model by loading from checkpoint directory.\n",
    "\n",
    "`if os.path.exists(\"./checkpoints/bert-base/best_grid\"):` checks for hyperparameter-tuned grid search checkpoint first (highest priority).\n",
    "\n",
    "`best_ckpt_dir = \"./checkpoints/bert-base/best_grid\"` sets checkpoint path to grid search results.\n",
    "\n",
    "`elif os.path.exists(\"./checkpoints/bert-base/best_random\"):` falls back to random search checkpoint if grid search unavailable.\n",
    "\n",
    "`elif os.path.exists(\"./checkpoints/bert-base/best\"):` falls back to default training checkpoint if no tuning was performed.\n",
    "\n",
    "`best_model = AutoModelForSequenceClassification.from_pretrained(best_ckpt_dir).to(device)` loads the trained model from checkpoint.\n",
    "\n",
    "`full_model_path = Path(best_ckpt_dir) / \"pytorch_model.bin\"` constructs the path for saving PyTorch model weights.\n",
    "\n",
    "`safetensors_path = Path(best_ckpt_dir) / \"model.safetensors\"` constructs the path for safetensors format (may exist from HuggingFace save).\n",
    "\n",
    "`best_model.save_pretrained(best_ckpt_dir, safe_serialization=False)` saves model using HuggingFace's save method with PyTorch format (not safetensors).\n",
    "\n",
    "`best_model.cpu()` moves model to CPU before saving state dict (required for some PyTorch save operations).\n",
    "\n",
    "`torch.save(best_model.state_dict(), full_model_path)` explicitly saves model state dictionary as pytorch_model.bin for deployment compatibility.\n",
    "\n",
    "`best_model.to(device)` moves model back to original device for subsequent operations.\n",
    "\n",
    "`file_size = os.path.getsize(full_model_path) / (1024*1024)` calculates model file size in megabytes for verification.\n",
    "\n",
    "`if safetensors_path.exists(): safetensors_path.unlink()` removes safetensors file to use PyTorch format exclusively.\n",
    "\n",
    "`quantized_model = torch.quantization.quantize_dynamic(best_model.cpu(), {torch.nn.Linear}, dtype=torch.qint8)` applies dynamic quantization to linear layers, converting weights to 8-bit integers to reduce model size.\n",
    "\n",
    "`quantized_path = Path(best_ckpt_dir) / 'pytorch_model_quantized.bin'` constructs path for quantized model weights.\n",
    "\n",
    "`torch.save(quantized_model.state_dict(), quantized_path)` saves the quantized model weights to disk.\n",
    "\n",
    "`if os.path.exists(\"runs_log.csv\"):` checks if experiment log file exists before exporting.\n",
    "\n",
    "`runs_df = pd.read_csv(\"runs_log.csv\")` loads all experiment runs into a pandas DataFrame.\n",
    "\n",
    "`runs_df.to_csv(\"exports/experiment_runs_all.csv\", index=False)` exports experiment logs to CSV format in exports directory.\n",
    "\n",
    "`runs_df.to_excel(\"exports/experiment_runs_all.xlsx\", index=False)` exports experiment logs to Excel format for easy sharing and analysis.\n",
    "\n",
    "`model_card = {...}` creates a dictionary containing model metadata, configuration, and performance metrics.\n",
    "\n",
    "`\"model_name\": MODEL_NAME` records the base model identifier (bert-base-uncased).\n",
    "\n",
    "`\"task\": \"Toxic Comment Detection on Twitter\"` specifies the task domain.\n",
    "\n",
    "`\"num_labels\": 3` records the number of classification classes.\n",
    "\n",
    "`\"labels\": [\"negative/toxic (-1)\", \"neutral (0)\", \"positive (1)\"]` lists all class labels with their encodings.\n",
    "\n",
    "`\"best_test_accuracy\": float(test_results.get('eval_accuracy', 0))` records final test set accuracy.\n",
    "\n",
    "`\"best_test_f1_macro\": float(test_results.get('eval_f1_macro', 0))` records final test set F1-macro score.\n",
    "\n",
    "`\"improvement\": f\"{((test_results.get('eval_f1_macro', 0) - test_f1) / test_f1 * 100):.2f}%\"` calculates and formats percentage improvement over baseline.\n",
    "\n",
    "`with open(\"exports/model_card.json\", \"w\") as f: json.dump(model_card, f, indent=2)` saves model card as formatted JSON file.\n",
    "\n",
    "`summary_text = f\"\"\"...\"\"\"` creates a formatted text summary report using f-string template.\n",
    "\n",
    "`with open(\"exports/summary_report.txt\", \"w\") as f: f.write(summary_text)` saves the human-readable summary report to text file.\n",
    "\n",
    "`print(\"=\"*70)` and `print(\"✓ All exports completed successfully!\")` provides visual confirmation that export process finished successfully.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ERIao_fKeWY2",
    "outputId": "551a2d96-c580-4755-b201-00dc5d9e1a3e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exporting artifacts for deployment...\n",
      "Using model from previous cells...\n",
      "\n",
      "0. Ensuring full model is saved...\n",
      "   Saving model in PyTorch format (pytorch_model.bin)...\n",
      "   [OK] Model saved via save_pretrained()\n",
      "   Explicitly saving state_dict as pytorch_model.bin...\n",
      "   [OK] State dict saved directly\n",
      "   [OK] Verified: pytorch_model.bin exists (417.73 MB)\n",
      "   [INFO] Removing model.safetensors (using pytorch_model.bin instead)\n",
      "\n",
      "1. Saving quantized model weights...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipython-input-2413080969.py:58: DeprecationWarning: torch.ao.quantization is deprecated and will be removed in 2.10. \n",
      "For migrations of users: \n",
      "1. Eager mode quantization (torch.ao.quantization.quantize, torch.ao.quantization.quantize_dynamic), please migrate to use torchao eager mode quantize_ API instead \n",
      "2. FX graph mode quantization (torch.ao.quantization.quantize_fx.prepare_fx,torch.ao.quantization.quantize_fx.convert_fx, please migrate to use torchao pt2e quantization API instead (prepare_pt2e, convert_pt2e) \n",
      "3. pt2e quantization has been migrated to torchao (https://github.com/pytorch/ao/tree/main/torchao/quantization/pt2e) \n",
      "see https://github.com/pytorch/ao/issues/2259 for more details\n",
      "  quantized_model = torch.quantization.quantize_dynamic(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ✓ Quantized model saved to checkpoints/bert-base/best_grid/pytorch_model_quantized.bin\n",
      "\n",
      "2. Exporting consolidated experiment logs...\n",
      "   ✓ Experiment logs exported to exports/experiment_runs_all.csv\n",
      "   ✓ Excel summary exported to exports/experiment_runs_all.xlsx\n",
      "\n",
      "3. Generating model card...\n",
      "   ✓ Model card saved to exports/model_card.json\n",
      "\n",
      "4. Creating summary report...\n",
      "\n",
      "Twitter Toxicity Detection Project - Summary Report\n",
      "==================================================\n",
      "\n",
      "Dataset: mteb/tweet_sentiment_extraction\n",
      "Total samples: 29756\n",
      "Train/Val/Test split: 70%/15%/15%\n",
      "\n",
      "Baseline Model (TF-IDF + Logistic Regression):\n",
      "  - Accuracy: 0.6224\n",
      "  - Precision: 0.6294\n",
      "  - Recall: 0.6197\n",
      "  - F1-macro: 0.6234\n",
      "\n",
      "BERT Model (bert-base-uncased):\n",
      "  - Accuracy: 0.6691\n",
      "  - Precision: 0.6884\n",
      "  - Recall: 0.6599\n",
      "  - F1-macro: 0.6679\n",
      "\n",
      "Improvement over baseline:\n",
      "  - F1-macro improvement: 7.14%\n",
      "\n",
      "Target F1-macro (per proposal): >0.85\n",
      "Achieved F1-macro: 0.6679\n",
      "Target met: ✗ NO\n",
      "\n",
      "All artifacts exported to:\n",
      "  - Model checkpoints: ./checkpoints/bert-base/best_grid\n",
      "  - Predictions: exports/\n",
      "  - Visualizations: exports/confusion_matrices/, exports/roc_curves/\n",
      "  - Logs: runs_log.csv, exports/experiment_runs_all.csv\n",
      "\n",
      "\n",
      "✓ Summary report saved to exports/summary_report.txt\n",
      "\n",
      "======================================================================\n",
      "✓ All exports completed successfully!\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"Exporting artifacts for deployment...\")\n",
    "\n",
    "try:\n",
    "    _ = best_model\n",
    "    _ = best_ckpt_dir\n",
    "    print(\"Using model from previous cells...\")\n",
    "except NameError:\n",
    "    print(\"Loading model from saved checkpoint...\")\n",
    "    from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "    from pathlib import Path\n",
    "    import os\n",
    "\n",
    "    if os.path.exists(\"./checkpoints/bert-base/best_grid\"):\n",
    "        best_ckpt_dir = \"./checkpoints/bert-base/best_grid\"\n",
    "        print(f\"   Found best_grid checkpoint: {best_ckpt_dir}\")\n",
    "    elif os.path.exists(\"./checkpoints/bert-base/best_random\"):\n",
    "        best_ckpt_dir = \"./checkpoints/bert-base/best_random\"\n",
    "        print(f\"   Found best_random checkpoint: {best_ckpt_dir}\")\n",
    "    elif os.path.exists(\"./checkpoints/bert-base/best\"):\n",
    "        best_ckpt_dir = \"./checkpoints/bert-base/best\"\n",
    "        print(f\"   Found best checkpoint: {best_ckpt_dir}\")\n",
    "    else:\n",
    "        raise FileNotFoundError(\n",
    "            \"No checkpoint directory found. Please run the training cells first.\\n\"\n",
    "            \"Expected locations: checkpoints/bert-base/best, checkpoints/bert-base/best_grid, or checkpoints/bert-base/best_random\"\n",
    "        )\n",
    "\n",
    "    best_model = AutoModelForSequenceClassification.from_pretrained(best_ckpt_dir).to(device)\n",
    "    best_model.eval()\n",
    "    print(f\"   ✓ Model loaded from {best_ckpt_dir}\")\n",
    "\n",
    "print(\"\\n0. Ensuring full model is saved...\")\n",
    "full_model_path = Path(best_ckpt_dir) / \"pytorch_model.bin\"\n",
    "safetensors_path = Path(best_ckpt_dir) / \"model.safetensors\"\n",
    "\n",
    "print(\"   Saving model in PyTorch format (pytorch_model.bin)...\")\n",
    "best_model.save_pretrained(best_ckpt_dir, safe_serialization=False)\n",
    "print(\"   [OK] Model saved via save_pretrained()\")\n",
    "\n",
    "print(\"   Explicitly saving state_dict as pytorch_model.bin...\")\n",
    "best_model.cpu()\n",
    "torch.save(best_model.state_dict(), full_model_path)\n",
    "best_model.to(device)\n",
    "print(\"   [OK] State dict saved directly\")\n",
    "\n",
    "if full_model_path.exists():\n",
    "    file_size = os.path.getsize(full_model_path) / (1024*1024)\n",
    "    print(f\"   [OK] Verified: pytorch_model.bin exists ({file_size:.2f} MB)\")\n",
    "\n",
    "    if safetensors_path.exists():\n",
    "        print(\"   [INFO] Removing model.safetensors (using pytorch_model.bin instead)\")\n",
    "        safetensors_path.unlink()\n",
    "else:\n",
    "    print(\"   [ERROR] pytorch_model.bin was not saved! Check permissions and disk space.\")\n",
    "\n",
    "print(\"\\n1. Saving quantized model weights...\")\n",
    "try:\n",
    "    quantized_model = torch.quantization.quantize_dynamic(\n",
    "        best_model.cpu(), {torch.nn.Linear}, dtype=torch.qint8\n",
    "    )\n",
    "    quantized_path = Path(best_ckpt_dir) / 'pytorch_model_quantized.bin'\n",
    "    torch.save(quantized_model.state_dict(), quantized_path)\n",
    "    print(f\"   ✓ Quantized model saved to {quantized_path}\")\n",
    "except Exception as e:\n",
    "    print(f\"   ⚠ Quantization failed: {e}\")\n",
    "\n",
    "print(\"\\n2. Exporting consolidated experiment logs...\")\n",
    "if os.path.exists(\"runs_log.csv\"):\n",
    "    runs_df = pd.read_csv(\"runs_log.csv\")\n",
    "    runs_df.to_csv(\"exports/experiment_runs_all.csv\", index=False)\n",
    "    print(\"   ✓ Experiment logs exported to exports/experiment_runs_all.csv\")\n",
    "\n",
    "    try:\n",
    "        runs_df.to_excel(\"exports/experiment_runs_all.xlsx\", index=False)\n",
    "        print(\"   ✓ Excel summary exported to exports/experiment_runs_all.xlsx\")\n",
    "    except:\n",
    "        print(\"   ⚠ Excel export skipped (openpyxl not available)\")\n",
    "\n",
    "print(\"\\n3. Generating model card...\")\n",
    "model_card = {\n",
    "    \"model_name\": MODEL_NAME,\n",
    "    \"task\": \"Toxic Comment Detection on Twitter\",\n",
    "    \"num_labels\": 3,\n",
    "    \"labels\": [\"negative/toxic (-1)\", \"neutral (0)\", \"positive (1)\"],\n",
    "    \"dataset\": \"mteb/tweet_sentiment_extraction\",\n",
    "    \"training_split\": \"70%\",\n",
    "    \"validation_split\": \"15%\",\n",
    "    \"test_split\": \"15%\",\n",
    "    \"max_sequence_length\": MAX_LEN,\n",
    "    \"optimizer\": \"AdamW\",\n",
    "    \"loss\": \"Cross-entropy\",\n",
    "    \"scheduler\": \"Linear warmup\",\n",
    "    \"best_test_accuracy\": float(test_results.get('eval_accuracy', 0)),\n",
    "    \"best_test_f1_macro\": float(test_results.get('eval_f1_macro', 0)),\n",
    "    \"baseline_accuracy\": float(test_acc),\n",
    "    \"baseline_f1_macro\": float(test_f1),\n",
    "    \"improvement\": f\"{((test_results.get('eval_f1_macro', 0) - test_f1) / test_f1 * 100):.2f}%\",\n",
    "}\n",
    "\n",
    "with open(\"exports/model_card.json\", \"w\") as f:\n",
    "    json.dump(model_card, f, indent=2)\n",
    "print(\"   ✓ Model card saved to exports/model_card.json\")\n",
    "\n",
    "print(\"\\n4. Creating summary report...\")\n",
    "summary_text = f\"\"\"\n",
    "Twitter Toxicity Detection Project - Summary Report\n",
    "==================================================\n",
    "\n",
    "Dataset: mteb/tweet_sentiment_extraction\n",
    "Total samples: {len(df)}\n",
    "Train/Val/Test split: 70%/15%/15%\n",
    "\n",
    "Baseline Model (TF-IDF + Logistic Regression):\n",
    "  - Accuracy: {test_acc:.4f}\n",
    "  - Precision: {test_prec:.4f}\n",
    "  - Recall: {test_rec:.4f}\n",
    "  - F1-macro: {test_f1:.4f}\n",
    "\n",
    "BERT Model (bert-base-uncased):\n",
    "  - Accuracy: {test_results.get('eval_accuracy', 0):.4f}\n",
    "  - Precision: {test_results.get('eval_precision', 0):.4f}\n",
    "  - Recall: {test_results.get('eval_recall', 0):.4f}\n",
    "  - F1-macro: {test_results.get('eval_f1_macro', 0):.4f}\n",
    "\n",
    "Improvement over baseline:\n",
    "  - F1-macro improvement: {((test_results.get('eval_f1_macro', 0) - test_f1) / test_f1 * 100):.2f}%\n",
    "\n",
    "Target F1-macro (per proposal): >0.85\n",
    "Achieved F1-macro: {test_results.get('eval_f1_macro', 0):.4f}\n",
    "Target met: {'✓ YES' if test_results.get('eval_f1_macro', 0) > 0.85 else '✗ NO'}\n",
    "\n",
    "All artifacts exported to:\n",
    "  - Model checkpoints: {best_ckpt_dir}\n",
    "  - Predictions: exports/\n",
    "  - Visualizations: exports/confusion_matrices/, exports/roc_curves/\n",
    "  - Logs: runs_log.csv, exports/experiment_runs_all.csv\n",
    "\"\"\"\n",
    "\n",
    "with open(\"exports/summary_report.txt\", \"w\") as f:\n",
    "    f.write(summary_text)\n",
    "print(summary_text)\n",
    "print(\"\\n✓ Summary report saved to exports/summary_report.txt\")\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"✓ All exports completed successfully!\")\n",
    "print(\"=\"*70)\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "03212a099ce4422b8a135b8c6eeb2fcd": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "03616f6164a849c0984dc1ccff5b2b3a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c9fc02707312427b9bdc9f7495993b0e",
      "placeholder": "​",
      "style": "IPY_MODEL_6e89fdd78d3d44bfb2b3b04e91e4be66",
      "value": "model.safetensors: 100%"
     }
    },
    "08186379a45246ae86d4602033bb3ccc": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_bc148e80c2964c90996a6aa224ec9752",
      "placeholder": "​",
      "style": "IPY_MODEL_17d6367ac07342bab4215ac7191f5c16",
      "value": " 8/8 [32:34&lt;00:00, 229.44s/it]"
     }
    },
    "0818eeb507cd4c30a17c845d2ad4c0dd": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0afce817cd2941b1bc24854e73cd4dbe": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "0b00736fef7b454bbfcd829b1667db64": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "10cc0dc7261a4eb9884f0ba78c7a3926": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "11fda0ea2b454ce1aa719160211afd08": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "135e3577576d4b26a3d43bae38d67208": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "135feff3d9614e76b88313ad6bfb8177": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "15626e0d50ea4e09a3e134a02c4cfd69": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "17c15355c9ef4a7fa5669c930cdf84fd": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "17d6367ac07342bab4215ac7191f5c16": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "1a7378e6d40e4a6eb80c0d805727c0f2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "1b650b5232834ef5880468f21b8dd263": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1cf59def1999467e80be0bdab29cfdfe": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_43bdfbe028ab4c0c8718679e4c4b1e95",
      "placeholder": "​",
      "style": "IPY_MODEL_70dd0010da4849f4aa9ad301e61e230c",
      "value": "Best trial: 7. Best value: 0.677417: 100%"
     }
    },
    "1d54003236e24467957614ff7a260afd": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1f92e948f74348f5bcfc5ead3bfaeb4c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "22d5fa6213ae4a0b837652285777cbd8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f372766774e9466fb15d34d86e5f834f",
      "placeholder": "​",
      "style": "IPY_MODEL_2aced18c55e24958be0a413cdc875a78",
      "value": " 8330/8330 [00:00&lt;00:00, 18653.82 examples/s]"
     }
    },
    "255eef29891f471ab6626ea3c5cd3f6f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "275b70feaa5445809c8519700bbcc14e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a8c2d07a17fa41caa6a66e2c249634ea",
      "placeholder": "​",
      "style": "IPY_MODEL_d0344b3fe88049a3951cf09b34f911a0",
      "value": "tokenizer.json: 100%"
     }
    },
    "27f3b02b05694355905bd30e73dbdb76": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_fb09029059d942e79db695cd14274656",
      "placeholder": "​",
      "style": "IPY_MODEL_c6a046344ce8439c8e84f473a8007da0",
      "value": "Best trial: 3. Best value: 0.675779: 100%"
     }
    },
    "2aced18c55e24958be0a413cdc875a78": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "2e910123a7ee43969d1daf67f03a994d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "351e5dc9d6f748f1a71abe462e7b0fff": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_77d0fc25f5fa4252ba04f49e8c4bb7a6",
       "IPY_MODEL_c81749ecedde40f0b716bbcaa9512817",
       "IPY_MODEL_51e9448be13b4de998214e74e896bead"
      ],
      "layout": "IPY_MODEL_719cb2899fae4fe2af07babb0302e869"
     }
    },
    "3772522c7cc946ab9972c97a049d5e50": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a5d5738beab6445ababb3f0b67109d47",
      "max": 4456,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_db36372a8dd44ae4a53771f3722a00f5",
      "value": 4456
     }
    },
    "39696b895e6a4d3ab6865c236317f70a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3a554ae9db8d4455807cdf97c6928f59": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e1769733b168434f8011db6a0b28de3e",
      "placeholder": "​",
      "style": "IPY_MODEL_c968ea901b14496bacf45f166b0b26b5",
      "value": " 466k/466k [00:00&lt;00:00, 14.6MB/s]"
     }
    },
    "3ad66231e487409bacfadc9e79f01d36": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_9bd68fc454504c0a83949f9564799c35",
       "IPY_MODEL_f5b54a3a770b4b29bbb24ed5b1336519",
       "IPY_MODEL_22d5fa6213ae4a0b837652285777cbd8"
      ],
      "layout": "IPY_MODEL_d08e382ef1374c2b8f18a95ac2269f1e"
     }
    },
    "3f5fcfa83b354817b5d21145b54b5e6f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "4221c547dbe7453f8dad422356a0b68d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_db4350bb911e4e108aaa1b13db200d9e",
      "placeholder": "​",
      "style": "IPY_MODEL_67d53b7bc4c6437ebfa159d59cd2b245",
      "value": "Map (num_proc=4): 100%"
     }
    },
    "42bd72f0f1d246f3bfc32ea677583c7b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "43bdfbe028ab4c0c8718679e4c4b1e95": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4517b6ef49d24799b1e9108c7d1eda2a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e65a75ceddcf4230ac03b8a131714b4b",
      "placeholder": "​",
      "style": "IPY_MODEL_576b4557bf14422b8850cf5d3819a7c1",
      "value": " 8/8 [30:39&lt;00:00, 250.92s/it]"
     }
    },
    "51e9448be13b4de998214e74e896bead": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_71191bac6547415399a6da202d8b23e8",
      "placeholder": "​",
      "style": "IPY_MODEL_1a7378e6d40e4a6eb80c0d805727c0f2",
      "value": " 570/570 [00:00&lt;00:00, 51.7kB/s]"
     }
    },
    "54b7f438ed644a4fb23906fd12a32197": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "56f2ea0f5985448bb60cc73af75d02e5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "576b4557bf14422b8850cf5d3819a7c1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "5c0e791e5fc348bab3239e09b32c29c9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_dfaa1b6ff7f84358bb9b333ac31d1626",
      "placeholder": "​",
      "style": "IPY_MODEL_1f92e948f74348f5bcfc5ead3bfaeb4c",
      "value": "Map (num_proc=4): 100%"
     }
    },
    "5d882abf74834499921a526972845a6a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "5dd5311eedb64a12a6b0eb667c55b9b6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_15626e0d50ea4e09a3e134a02c4cfd69",
      "placeholder": "​",
      "style": "IPY_MODEL_56f2ea0f5985448bb60cc73af75d02e5",
      "value": " 232k/232k [00:00&lt;00:00, 5.21MB/s]"
     }
    },
    "5ef7762988b94fe7b83fc58ab38e8251": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_b9bbc48ea31c4415bce6083ad89e1ee9",
       "IPY_MODEL_a07cd198a7404d79ac9aa475eadfbc24",
       "IPY_MODEL_5dd5311eedb64a12a6b0eb667c55b9b6"
      ],
      "layout": "IPY_MODEL_255eef29891f471ab6626ea3c5cd3f6f"
     }
    },
    "610d486ba5204fb5a1c5415bd0dddb81": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "648381ab878c415c8b3e2ecc3c2acbc7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_135feff3d9614e76b88313ad6bfb8177",
      "placeholder": "​",
      "style": "IPY_MODEL_9f3d5e77337b4f64a72b47a069eb60a2",
      "value": " 440M/440M [00:01&lt;00:00, 562MB/s]"
     }
    },
    "67d53b7bc4c6437ebfa159d59cd2b245": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "6c130366457445aea8de3ec7921a3c14": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_fb28759cd8754b1eaa0c56b835b23b73",
      "placeholder": "​",
      "style": "IPY_MODEL_b55e528c34ef4d9b8961731ffc4cca01",
      "value": " 4456/4456 [00:00&lt;00:00, 3549.42 examples/s]"
     }
    },
    "6cadb6fc36fe47dfa0fd9f2bd1c807ca": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0b00736fef7b454bbfcd829b1667db64",
      "max": 8,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_9145878ce90e4126afc4721207e3307f",
      "value": 8
     }
    },
    "6d7886bc88784b768ec81496afc5855a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6e89fdd78d3d44bfb2b3b04e91e4be66": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "6e9c7a54fc5a4d62ab885be848268c2d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_275b70feaa5445809c8519700bbcc14e",
       "IPY_MODEL_e1e06685f2cd49a19f14d4a6531c7c07",
       "IPY_MODEL_3a554ae9db8d4455807cdf97c6928f59"
      ],
      "layout": "IPY_MODEL_d833c9f53700449a91bdd2babdc8dfce"
     }
    },
    "70dd0010da4849f4aa9ad301e61e230c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "71191bac6547415399a6da202d8b23e8": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7163be4a7bc24997945acdc9404463c4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "719cb2899fae4fe2af07babb0302e869": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "77d0fc25f5fa4252ba04f49e8c4bb7a6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d04b6c9f26ae47e9a7b80edf79f39ed3",
      "placeholder": "​",
      "style": "IPY_MODEL_3f5fcfa83b354817b5d21145b54b5e6f",
      "value": "config.json: 100%"
     }
    },
    "851d104f415a4c85bd3bb4a27871c3cc": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c9eaabab5d844cf8b02048fb48cbdc1b",
      "max": 8,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_5d882abf74834499921a526972845a6a",
      "value": 8
     }
    },
    "8d13e61f557247a69d8ade9b9aa14328": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "9145878ce90e4126afc4721207e3307f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "93e73aef85fb46bf8f75f0f701598657": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "96ec73e3109a4cac8204f01396acac13": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_39696b895e6a4d3ab6865c236317f70a",
      "max": 4476,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_135e3577576d4b26a3d43bae38d67208",
      "value": 4476
     }
    },
    "9bd68fc454504c0a83949f9564799c35": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_eb71c1244137418b9ab28596aa28d34d",
      "placeholder": "​",
      "style": "IPY_MODEL_8d13e61f557247a69d8ade9b9aa14328",
      "value": "Map (num_proc=4): 100%"
     }
    },
    "9f3d5e77337b4f64a72b47a069eb60a2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "a07cd198a7404d79ac9aa475eadfbc24": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_93e73aef85fb46bf8f75f0f701598657",
      "max": 231508,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_d7a43b67ebbf4e119f0c5ea0830f8fe3",
      "value": 231508
     }
    },
    "a5d5738beab6445ababb3f0b67109d47": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a701b5dfeb164cf5ad6be732871e00b3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_5c0e791e5fc348bab3239e09b32c29c9",
       "IPY_MODEL_96ec73e3109a4cac8204f01396acac13",
       "IPY_MODEL_cf09a98a3b7a4c938faed59c7d883950"
      ],
      "layout": "IPY_MODEL_54b7f438ed644a4fb23906fd12a32197"
     }
    },
    "a8975c6dd820414597ed8cd897065751": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_03616f6164a849c0984dc1ccff5b2b3a",
       "IPY_MODEL_ef6ca063f92340c7a22a0befb15d2ea2",
       "IPY_MODEL_648381ab878c415c8b3e2ecc3c2acbc7"
      ],
      "layout": "IPY_MODEL_6d7886bc88784b768ec81496afc5855a"
     }
    },
    "a8c2d07a17fa41caa6a66e2c249634ea": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b23664ab84c84328b4916afad791ddbf": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "b2e169dc048a463d803dfb31fc110372": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_27f3b02b05694355905bd30e73dbdb76",
       "IPY_MODEL_851d104f415a4c85bd3bb4a27871c3cc",
       "IPY_MODEL_4517b6ef49d24799b1e9108c7d1eda2a"
      ],
      "layout": "IPY_MODEL_cc100f025a7b454392427512aa929fb4"
     }
    },
    "b55e528c34ef4d9b8961731ffc4cca01": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "b744c8c467ab40e7b5b20f5c019f4fe3": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b9bbc48ea31c4415bce6083ad89e1ee9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_42bd72f0f1d246f3bfc32ea677583c7b",
      "placeholder": "​",
      "style": "IPY_MODEL_0afce817cd2941b1bc24854e73cd4dbe",
      "value": "vocab.txt: 100%"
     }
    },
    "bc148e80c2964c90996a6aa224ec9752": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c6a046344ce8439c8e84f473a8007da0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "c81749ecedde40f0b716bbcaa9512817": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_1d54003236e24467957614ff7a260afd",
      "max": 570,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_fb628b4fd03e46a0952b9023f91c8b95",
      "value": 570
     }
    },
    "c91e652010b94d00ba44e835da6149b0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "c968ea901b14496bacf45f166b0b26b5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "c9eaabab5d844cf8b02048fb48cbdc1b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c9fc02707312427b9bdc9f7495993b0e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "cbe81ad09104464487e3631a09652a4f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "cc067326155445bc9b80fb26c32187a5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "cc100f025a7b454392427512aa929fb4": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "cf09a98a3b7a4c938faed59c7d883950": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_610d486ba5204fb5a1c5415bd0dddb81",
      "placeholder": "​",
      "style": "IPY_MODEL_cc067326155445bc9b80fb26c32187a5",
      "value": " 4476/4476 [00:00&lt;00:00, 3893.15 examples/s]"
     }
    },
    "d0344b3fe88049a3951cf09b34f911a0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "d04b6c9f26ae47e9a7b80edf79f39ed3": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d08e382ef1374c2b8f18a95ac2269f1e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d7a43b67ebbf4e119f0c5ea0830f8fe3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "d833c9f53700449a91bdd2babdc8dfce": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "da6503c757ad4816ad8beb4eb58ed984": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_03212a099ce4422b8a135b8c6eeb2fcd",
      "placeholder": "​",
      "style": "IPY_MODEL_b23664ab84c84328b4916afad791ddbf",
      "value": " 48.0/48.0 [00:00&lt;00:00, 5.39kB/s]"
     }
    },
    "db36372a8dd44ae4a53771f3722a00f5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "db4350bb911e4e108aaa1b13db200d9e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "dcc54877f06d43deab853869e5f0b1e7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_f50b6e29f9164d70aa03d2b392e39157",
       "IPY_MODEL_f0fd7fea1774410e8875370e9209dc9b",
       "IPY_MODEL_da6503c757ad4816ad8beb4eb58ed984"
      ],
      "layout": "IPY_MODEL_eae034b764694e529838da79371cf9c1"
     }
    },
    "dfaa1b6ff7f84358bb9b333ac31d1626": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e1769733b168434f8011db6a0b28de3e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e1e06685f2cd49a19f14d4a6531c7c07": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_11fda0ea2b454ce1aa719160211afd08",
      "max": 466062,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_c91e652010b94d00ba44e835da6149b0",
      "value": 466062
     }
    },
    "e65a75ceddcf4230ac03b8a131714b4b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "eae034b764694e529838da79371cf9c1": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "eb71c1244137418b9ab28596aa28d34d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ef6ca063f92340c7a22a0befb15d2ea2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_1b650b5232834ef5880468f21b8dd263",
      "max": 440449768,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_2e910123a7ee43969d1daf67f03a994d",
      "value": 440449768
     }
    },
    "f0fd7fea1774410e8875370e9209dc9b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_10cc0dc7261a4eb9884f0ba78c7a3926",
      "max": 48,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_7163be4a7bc24997945acdc9404463c4",
      "value": 48
     }
    },
    "f2b5967ccc1c4665ac7d5638c47b40c9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_1cf59def1999467e80be0bdab29cfdfe",
       "IPY_MODEL_6cadb6fc36fe47dfa0fd9f2bd1c807ca",
       "IPY_MODEL_08186379a45246ae86d4602033bb3ccc"
      ],
      "layout": "IPY_MODEL_0818eeb507cd4c30a17c845d2ad4c0dd"
     }
    },
    "f372766774e9466fb15d34d86e5f834f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f4d9f57aee294796a5dd48c2f18ad43e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f50b6e29f9164d70aa03d2b392e39157": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f4d9f57aee294796a5dd48c2f18ad43e",
      "placeholder": "​",
      "style": "IPY_MODEL_cbe81ad09104464487e3631a09652a4f",
      "value": "tokenizer_config.json: 100%"
     }
    },
    "f58f8b579d334f9eb7445d47514c02b6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_4221c547dbe7453f8dad422356a0b68d",
       "IPY_MODEL_3772522c7cc946ab9972c97a049d5e50",
       "IPY_MODEL_6c130366457445aea8de3ec7921a3c14"
      ],
      "layout": "IPY_MODEL_fc70866129d94a7fb33a1bda53df2146"
     }
    },
    "f5b54a3a770b4b29bbb24ed5b1336519": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b744c8c467ab40e7b5b20f5c019f4fe3",
      "max": 8330,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_17c15355c9ef4a7fa5669c930cdf84fd",
      "value": 8330
     }
    },
    "fb09029059d942e79db695cd14274656": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "fb28759cd8754b1eaa0c56b835b23b73": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "fb628b4fd03e46a0952b9023f91c8b95": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "fc70866129d94a7fb33a1bda53df2146": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}