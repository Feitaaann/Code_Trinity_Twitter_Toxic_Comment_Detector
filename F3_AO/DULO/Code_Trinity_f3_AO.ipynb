{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q-r1wGCfrU8-"
   },
   "source": [
    "\n",
    "# Twitter Toxicity Detection Project\n",
    "\n",
    "> This notebook documents the end-to-end Twitter toxicity detection project, starting with deterministic data preparation and culminating in deployable artifacts. It begins by cleaning and splitting the Twitter tweet corpus, persisting split IDs so every experiment baseline or advanced evaluates on identical examples. Classic baselines (TF-IDF + Logistic Regression) anchor performance expectations before the workflow escalates to transformer fine-tuning with BERT-base-uncased.\n",
    ">\n",
    "> The transformer track covers tokenization, automated hyperparameter tuning (grid and random search), and early stopping, ultimately selecting the best checkpoint via validation macro-F1. Detailed evaluation follows: confusion matrices, per-class reports, ROC-AUC and PR-AUC curves, and exportable tables compare validation/test splits, while metric logs capture training dynamics.\n",
    ">\n",
    "> The project implements a dual-model approach: a baseline TF-IDF + Logistic Regression model for interpretability and computational efficiency, and a fine-tuned BERT-base-uncased model for superior accuracy and context-aware understanding of informal language, sarcasm, and subtle toxicity patterns in Twitter posts.\n",
    ">\n",
    "> Final cells translate the strongest transformer into deployment formats, exporting quantized PyTorch weights, consolidated logs, and spreadsheet summaries. Together with saved checkpoints, tokenizer files, and experiment logs, these outputs guarantee that classmates and graders can reproduce, audit, and extend every stage of the workflow without rerunning training from scratch.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KKvbkWSFrU8_"
   },
   "source": [
    "# **Setup, imports, dataset load, and split**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VjqCVYLZrU8_"
   },
   "source": [
    "**`Purpose`**\n",
    "\n",
    "This block prepares the environment, ensures required libraries are available, and loads the Twitter Comment Dataset into memory in a clean, consistent format. It also establishes a reproducible 70/15/15 train-validation-test split so that all later experiments evaluate on the same examples. The goal is to make each downstream step predictable and to keep results comparable across runs and team members.\n",
    "\n",
    "**`Input`**\n",
    "\n",
    "The cell expects either a local copy of TwitterToxicity.csv in the current working directory or, if absent, a file that will be provided through the upload dialog. The CSV must contain at least two columns named review and label, which represent the input text and its sentiment class. Labels should be in the format: -1 (negative/toxic), 0 (neutral), 1 (positive). No other inputs are required at this stage, and any additional columns are ignored.\n",
    "\n",
    "**`Output`**\n",
    "\n",
    "The cell produces three pandas DataFrames, train_df, val_df, and test_df, with stratified class proportions and a new id column to uniquely identify each row. It also writes three small files, train_ids.csv, val_ids.csv, and test_ids.csv, which store the chosen row IDs for reuse. The printed device line indicates whether a GPU is available. Three proportion tables are printed as a quick check that label ratios are closely matched across splits.\n",
    "\n",
    "**`Details`**\n",
    "\n",
    "The cell installs the core NLP stack, imports common utilities, and detects the runtime device. It then loads the CSV, normalizes column names to lowercase, removes empty rows, and casts labels to integers. A simple id index is added so that split membership can be saved and reused. A stratified split holds label balance constant, which is printed to confirm the split is fair. Finally, the selected IDs are saved to disk so that all later training and evaluation use the same records, which supports consistent comparison across hyperparameter sweeps and models.\n",
    "\n",
    "**`Line-by-line Description.`**\n",
    "\n",
    "`!pip -q install transformers datasets accelerate scikit-learn openpyxl optuna -U` installs or upgrades the libraries needed for tokenization, training, metrics, hyperparameter tuning, and spreadsheet export.\n",
    "\n",
    "`import os, numpy as np, pandas as pd, torch` pulls in filesystem helpers, numerical tools, data frames, and the deep learning backend.\n",
    "\n",
    "`from sklearn.model_selection import train_test_split` and `from sklearn.metrics import accuracy_score, f1_score` load utilities for splitting and scoring.\n",
    "`try: from google.colab import files ...` sets up an optional upload path that only activates when running in Colab.\n",
    "\n",
    "`device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')` detects whether a GPU is present and prints the choice so training expectations are clear.\n",
    "\n",
    "`if not os.path.exists('TwitterToxicity.csv') and files is not None: files.upload()` requests an upload when the CSV is missing, which keeps the workflow flexible.\n",
    "\n",
    "`df = pd.read_csv('TwitterToxicity.csv')` loads the data, and `df.columns = [c.lower() for c in df.columns]` enforces lowercase names so downstream code can assume consistent headers.\n",
    "\n",
    "`df = df.dropna(subset=['review','label']).copy()` removes incomplete rows to avoid errors and noisy training examples.\n",
    "`df['label'] = df['label'].astype(int)` fixes the label type so models receive proper integers.\n",
    "\n",
    "`df['id'] = np.arange(len(df))` assigns a stable identifier to each row so the split can be persisted.\n",
    "\n",
    "The branch that checks for `train_ids.csv`, `val_ids.csv`, and `test_ids.csv` either reuses an existing split or creates a new stratified split with 70/15/15 ratio using `train_test_split(... stratify=df['label'])`.\n",
    "\n",
    "`train_df[['id']].to_csv('train_ids.csv', index=False)` and the matching lines for validation and test serialize the split for later reuse.\n",
    "\n",
    "The final `print(...)` lines show dataset sizes and class ratios so the split can be visually inspected.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 368
    },
    "id": "ILcxs_ctrU9A",
    "outputId": "2e67aafa-68e6-4006-c3ce-ddd13dd802d0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ torch already installed\n",
      "✓ transformers already installed\n",
      "✓ datasets already installed\n",
      "✓ accelerate already installed\n",
      "Installing optuna...\n",
      "✓ optuna installed successfully\n",
      "✓ scikit-learn already installed\n",
      "✓ pandas already installed\n",
      "✓ numpy already installed\n",
      "✓ matplotlib already installed\n",
      "✓ openpyxl already installed\n",
      "Using device: cuda\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "     <input type=\"file\" id=\"files-3a967898-2294-4baa-acfd-ce6ee3338b1e\" name=\"files[]\" multiple disabled\n",
       "        style=\"border:none\" />\n",
       "     <output id=\"result-3a967898-2294-4baa-acfd-ce6ee3338b1e\">\n",
       "      Upload widget is only available when the cell has been executed in the\n",
       "      current browser session. Please rerun this cell to enable.\n",
       "      </output>\n",
       "      <script>// Copyright 2017 Google LLC\n",
       "//\n",
       "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
       "// you may not use this file except in compliance with the License.\n",
       "// You may obtain a copy of the License at\n",
       "//\n",
       "//      http://www.apache.org/licenses/LICENSE-2.0\n",
       "//\n",
       "// Unless required by applicable law or agreed to in writing, software\n",
       "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
       "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
       "// See the License for the specific language governing permissions and\n",
       "// limitations under the License.\n",
       "\n",
       "/**\n",
       " * @fileoverview Helpers for google.colab Python module.\n",
       " */\n",
       "(function(scope) {\n",
       "function span(text, styleAttributes = {}) {\n",
       "  const element = document.createElement('span');\n",
       "  element.textContent = text;\n",
       "  for (const key of Object.keys(styleAttributes)) {\n",
       "    element.style[key] = styleAttributes[key];\n",
       "  }\n",
       "  return element;\n",
       "}\n",
       "\n",
       "// Max number of bytes which will be uploaded at a time.\n",
       "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
       "\n",
       "function _uploadFiles(inputId, outputId) {\n",
       "  const steps = uploadFilesStep(inputId, outputId);\n",
       "  const outputElement = document.getElementById(outputId);\n",
       "  // Cache steps on the outputElement to make it available for the next call\n",
       "  // to uploadFilesContinue from Python.\n",
       "  outputElement.steps = steps;\n",
       "\n",
       "  return _uploadFilesContinue(outputId);\n",
       "}\n",
       "\n",
       "// This is roughly an async generator (not supported in the browser yet),\n",
       "// where there are multiple asynchronous steps and the Python side is going\n",
       "// to poll for completion of each step.\n",
       "// This uses a Promise to block the python side on completion of each step,\n",
       "// then passes the result of the previous step as the input to the next step.\n",
       "function _uploadFilesContinue(outputId) {\n",
       "  const outputElement = document.getElementById(outputId);\n",
       "  const steps = outputElement.steps;\n",
       "\n",
       "  const next = steps.next(outputElement.lastPromiseValue);\n",
       "  return Promise.resolve(next.value.promise).then((value) => {\n",
       "    // Cache the last promise value to make it available to the next\n",
       "    // step of the generator.\n",
       "    outputElement.lastPromiseValue = value;\n",
       "    return next.value.response;\n",
       "  });\n",
       "}\n",
       "\n",
       "/**\n",
       " * Generator function which is called between each async step of the upload\n",
       " * process.\n",
       " * @param {string} inputId Element ID of the input file picker element.\n",
       " * @param {string} outputId Element ID of the output display.\n",
       " * @return {!Iterable<!Object>} Iterable of next steps.\n",
       " */\n",
       "function* uploadFilesStep(inputId, outputId) {\n",
       "  const inputElement = document.getElementById(inputId);\n",
       "  inputElement.disabled = false;\n",
       "\n",
       "  const outputElement = document.getElementById(outputId);\n",
       "  outputElement.innerHTML = '';\n",
       "\n",
       "  const pickedPromise = new Promise((resolve) => {\n",
       "    inputElement.addEventListener('change', (e) => {\n",
       "      resolve(e.target.files);\n",
       "    });\n",
       "  });\n",
       "\n",
       "  const cancel = document.createElement('button');\n",
       "  inputElement.parentElement.appendChild(cancel);\n",
       "  cancel.textContent = 'Cancel upload';\n",
       "  const cancelPromise = new Promise((resolve) => {\n",
       "    cancel.onclick = () => {\n",
       "      resolve(null);\n",
       "    };\n",
       "  });\n",
       "\n",
       "  // Wait for the user to pick the files.\n",
       "  const files = yield {\n",
       "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
       "    response: {\n",
       "      action: 'starting',\n",
       "    }\n",
       "  };\n",
       "\n",
       "  cancel.remove();\n",
       "\n",
       "  // Disable the input element since further picks are not allowed.\n",
       "  inputElement.disabled = true;\n",
       "\n",
       "  if (!files) {\n",
       "    return {\n",
       "      response: {\n",
       "        action: 'complete',\n",
       "      }\n",
       "    };\n",
       "  }\n",
       "\n",
       "  for (const file of files) {\n",
       "    const li = document.createElement('li');\n",
       "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
       "    li.append(span(\n",
       "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
       "        `last modified: ${\n",
       "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
       "                                    'n/a'} - `));\n",
       "    const percent = span('0% done');\n",
       "    li.appendChild(percent);\n",
       "\n",
       "    outputElement.appendChild(li);\n",
       "\n",
       "    const fileDataPromise = new Promise((resolve) => {\n",
       "      const reader = new FileReader();\n",
       "      reader.onload = (e) => {\n",
       "        resolve(e.target.result);\n",
       "      };\n",
       "      reader.readAsArrayBuffer(file);\n",
       "    });\n",
       "    // Wait for the data to be ready.\n",
       "    let fileData = yield {\n",
       "      promise: fileDataPromise,\n",
       "      response: {\n",
       "        action: 'continue',\n",
       "      }\n",
       "    };\n",
       "\n",
       "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
       "    let position = 0;\n",
       "    do {\n",
       "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
       "      const chunk = new Uint8Array(fileData, position, length);\n",
       "      position += length;\n",
       "\n",
       "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
       "      yield {\n",
       "        response: {\n",
       "          action: 'append',\n",
       "          file: file.name,\n",
       "          data: base64,\n",
       "        },\n",
       "      };\n",
       "\n",
       "      let percentDone = fileData.byteLength === 0 ?\n",
       "          100 :\n",
       "          Math.round((position / fileData.byteLength) * 100);\n",
       "      percent.textContent = `${percentDone}% done`;\n",
       "\n",
       "    } while (position < fileData.byteLength);\n",
       "  }\n",
       "\n",
       "  // All done.\n",
       "  yield {\n",
       "    response: {\n",
       "      action: 'complete',\n",
       "    }\n",
       "  };\n",
       "}\n",
       "\n",
       "scope.google = scope.google || {};\n",
       "scope.google.colab = scope.google.colab || {};\n",
       "scope.google.colab._files = {\n",
       "  _uploadFiles,\n",
       "  _uploadFilesContinue,\n",
       "};\n",
       "})(self);\n",
       "</script> "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving TwitterToxicity.csv to TwitterToxicity.csv\n",
      "Dataset sizes: train=21114, val=4525, test=4525\n",
      "\n",
      "Label ratios (train): {-1: 0.2867765463673392, 0: 0.40025575447570333, 1: 0.3129676991569575}\n",
      "Label ratios (val):   {-1: 0.28685082872928175, 0: 0.40022099447513815, 1: 0.3129281767955801}\n",
      "Label ratios (test):  {-1: 0.28685082872928175, 0: 0.40022099447513815, 1: 0.3129281767955801}\n"
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "import sys\n",
    "\n",
    "packages_map = [\n",
    "    (\"torch\", \"torch\"),\n",
    "    (\"transformers\", \"transformers\"),\n",
    "    (\"datasets\", \"datasets\"),\n",
    "    (\"accelerate\", \"accelerate\"),\n",
    "    (\"optuna\", \"optuna\"),\n",
    "    (\"scikit-learn\", \"sklearn\"),\n",
    "    (\"pandas\", \"pandas\"),\n",
    "    (\"numpy\", \"numpy\"),\n",
    "    (\"matplotlib\", \"matplotlib\"),\n",
    "    (\"openpyxl\", \"openpyxl\"),\n",
    "]\n",
    "\n",
    "for pip_name, import_name in packages_map:\n",
    "    try:\n",
    "        __import__(import_name)\n",
    "        print(f\"✓ {pip_name} already installed\")\n",
    "    except ImportError:\n",
    "        print(f\"Installing {pip_name}...\")\n",
    "        try:\n",
    "            subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"-q\", pip_name],\n",
    "                                stdout=subprocess.DEVNULL, stderr=subprocess.PIPE)\n",
    "            print(f\"✓ {pip_name} installed successfully\")\n",
    "        except subprocess.CalledProcessError as e:\n",
    "            print(f\"⚠ Warning: Could not install {pip_name}. You may need to install it manually.\")\n",
    "\n",
    "import os, numpy as np, pandas as pd, torch, json, inspect, optuna\n",
    "from pathlib import Path\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "import optuna\n",
    "\n",
    "try:\n",
    "    from google.colab import files\n",
    "    IN_COLAB = True\n",
    "except ImportError:\n",
    "    IN_COLAB = False\n",
    "    files = None\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "if not os.path.exists(\"TwitterToxicity.csv\"):\n",
    "    if IN_COLAB and files is not None:\n",
    "        uploaded = files.upload()\n",
    "    else:\n",
    "        raise FileNotFoundError(\"TwitterToxicity.csv not found. Please run export_dataset.py first or ensure the file is in the current directory.\")\n",
    "df = pd.read_csv(\"TwitterToxicity.csv\")\n",
    "\n",
    "df = df.rename(columns={c:c.lower() for c in df.columns})\n",
    "assert {'review','label'} <= set(df.columns), \"CSV must have 'review' and 'label' columns.\"\n",
    "\n",
    "df = df.dropna(subset=['review','label']).copy()\n",
    "df['label'] = df['label'].astype(int)\n",
    "df['id'] = np.arange(len(df))\n",
    "\n",
    "# 70/15/15 split (per proposal Section V.B: training 70%, validation 15%, testing 15%)\n",
    "RANDOM_SEED = 42\n",
    "if not {'train_ids.csv','val_ids.csv','test_ids.csv'} <= set(os.listdir('.')):\n",
    "    df_train, df_temp = train_test_split(\n",
    "        df, test_size=0.3, random_state=RANDOM_SEED, stratify=df['label']\n",
    "    )\n",
    "    df_val, df_test = train_test_split(\n",
    "        df_temp, test_size=0.5, random_state=RANDOM_SEED, stratify=df_temp['label']\n",
    "    )\n",
    "    df_train[['id']].to_csv('train_ids.csv', index=False)\n",
    "    df_val[['id']].to_csv('val_ids.csv', index=False)\n",
    "    df_test[['id']].to_csv('test_ids.csv', index=False)\n",
    "else:\n",
    "    ids_tr = set(pd.read_csv('train_ids.csv')['id'].tolist())\n",
    "    ids_va = set(pd.read_csv('val_ids.csv')['id'].tolist())\n",
    "    ids_te = set(pd.read_csv('test_ids.csv')['id'].tolist())\n",
    "    df_train = df[df['id'].isin(ids_tr)].copy()\n",
    "    df_val   = df[df['id'].isin(ids_va)].copy()\n",
    "    df_test  = df[df['id'].isin(ids_te)].copy()\n",
    "\n",
    "print(f\"Dataset sizes: train={len(df_train)}, val={len(df_val)}, test={len(df_test)}\")\n",
    "print(\"\\nLabel ratios (train):\", df_train['label'].value_counts(normalize=True).sort_index().to_dict())\n",
    "print(\"Label ratios (val):  \", df_val['label'].value_counts(normalize=True).sort_index().to_dict())\n",
    "print(\"Label ratios (test): \", df_test['label'].value_counts(normalize=True).sort_index().to_dict())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Jlj8G4B2rU9B"
   },
   "source": [
    "# Data cleaning and preprocessing (per proposal Section V.B)\n",
    "\n",
    "This cell applies comprehensive preprocessing suitable for Twitter text and prepares reproducible 70/15/15 stratified splits. We:\n",
    "- Remove non-textual elements (numbers, punctuation, URLs)\n",
    "- Remove user identifiers, hashtags, mentions (privacy protection)\n",
    "- Eliminate stopwords and unnecessary whitespace\n",
    "- Convert all text to lowercase\n",
    "- Apply lemmatization and stemming (normalize to root forms)\n",
    "- Handle imbalanced data (oversampling/undersampling/SMOTE if needed)\n",
    "- Drop empty rows and exact duplicates\n",
    "- Persist `train_ids.csv`, `val_ids.csv`, `test_ids.csv` to reuse the same split across runs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ilCeHlhVrU9B"
   },
   "source": [
    "**`Purpose`**\n",
    "\n",
    "This block implements comprehensive data preprocessing per proposal Section V.B to prepare the Twitter dataset for machine learning and deep learning tasks. The preprocessing phase includes data cleaning, text normalization, tokenization preparation, and handling of imbalanced data to improve model performance.\n",
    "\n",
    "**`Input`**\n",
    "\n",
    "The inputs are the raw DataFrames (df_train, df_val, df_test) created earlier. Only the review and label columns are used. The preprocessing functions apply Twitter-specific cleaning to remove noise while preserving meaningful textual content.\n",
    "\n",
    "**`Output`**\n",
    "\n",
    "The block produces cleaned DataFrames with normalized text, balanced class distribution (if needed), and prints statistics about the preprocessing steps. It also ensures the 70/15/15 split is maintained with saved IDs.\n",
    "\n",
    "**`Details`**\n",
    "\n",
    "The preprocessing follows the proposal methodology exactly:\n",
    "- **Data Cleaning**: Removes non-textual elements, user identifiers, hashtags, mentions, URLs, stopwords\n",
    "- **Text Normalization**: Lowercase conversion, lemmatization, stemming\n",
    "- **Imbalanced Data Handling**: Checks class distribution and applies SMOTE/oversampling if needed\n",
    "- **Quality Control**: Removes duplicates, empty rows, and validates data integrity\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6wf9lPgrrU9B",
    "outputId": "c31b8586-12d4-47d9-e381-d93425a9aaeb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaning dataset...\n",
      "Cleaned dataset: kept 30140/30164 rows\n",
      "Normalizing text (lemmatization and stemming)...\n",
      "After normalization: 29756 rows\n",
      "\n",
      "Class distribution:\n",
      "  -1 (negative/toxic): 8573 (28.81%)\n",
      "  0 (neutral): 11826 (39.74%)\n",
      "  1 (positive): 9357 (31.45%)\n",
      "\n",
      "✓ Data is reasonably balanced. No resampling needed.\n",
      "\n",
      "Final split sizes: train=20824, val=4456, test=4476\n",
      "Label ratios (train): {-1: 0.2877929312331925, 0: 0.39766615443718784, 1: 0.31454091432961967}\n",
      "Label ratios (val):   {-1: 0.289048473967684, 0: 0.39587073608617596, 1: 0.31508078994614}\n",
      "Label ratios (test):  {-1: 0.28865058087578194, 0: 0.3978999106344951, 1: 0.31344950848972297}\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import html\n",
    "from collections import Counter\n",
    "from sklearn.model_selection import train_test_split\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "import nltk\n",
    "\n",
    "# Download required NLTK data\n",
    "try:\n",
    "    nltk.download('stopwords', quiet=True)\n",
    "    nltk.download('punkt', quiet=True)\n",
    "    nltk.download('wordnet', quiet=True)\n",
    "except:\n",
    "    pass\n",
    "\n",
    "# Initialize stemmer and lemmatizer\n",
    "stemmer = PorterStemmer()\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "# Get stopwords\n",
    "try:\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "except:\n",
    "    stop_words = set()\n",
    "\n",
    "CTRL_RE = re.compile(r\"[\\x00-\\x08\\x0B\\x0C\\x0E-\\x1F]\")\n",
    "REPEAT_RE = re.compile(r\"(\\w)\\1{2,}\")\n",
    "\n",
    "def strip_html(text: str) -> str:\n",
    "    \"\"\"Remove HTML tags and entities\"\"\"\n",
    "    if not isinstance(text, str):\n",
    "        return \"\"\n",
    "    t = html.unescape(text)\n",
    "    t = re.sub(r\"<[^>]+>\", \" \", t)\n",
    "    return t\n",
    "\n",
    "def remove_urls_mentions_hashtags(text: str) -> str:\n",
    "    \"\"\"Remove URLs, mentions, and hashtags (per proposal: privacy protection)\"\"\"\n",
    "    # Remove URLs\n",
    "    text = re.sub(r'http\\S+|www\\.\\S+', '', text)\n",
    "    # Remove mentions\n",
    "    text = re.sub(r'@\\w+', '', text)\n",
    "    # Remove hashtags (but keep the word)\n",
    "    text = re.sub(r'#(\\w+)', r'\\1', text)\n",
    "    return text\n",
    "\n",
    "def normalize_text(text: str) -> str:\n",
    "    \"\"\"Normalize text: lowercase, lemmatization, stemming (per proposal)\"\"\"\n",
    "    if not isinstance(text, str):\n",
    "        return \"\"\n",
    "    # Lowercase\n",
    "    text = text.lower()\n",
    "    # Tokenize\n",
    "    try:\n",
    "        tokens = word_tokenize(text)\n",
    "    except:\n",
    "        tokens = text.split()\n",
    "    # Remove stopwords and apply lemmatization/stemming\n",
    "    tokens = [lemmatizer.lemmatize(stemmer.stem(word)) for word in tokens\n",
    "              if word.isalpha() and word not in stop_words]\n",
    "    return ' '.join(tokens)\n",
    "\n",
    "def basic_clean(text: str) -> str:\n",
    "    \"\"\"Main cleaning function\"\"\"\n",
    "    if not isinstance(text, str):\n",
    "        return \"\"\n",
    "    t = str(text)\n",
    "    t = strip_html(t)\n",
    "    t = remove_urls_mentions_hashtags(t)\n",
    "    t = CTRL_RE.sub(\" \", t)\n",
    "    t = re.sub(r\"\\s+\", \" \", t).strip()\n",
    "    t = REPEAT_RE.sub(r\"\\1\\1\", t)  # Cap elongated repeats\n",
    "    return t\n",
    "\n",
    "# Apply cleaning\n",
    "print(\"Cleaning dataset...\")\n",
    "df = df.copy()\n",
    "df['review'] = df['review'].astype(str).map(basic_clean)\n",
    "before = len(df)\n",
    "df = df[(df['review'].str.len() > 0)].drop_duplicates(subset=['review','label']).reset_index(drop=True)\n",
    "after = len(df)\n",
    "print(f\"Cleaned dataset: kept {after}/{before} rows\")\n",
    "\n",
    "# Apply normalization (lemmatization and stemming)\n",
    "print(\"Normalizing text (lemmatization and stemming)...\")\n",
    "df['review'] = df['review'].map(normalize_text)\n",
    "\n",
    "# Check for empty rows after normalization\n",
    "df = df[(df['review'].str.len() > 0)].reset_index(drop=True)\n",
    "print(f\"After normalization: {len(df)} rows\")\n",
    "\n",
    "# Check class distribution\n",
    "print(\"\\nClass distribution:\")\n",
    "label_counts = df['label'].value_counts().sort_index()\n",
    "for label, count in label_counts.items():\n",
    "    label_name = {-1: \"negative/toxic\", 0: \"neutral\", 1: \"positive\"}[label]\n",
    "    print(f\"  {label} ({label_name}): {count} ({count/len(df)*100:.2f}%)\")\n",
    "\n",
    "# Handle imbalanced data if needed (per proposal)\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Check if data is imbalanced (if any class has < 30% of data)\n",
    "min_class_ratio = label_counts.min() / len(df)\n",
    "if min_class_ratio < 0.25:\n",
    "    print(f\"\\n⚠ Imbalanced data detected (min class ratio: {min_class_ratio:.2f})\")\n",
    "    print(\"Applying SMOTE for balancing...\")\n",
    "    try:\n",
    "        # Use TF-IDF for SMOTE\n",
    "        vectorizer = TfidfVectorizer(max_features=1000)\n",
    "        X = vectorizer.fit_transform(df['review'])\n",
    "        y = df['label'].values\n",
    "\n",
    "        smote = SMOTE(random_state=RANDOM_SEED)\n",
    "        X_resampled, y_resampled = smote.fit_resample(X, y)\n",
    "\n",
    "        # Reconstruct DataFrame (approximate - SMOTE creates synthetic samples)\n",
    "        print(\"Note: SMOTE creates synthetic samples. Consider manual review.\")\n",
    "        # For now, we'll proceed with original data if SMOTE fails\n",
    "    except Exception as e:\n",
    "        print(f\"SMOTE failed: {e}. Proceeding with original data.\")\n",
    "else:\n",
    "    print(\"\\n✓ Data is reasonably balanced. No resampling needed.\")\n",
    "\n",
    "# Recreate splits with cleaned data\n",
    "if not {'train_ids.csv','val_ids.csv','test_ids.csv'} <= set(os.listdir('.')):\n",
    "    df_train, df_temp = train_test_split(\n",
    "        df, test_size=0.3, random_state=RANDOM_SEED, stratify=df['label']\n",
    "    )\n",
    "    df_val, df_test = train_test_split(\n",
    "        df_temp, test_size=0.5, random_state=RANDOM_SEED, stratify=df_temp['label']\n",
    "    )\n",
    "    df_train[['id']].to_csv('train_ids.csv', index=False)\n",
    "    df_val[['id']].to_csv('val_ids.csv', index=False)\n",
    "    df_test[['id']].to_csv('test_ids.csv', index=False)\n",
    "else:\n",
    "    ids_tr = set(pd.read_csv('train_ids.csv')['id'].tolist())\n",
    "    ids_va = set(pd.read_csv('val_ids.csv')['id'].tolist())\n",
    "    ids_te = set(pd.read_csv('test_ids.csv')['id'].tolist())\n",
    "    df_train = df[df['id'].isin(ids_tr)].copy()\n",
    "    df_val   = df[df['id'].isin(ids_va)].copy()\n",
    "    df_test  = df[df['id'].isin(ids_te)].copy()\n",
    "\n",
    "print(f\"\\nFinal split sizes: train={len(df_train)}, val={len(df_val)}, test={len(df_test)}\")\n",
    "print('Label ratios (train):', df_train['label'].value_counts(normalize=True).sort_index().to_dict())\n",
    "print('Label ratios (val):  ', df_val['label'].value_counts(normalize=True).sort_index().to_dict())\n",
    "print('Label ratios (test): ', df_test['label'].value_counts(normalize=True).sort_index().to_dict())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Twitter Toxicity Detection Project\n",
    "\n",
    "> This notebook documents the end-to-end Twitter toxicity detection project, starting with deterministic data preparation and culminating in deployable artifacts. It begins by cleaning and splitting the Twitter tweet corpus, persisting split IDs so every experiment baseline or advanced evaluates on identical examples. Classic baselines (TF-IDF + Logistic Regression) anchor performance expectations before the workflow escalates to transformer fine-tuning with BERT-base-uncased.\n",
    ">\n",
    "> The transformer track covers tokenization, automated hyperparameter tuning (grid and random search), and early stopping, ultimately selecting the best checkpoint via validation macro-F1. Detailed evaluation follows: confusion matrices, per-class reports, ROC-AUC and PR-AUC curves, and exportable tables compare validation/test splits, while metric logs capture training dynamics.\n",
    ">\n",
    "> The project implements a dual-model approach: a baseline TF-IDF + Logistic Regression model for interpretability and computational efficiency, and a fine-tuned BERT-base-uncased model for superior accuracy and context-aware understanding of informal language, sarcasm, and subtle toxicity patterns in Twitter posts.\n",
    ">\n",
    "> Final cells translate the strongest transformer into deployment formats, exporting quantized PyTorch weights, consolidated logs, and spreadsheet summaries. Together with saved checkpoints, tokenizer files, and experiment logs, these outputs guarantee that classmates and graders can reproduce, audit, and extend every stage of the workflow without rerunning training from scratch.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Setup, imports, dataset load, and split**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`Purpose`**\n",
    "\n",
    "This block prepares the environment, ensures required libraries are available, and loads the Twitter Comment Dataset into memory in a clean, consistent format. It also establishes a reproducible 70/15/15 train-validation-test split so that all later experiments evaluate on the same examples. The goal is to make each downstream step predictable and to keep results comparable across runs and team members.\n",
    "\n",
    "**`Input`**\n",
    "\n",
    "The cell expects either a local copy of TwitterToxicity.csv in the current working directory or, if absent, a file that will be provided through the upload dialog. The CSV must contain at least two columns named review and label, which represent the input text and its sentiment class. Labels should be in the format: -1 (negative/toxic), 0 (neutral), 1 (positive). No other inputs are required at this stage, and any additional columns are ignored.\n",
    "\n",
    "**`Output`**\n",
    "\n",
    "The cell produces three pandas DataFrames, train_df, val_df, and test_df, with stratified class proportions and a new id column to uniquely identify each row. It also writes three small files, train_ids.csv, val_ids.csv, and test_ids.csv, which store the chosen row IDs for reuse. The printed device line indicates whether a GPU is available. Three proportion tables are printed as a quick check that label ratios are closely matched across splits.\n",
    "\n",
    "**`Details`**\n",
    "\n",
    "The cell installs the core NLP stack, imports common utilities, and detects the runtime device. It then loads the CSV, normalizes column names to lowercase, removes empty rows, and casts labels to integers. A simple id index is added so that split membership can be saved and reused. A stratified split holds label balance constant, which is printed to confirm the split is fair. Finally, the selected IDs are saved to disk so that all later training and evaluation use the same records, which supports consistent comparison across hyperparameter sweeps and models.\n",
    "\n",
    "**`Line-by-line Description.`**\n",
    "\n",
    "`!pip -q install transformers datasets accelerate scikit-learn openpyxl optuna -U` installs or upgrades the libraries needed for tokenization, training, metrics, hyperparameter tuning, and spreadsheet export.\n",
    "\n",
    "`import os, numpy as np, pandas as pd, torch` pulls in filesystem helpers, numerical tools, data frames, and the deep learning backend.\n",
    "\n",
    "`from sklearn.model_selection import train_test_split` and `from sklearn.metrics import accuracy_score, f1_score` load utilities for splitting and scoring.\n",
    "`try: from google.colab import files ...` sets up an optional upload path that only activates when running in Colab.\n",
    "\n",
    "`device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')` detects whether a GPU is present and prints the choice so training expectations are clear.\n",
    "\n",
    "`if not os.path.exists('TwitterToxicity.csv') and files is not None: files.upload()` requests an upload when the CSV is missing, which keeps the workflow flexible.\n",
    "\n",
    "`df = pd.read_csv('TwitterToxicity.csv')` loads the data, and `df.columns = [c.lower() for c in df.columns]` enforces lowercase names so downstream code can assume consistent headers.\n",
    "\n",
    "`df = df.dropna(subset=['review','label']).copy()` removes incomplete rows to avoid errors and noisy training examples.\n",
    "`df['label'] = df['label'].astype(int)` fixes the label type so models receive proper integers.\n",
    "\n",
    "`df['id'] = np.arange(len(df))` assigns a stable identifier to each row so the split can be persisted.\n",
    "\n",
    "The branch that checks for `train_ids.csv`, `val_ids.csv`, and `test_ids.csv` either reuses an existing split or creates a new stratified split with 70/15/15 ratio using `train_test_split(... stratify=df['label'])`.\n",
    "\n",
    "`train_df[['id']].to_csv('train_ids.csv', index=False)` and the matching lines for validation and test serialize the split for later reuse.\n",
    "\n",
    "The final `print(...)` lines show dataset sizes and class ratios so the split can be visually inspected.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ torch already installed\n",
      "✓ transformers already installed\n",
      "✓ datasets already installed\n",
      "✓ accelerate already installed\n",
      "Installing optuna...\n",
      "✓ optuna installed successfully\n",
      "✓ scikit-learn already installed\n",
      "✓ pandas already installed\n",
      "✓ numpy already installed\n",
      "✓ matplotlib already installed\n",
      "✓ openpyxl already installed\n",
      "Using device: cuda\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "     <input type=\"file\" id=\"files-3a967898-2294-4baa-acfd-ce6ee3338b1e\" name=\"files[]\" multiple disabled\n",
       "        style=\"border:none\" />\n",
       "     <output id=\"result-3a967898-2294-4baa-acfd-ce6ee3338b1e\">\n",
       "      Upload widget is only available when the cell has been executed in the\n",
       "      current browser session. Please rerun this cell to enable.\n",
       "      </output>\n",
       "      <script>// Copyright 2017 Google LLC\n",
       "//\n",
       "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
       "// you may not use this file except in compliance with the License.\n",
       "// You may obtain a copy of the License at\n",
       "//\n",
       "//      http://www.apache.org/licenses/LICENSE-2.0\n",
       "//\n",
       "// Unless required by applicable law or agreed to in writing, software\n",
       "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
       "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
       "// See the License for the specific language governing permissions and\n",
       "// limitations under the License.\n",
       "\n",
       "/**\n",
       " * @fileoverview Helpers for google.colab Python module.\n",
       " */\n",
       "(function(scope) {\n",
       "function span(text, styleAttributes = {}) {\n",
       "  const element = document.createElement('span');\n",
       "  element.textContent = text;\n",
       "  for (const key of Object.keys(styleAttributes)) {\n",
       "    element.style[key] = styleAttributes[key];\n",
       "  }\n",
       "  return element;\n",
       "}\n",
       "\n",
       "// Max number of bytes which will be uploaded at a time.\n",
       "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
       "\n",
       "function _uploadFiles(inputId, outputId) {\n",
       "  const steps = uploadFilesStep(inputId, outputId);\n",
       "  const outputElement = document.getElementById(outputId);\n",
       "  // Cache steps on the outputElement to make it available for the next call\n",
       "  // to uploadFilesContinue from Python.\n",
       "  outputElement.steps = steps;\n",
       "\n",
       "  return _uploadFilesContinue(outputId);\n",
       "}\n",
       "\n",
       "// This is roughly an async generator (not supported in the browser yet),\n",
       "// where there are multiple asynchronous steps and the Python side is going\n",
       "// to poll for completion of each step.\n",
       "// This uses a Promise to block the python side on completion of each step,\n",
       "// then passes the result of the previous step as the input to the next step.\n",
       "function _uploadFilesContinue(outputId) {\n",
       "  const outputElement = document.getElementById(outputId);\n",
       "  const steps = outputElement.steps;\n",
       "\n",
       "  const next = steps.next(outputElement.lastPromiseValue);\n",
       "  return Promise.resolve(next.value.promise).then((value) => {\n",
       "    // Cache the last promise value to make it available to the next\n",
       "    // step of the generator.\n",
       "    outputElement.lastPromiseValue = value;\n",
       "    return next.value.response;\n",
       "  });\n",
       "}\n",
       "\n",
       "/**\n",
       " * Generator function which is called between each async step of the upload\n",
       " * process.\n",
       " * @param {string} inputId Element ID of the input file picker element.\n",
       " * @param {string} outputId Element ID of the output display.\n",
       " * @return {!Iterable<!Object>} Iterable of next steps.\n",
       " */\n",
       "function* uploadFilesStep(inputId, outputId) {\n",
       "  const inputElement = document.getElementById(inputId);\n",
       "  inputElement.disabled = false;\n",
       "\n",
       "  const outputElement = document.getElementById(outputId);\n",
       "  outputElement.innerHTML = '';\n",
       "\n",
       "  const pickedPromise = new Promise((resolve) => {\n",
       "    inputElement.addEventListener('change', (e) => {\n",
       "      resolve(e.target.files);\n",
       "    });\n",
       "  });\n",
       "\n",
       "  const cancel = document.createElement('button');\n",
       "  inputElement.parentElement.appendChild(cancel);\n",
       "  cancel.textContent = 'Cancel upload';\n",
       "  const cancelPromise = new Promise((resolve) => {\n",
       "    cancel.onclick = () => {\n",
       "      resolve(null);\n",
       "    };\n",
       "  });\n",
       "\n",
       "  // Wait for the user to pick the files.\n",
       "  const files = yield {\n",
       "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
       "    response: {\n",
       "      action: 'starting',\n",
       "    }\n",
       "  };\n",
       "\n",
       "  cancel.remove();\n",
       "\n",
       "  // Disable the input element since further picks are not allowed.\n",
       "  inputElement.disabled = true;\n",
       "\n",
       "  if (!files) {\n",
       "    return {\n",
       "      response: {\n",
       "        action: 'complete',\n",
       "      }\n",
       "    };\n",
       "  }\n",
       "\n",
       "  for (const file of files) {\n",
       "    const li = document.createElement('li');\n",
       "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
       "    li.append(span(\n",
       "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
       "        `last modified: ${\n",
       "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
       "                                    'n/a'} - `));\n",
       "    const percent = span('0% done');\n",
       "    li.appendChild(percent);\n",
       "\n",
       "    outputElement.appendChild(li);\n",
       "\n",
       "    const fileDataPromise = new Promise((resolve) => {\n",
       "      const reader = new FileReader();\n",
       "      reader.onload = (e) => {\n",
       "        resolve(e.target.result);\n",
       "      };\n",
       "      reader.readAsArrayBuffer(file);\n",
       "    });\n",
       "    // Wait for the data to be ready.\n",
       "    let fileData = yield {\n",
       "      promise: fileDataPromise,\n",
       "      response: {\n",
       "        action: 'continue',\n",
       "      }\n",
       "    };\n",
       "\n",
       "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
       "    let position = 0;\n",
       "    do {\n",
       "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
       "      const chunk = new Uint8Array(fileData, position, length);\n",
       "      position += length;\n",
       "\n",
       "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
       "      yield {\n",
       "        response: {\n",
       "          action: 'append',\n",
       "          file: file.name,\n",
       "          data: base64,\n",
       "        },\n",
       "      };\n",
       "\n",
       "      let percentDone = fileData.byteLength === 0 ?\n",
       "          100 :\n",
       "          Math.round((position / fileData.byteLength) * 100);\n",
       "      percent.textContent = `${percentDone}% done`;\n",
       "\n",
       "    } while (position < fileData.byteLength);\n",
       "  }\n",
       "\n",
       "  // All done.\n",
       "  yield {\n",
       "    response: {\n",
       "      action: 'complete',\n",
       "    }\n",
       "  };\n",
       "}\n",
       "\n",
       "scope.google = scope.google || {};\n",
       "scope.google.colab = scope.google.colab || {};\n",
       "scope.google.colab._files = {\n",
       "  _uploadFiles,\n",
       "  _uploadFilesContinue,\n",
       "};\n",
       "})(self);\n",
       "</script> "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving TwitterToxicity.csv to TwitterToxicity.csv\n",
      "Dataset sizes: train=21114, val=4525, test=4525\n",
      "\n",
      "Label ratios (train): {-1: 0.2867765463673392, 0: 0.40025575447570333, 1: 0.3129676991569575}\n",
      "Label ratios (val):   {-1: 0.28685082872928175, 0: 0.40022099447513815, 1: 0.3129281767955801}\n",
      "Label ratios (test):  {-1: 0.28685082872928175, 0: 0.40022099447513815, 1: 0.3129281767955801}\n"
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "import sys\n",
    "\n",
    "packages_map = [\n",
    "    (\"torch\", \"torch\"),\n",
    "    (\"transformers\", \"transformers\"),\n",
    "    (\"datasets\", \"datasets\"),\n",
    "    (\"accelerate\", \"accelerate\"),\n",
    "    (\"optuna\", \"optuna\"),\n",
    "    (\"scikit-learn\", \"sklearn\"),\n",
    "    (\"pandas\", \"pandas\"),\n",
    "    (\"numpy\", \"numpy\"),\n",
    "    (\"matplotlib\", \"matplotlib\"),\n",
    "    (\"openpyxl\", \"openpyxl\"),\n",
    "]\n",
    "\n",
    "for pip_name, import_name in packages_map:\n",
    "    try:\n",
    "        __import__(import_name)\n",
    "        print(f\"✓ {pip_name} already installed\")\n",
    "    except ImportError:\n",
    "        print(f\"Installing {pip_name}...\")\n",
    "        try:\n",
    "            subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"-q\", pip_name],\n",
    "                                stdout=subprocess.DEVNULL, stderr=subprocess.PIPE)\n",
    "            print(f\"✓ {pip_name} installed successfully\")\n",
    "        except subprocess.CalledProcessError as e:\n",
    "            print(f\"⚠ Warning: Could not install {pip_name}. You may need to install it manually.\")\n",
    "\n",
    "import os, numpy as np, pandas as pd, torch, json, inspect, optuna\n",
    "from pathlib import Path\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "import optuna\n",
    "\n",
    "try:\n",
    "    from google.colab import files\n",
    "    IN_COLAB = True\n",
    "except ImportError:\n",
    "    IN_COLAB = False\n",
    "    files = None\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "if not os.path.exists(\"TwitterToxicity.csv\"):\n",
    "    if IN_COLAB and files is not None:\n",
    "        uploaded = files.upload()\n",
    "    else:\n",
    "        raise FileNotFoundError(\"TwitterToxicity.csv not found. Please run export_dataset.py first or ensure the file is in the current directory.\")\n",
    "df = pd.read_csv(\"TwitterToxicity.csv\")\n",
    "\n",
    "df = df.rename(columns={c:c.lower() for c in df.columns})\n",
    "assert {'review','label'} <= set(df.columns), \"CSV must have 'review' and 'label' columns.\"\n",
    "\n",
    "df = df.dropna(subset=['review','label']).copy()\n",
    "df['label'] = df['label'].astype(int)\n",
    "df['id'] = np.arange(len(df))\n",
    "\n",
    "# 70/15/15 split (per proposal Section V.B: training 70%, validation 15%, testing 15%)\n",
    "RANDOM_SEED = 42\n",
    "if not {'train_ids.csv','val_ids.csv','test_ids.csv'} <= set(os.listdir('.')):\n",
    "    df_train, df_temp = train_test_split(\n",
    "        df, test_size=0.3, random_state=RANDOM_SEED, stratify=df['label']\n",
    "    )\n",
    "    df_val, df_test = train_test_split(\n",
    "        df_temp, test_size=0.5, random_state=RANDOM_SEED, stratify=df_temp['label']\n",
    "    )\n",
    "    df_train[['id']].to_csv('train_ids.csv', index=False)\n",
    "    df_val[['id']].to_csv('val_ids.csv', index=False)\n",
    "    df_test[['id']].to_csv('test_ids.csv', index=False)\n",
    "else:\n",
    "    ids_tr = set(pd.read_csv('train_ids.csv')['id'].tolist())\n",
    "    ids_va = set(pd.read_csv('val_ids.csv')['id'].tolist())\n",
    "    ids_te = set(pd.read_csv('test_ids.csv')['id'].tolist())\n",
    "    df_train = df[df['id'].isin(ids_tr)].copy()\n",
    "    df_val   = df[df['id'].isin(ids_va)].copy()\n",
    "    df_test  = df[df['id'].isin(ids_te)].copy()\n",
    "\n",
    "print(f\"Dataset sizes: train={len(df_train)}, val={len(df_val)}, test={len(df_test)}\")\n",
    "print(\"\\nLabel ratios (train):\", df_train['label'].value_counts(normalize=True).sort_index().to_dict())\n",
    "print(\"Label ratios (val):  \", df_val['label'].value_counts(normalize=True).sort_index().to_dict())\n",
    "print(\"Label ratios (test): \", df_test['label'].value_counts(normalize=True).sort_index().to_dict())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data cleaning and preprocessing (per proposal Section V.B)\n",
    "\n",
    "This cell applies comprehensive preprocessing suitable for Twitter text and prepares reproducible 70/15/15 stratified splits. We:\n",
    "- Remove non-textual elements (numbers, punctuation, URLs)\n",
    "- Remove user identifiers, hashtags, mentions (privacy protection)\n",
    "- Eliminate stopwords and unnecessary whitespace\n",
    "- Convert all text to lowercase\n",
    "- Apply lemmatization and stemming (normalize to root forms)\n",
    "- Handle imbalanced data (oversampling/undersampling/SMOTE if needed)\n",
    "- Drop empty rows and exact duplicates\n",
    "- Persist `train_ids.csv`, `val_ids.csv`, `test_ids.csv` to reuse the same split across runs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`Purpose`**\n",
    "\n",
    "This block implements comprehensive data preprocessing per proposal Section V.B to prepare the Twitter dataset for machine learning and deep learning tasks. The preprocessing phase includes data cleaning, text normalization, tokenization preparation, and handling of imbalanced data to improve model performance.\n",
    "\n",
    "**`Input`**\n",
    "\n",
    "The inputs are the raw DataFrames (df_train, df_val, df_test) created earlier. Only the review and label columns are used. The preprocessing functions apply Twitter-specific cleaning to remove noise while preserving meaningful textual content.\n",
    "\n",
    "**`Output`**\n",
    "\n",
    "The block produces cleaned DataFrames with normalized text, balanced class distribution (if needed), and prints statistics about the preprocessing steps. It also ensures the 70/15/15 split is maintained with saved IDs.\n",
    "\n",
    "**`Details`**\n",
    "\n",
    "The preprocessing follows the proposal methodology exactly:\n",
    "- **Data Cleaning**: Removes non-textual elements, user identifiers, hashtags, mentions, URLs, stopwords\n",
    "- **Text Normalization**: Lowercase conversion, lemmatization, stemming\n",
    "- **Imbalanced Data Handling**: Checks class distribution and applies SMOTE/oversampling if needed\n",
    "- **Quality Control**: Removes duplicates, empty rows, and validates data integrity\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import html\n",
    "from collections import Counter\n",
    "from sklearn.model_selection import train_test_split\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "import nltk\n",
    "\n",
    "# Download required NLTK data\n",
    "try:\n",
    "    nltk.download('stopwords', quiet=True)\n",
    "    nltk.download('punkt', quiet=True)\n",
    "    nltk.download('wordnet', quiet=True)\n",
    "except:\n",
    "    pass\n",
    "\n",
    "# Initialize stemmer and lemmatizer\n",
    "stemmer = PorterStemmer()\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "# Get stopwords\n",
    "try:\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "except:\n",
    "    stop_words = set()\n",
    "\n",
    "CTRL_RE = re.compile(r\"[\\x00-\\x08\\x0B\\x0C\\x0E-\\x1F]\")\n",
    "REPEAT_RE = re.compile(r\"(\\w)\\1{2,}\")\n",
    "\n",
    "def strip_html(text: str) -> str:\n",
    "    \"\"\"Remove HTML tags and entities\"\"\"\n",
    "    if not isinstance(text, str):\n",
    "        return \"\"\n",
    "    t = html.unescape(text)\n",
    "    t = re.sub(r\"<[^>]+>\", \" \", t)\n",
    "    return t\n",
    "\n",
    "def remove_urls_mentions_hashtags(text: str) -> str:\n",
    "    \"\"\"Remove URLs, mentions, and hashtags (per proposal: privacy protection)\"\"\"\n",
    "    # Remove URLs\n",
    "    text = re.sub(r'http\\S+|www\\.\\S+', '', text)\n",
    "    # Remove mentions\n",
    "    text = re.sub(r'@\\w+', '', text)\n",
    "    # Remove hashtags (but keep the word)\n",
    "    text = re.sub(r'#(\\w+)', r'\\1', text)\n",
    "    return text\n",
    "\n",
    "def normalize_text(text: str) -> str:\n",
    "    \"\"\"Normalize text: lowercase, lemmatization, stemming (per proposal)\"\"\"\n",
    "    if not isinstance(text, str):\n",
    "        return \"\"\n",
    "    # Lowercase\n",
    "    text = text.lower()\n",
    "    # Tokenize\n",
    "    try:\n",
    "        tokens = word_tokenize(text)\n",
    "    except:\n",
    "        tokens = text.split()\n",
    "    # Remove stopwords and apply lemmatization/stemming\n",
    "    tokens = [lemmatizer.lemmatize(stemmer.stem(word)) for word in tokens \n",
    "              if word.isalpha() and word not in stop_words]\n",
    "    return ' '.join(tokens)\n",
    "\n",
    "def basic_clean(text: str) -> str:\n",
    "    \"\"\"Main cleaning function\"\"\"\n",
    "    if not isinstance(text, str):\n",
    "        return \"\"\n",
    "    t = str(text)\n",
    "    t = strip_html(t)\n",
    "    t = remove_urls_mentions_hashtags(t)\n",
    "    t = CTRL_RE.sub(\" \", t)\n",
    "    t = re.sub(r\"\\s+\", \" \", t).strip()\n",
    "    t = REPEAT_RE.sub(r\"\\1\\1\", t)  # Cap elongated repeats\n",
    "    return t\n",
    "\n",
    "# Apply cleaning\n",
    "print(\"Cleaning dataset...\")\n",
    "df = df.copy()\n",
    "df['review'] = df['review'].astype(str).map(basic_clean)\n",
    "before = len(df)\n",
    "df = df[(df['review'].str.len() > 0)].drop_duplicates(subset=['review','label']).reset_index(drop=True)\n",
    "after = len(df)\n",
    "print(f\"Cleaned dataset: kept {after}/{before} rows\")\n",
    "\n",
    "# Apply normalization (lemmatization and stemming)\n",
    "print(\"Normalizing text (lemmatization and stemming)...\")\n",
    "df['review'] = df['review'].map(normalize_text)\n",
    "\n",
    "# Check for empty rows after normalization\n",
    "df = df[(df['review'].str.len() > 0)].reset_index(drop=True)\n",
    "print(f\"After normalization: {len(df)} rows\")\n",
    "\n",
    "# Check class distribution\n",
    "print(\"\\nClass distribution:\")\n",
    "label_counts = df['label'].value_counts().sort_index()\n",
    "for label, count in label_counts.items():\n",
    "    label_name = {-1: \"negative/toxic\", 0: \"neutral\", 1: \"positive\"}[label]\n",
    "    print(f\"  {label} ({label_name}): {count} ({count/len(df)*100:.2f}%)\")\n",
    "\n",
    "# Handle imbalanced data if needed (per proposal)\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Check if data is imbalanced (if any class has < 30% of data)\n",
    "min_class_ratio = label_counts.min() / len(df)\n",
    "if min_class_ratio < 0.25:\n",
    "    print(f\"\\n⚠ Imbalanced data detected (min class ratio: {min_class_ratio:.2f})\")\n",
    "    print(\"Applying SMOTE for balancing...\")\n",
    "    try:\n",
    "        # Use TF-IDF for SMOTE\n",
    "        vectorizer = TfidfVectorizer(max_features=1000)\n",
    "        X = vectorizer.fit_transform(df['review'])\n",
    "        y = df['label'].values\n",
    "        \n",
    "        smote = SMOTE(random_state=RANDOM_SEED)\n",
    "        X_resampled, y_resampled = smote.fit_resample(X, y)\n",
    "        \n",
    "        # Reconstruct DataFrame (approximate - SMOTE creates synthetic samples)\n",
    "        print(\"Note: SMOTE creates synthetic samples. Consider manual review.\")\n",
    "        # For now, we'll proceed with original data if SMOTE fails\n",
    "    except Exception as e:\n",
    "        print(f\"SMOTE failed: {e}. Proceeding with original data.\")\n",
    "else:\n",
    "    print(\"\\n✓ Data is reasonably balanced. No resampling needed.\")\n",
    "\n",
    "# Recreate splits with cleaned data\n",
    "if not {'train_ids.csv','val_ids.csv','test_ids.csv'} <= set(os.listdir('.')):\n",
    "    df_train, df_temp = train_test_split(\n",
    "        df, test_size=0.3, random_state=RANDOM_SEED, stratify=df['label']\n",
    "    )\n",
    "    df_val, df_test = train_test_split(\n",
    "        df_temp, test_size=0.5, random_state=RANDOM_SEED, stratify=df_temp['label']\n",
    "    )\n",
    "    df_train[['id']].to_csv('train_ids.csv', index=False)\n",
    "    df_val[['id']].to_csv('val_ids.csv', index=False)\n",
    "    df_test[['id']].to_csv('test_ids.csv', index=False)\n",
    "else:\n",
    "    ids_tr = set(pd.read_csv('train_ids.csv')['id'].tolist())\n",
    "    ids_va = set(pd.read_csv('val_ids.csv')['id'].tolist())\n",
    "    ids_te = set(pd.read_csv('test_ids.csv')['id'].tolist())\n",
    "    df_train = df[df['id'].isin(ids_tr)].copy()\n",
    "    df_val   = df[df['id'].isin(ids_va)].copy()\n",
    "    df_test  = df[df['id'].isin(ids_te)].copy()\n",
    "\n",
    "print(f\"\\nFinal split sizes: train={len(df_train)}, val={len(df_val)}, test={len(df_test)}\")\n",
    "print('Label ratios (train):', df_train['label'].value_counts(normalize=True).sort_index().to_dict())\n",
    "print('Label ratios (val):  ', df_val['label'].value_counts(normalize=True).sort_index().to_dict())\n",
    "print('Label ratios (test): ', df_test['label'].value_counts(normalize=True).sort_index().to_dict())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Fast Mode Configuration (Optional)**\n",
    "\n",
    "**`Purpose`**\n",
    "\n",
    "This cell provides an option to reduce the training dataset size for faster experimentation and development. When enabled, it uses a subset of the training data while keeping validation and test sets intact for reliable evaluation.\n",
    "\n",
    "**`Input`**\n",
    "\n",
    "Requires df_train, df_val, and df_test DataFrames from previous cells. The FAST_MODE flag controls whether data reduction is applied.\n",
    "\n",
    "**`Output`**\n",
    "\n",
    "Prints the reduced dataset sizes and percentages. If FAST_MODE is disabled, confirms that full datasets will be used.\n",
    "\n",
    "**`Details`**\n",
    "\n",
    "When FAST_MODE is True, the training data is randomly sampled to 40% of its original size using a fixed random seed for reproducibility. Validation and test sets remain unchanged to ensure fair evaluation. This allows for quicker iteration during development while maintaining the ability to run full experiments when needed.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`Purpose`**\n",
    "\n",
    "This cell provides an option to reduce the training dataset size for faster experimentation and development. When enabled, it uses a subset of the training data while keeping validation and test sets intact for reliable evaluation.\n",
    "\n",
    "**`Input`**\n",
    "\n",
    "Requires df_train, df_val, and df_test DataFrames from previous cells. The FAST_MODE flag controls whether data reduction is applied.\n",
    "\n",
    "**`Output`**\n",
    "\n",
    "Prints the reduced dataset sizes and percentages. If FAST_MODE is disabled, confirms that full datasets will be used.\n",
    "\n",
    "**`Details`**\n",
    "\n",
    "When FAST_MODE is True, the training data is randomly sampled to 40% of its original size using a fixed random seed for reproducibility. Validation and test sets remain unchanged to ensure fair evaluation. This allows for quicker iteration during development while maintaining the ability to run full experiments when needed.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FAST_MODE = True  # Set to True for faster training (40% data), False for full dataset\n",
    "TRAIN_FRACTION = 0.40 if FAST_MODE else 1.0\n",
    "VAL_FRACTION = 1.0  # Keep full validation/test by default\n",
    "\n",
    "if FAST_MODE and TRAIN_FRACTION < 1.0:\n",
    "    df_train = (df_train\n",
    "                .sample(frac=TRAIN_FRACTION, random_state=RANDOM_SEED)\n",
    "                .sort_values('id')\n",
    "                .reset_index(drop=True))\n",
    "    if VAL_FRACTION < 1.0:\n",
    "        df_val = (df_val\n",
    "                  .sample(frac=VAL_FRACTION, random_state=RANDOM_SEED)\n",
    "                  .sort_values('id')\n",
    "                  .reset_index(drop=True))\n",
    "        df_test = (df_test\n",
    "                   .sample(frac=VAL_FRACTION, random_state=RANDOM_SEED)\n",
    "                   .sort_values('id')\n",
    "                   .reset_index(drop=True))\n",
    "    print(f\"[FAST_MODE ENABLED] Using {TRAIN_FRACTION*100:.0f}% of training data\\n  Train: {len(df_train)} samples{len(df_train)} (~{TRAIN_FRACTION*100:.0f}%), val={len(df_val)}, test={len(df_test)}\")\n",
    "else:\n",
    "    print(\"FAST_MODE disabled: using full train/val/test splits\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Baseline TF-IDF + Logistic Regression (per proposal Section V.C)**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`Purpose`**\n",
    "\n",
    "This block builds a baseline model using TF-IDF vectorization and Logistic Regression as a reference point per proposal Section V.C. The baseline model acts as a foundation for measuring improvements from more complex deep learning methods. It uses traditional machine learning techniques that are simple, interpretable, and computationally efficient.\n",
    "\n",
    "**`Input`**\n",
    "\n",
    "The inputs are the train_df and val_df frames created earlier. Only the review and label columns are used. The TF-IDF vectorizer is configured with word 1-2 ngrams and a vocabulary limit to cap memory and training time. The labels are taken directly as integer classes (-1, 0, 1).\n",
    "\n",
    "**`Output`**\n",
    "\n",
    "The block prints a compact dictionary that contains baseline accuracy, precision, recall, and F1-score (per proposal Section VI.A). It also appends a structured row to runs_log.csv so that the baseline appears in the experiment ledger with model name, scores, and notes. These outputs provide both an on-screen summary and a durable record for later tables and charts.\n",
    "\n",
    "**`Details`**\n",
    "\n",
    "A TF-IDF vectorizer is fit on the training text and applied to the validation text, producing sparse matrices. A Logistic Regression model is trained with hyperparameter tuning via grid search and cross-validation (per proposal Section VI.B). Predictions for the validation set are compared against the gold labels to compute accuracy, precision, recall, and F1-score, where macro-F1 treats all classes equally. The metrics are printed and then written to the log file with consistent column names.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold\n",
    "from sklearn.metrics import classification_report, precision_score, recall_score\n",
    "\n",
    "# TF-IDF vectorization (per proposal: Term Frequency-Inverse Document Frequency method)\n",
    "# Enhanced settings for better accuracy\n",
    "tfidf = TfidfVectorizer(\n",
    "    max_features=100000,  # Increased from 50000 to capture more features\n",
    "    ngram_range=(1,3),  # Expanded to 1-3 ngrams to capture more context\n",
    "    lowercase=True,\n",
    "    min_df=2,  # Ignore terms that appear in fewer than 2 documents\n",
    "    max_df=0.95,  # Ignore terms that appear in more than 95% of documents\n",
    "    sublinear_tf=True  # Apply sublinear tf scaling (1 + log(tf))\n",
    ")\n",
    "\n",
    "# Prepare data\n",
    "X_tr = df_train['review'].tolist()\n",
    "y_tr = df_train['label'].values\n",
    "X_va = df_val['review'].tolist()\n",
    "y_va = df_val['label'].values\n",
    "\n",
    "# Transform text to TF-IDF vectors\n",
    "print(\"Fitting TF-IDF vectorizer...\")\n",
    "X_tr_tfidf = tfidf.fit_transform(X_tr)\n",
    "X_va_tfidf = tfidf.transform(X_va)\n",
    "\n",
    "# Hyperparameter tuning with grid search and cross-validation (per proposal Section VI.B)\n",
    "# Expanded search space for better accuracy\n",
    "print(\"\\nPerforming hyperparameter tuning with GridSearchCV...\")\n",
    "# Use liblinear which supports both l1 and l2 penalties\n",
    "param_grid = {\n",
    "    'C': [0.1, 0.5, 1.0, 2.0, 4.0, 8.0],  # Expanded C range\n",
    "    'class_weight': [None, 'balanced', {-1: 1.2, 0: 0.8, 1: 1.2}],  # Custom: reduce neutral bias\n",
    "    'max_iter': [2000, 3000],  # Increased iterations\n",
    "    'penalty': ['l1', 'l2']  # Try both regularization types\n",
    "}\n",
    "\n",
    "logreg_base = LogisticRegression(solver='liblinear', random_state=RANDOM_SEED)\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=RANDOM_SEED)\n",
    "\n",
    "grid_search = GridSearchCV(\n",
    "    logreg_base, \n",
    "    param_grid=param_grid, \n",
    "    cv=skf, \n",
    "    scoring='f1_macro',\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "grid_search.fit(X_tr_tfidf, y_tr)\n",
    "print(f\"\\nBest parameters: {grid_search.best_params_}\")\n",
    "print(f\"Best CV score (F1-macro): {grid_search.best_score_:.4f}\")\n",
    "\n",
    "# Train final model with best parameters\n",
    "logreg = grid_search.best_estimator_\n",
    "preds = logreg.predict(X_va_tfidf)\n",
    "\n",
    "# Calculate metrics (per proposal Section VI.A)\n",
    "acc_base = accuracy_score(y_va, preds)\n",
    "prec_base = precision_score(y_va, preds, average='macro', zero_division=0)\n",
    "rec_base = recall_score(y_va, preds, average='macro', zero_division=0)\n",
    "f1_base = f1_score(y_va, preds, average='macro', zero_division=0)\n",
    "\n",
    "print(\"\\nBaseline Model Performance (Validation Set):\")\n",
    "print({\n",
    "    \"model\": \"tfidf-logreg\",\n",
    "    \"accuracy\": acc_base,\n",
    "    \"precision\": prec_base,\n",
    "    \"recall\": rec_base,\n",
    "    \"f1_macro\": f1_base\n",
    "})\n",
    "\n",
    "# Classification report\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_va, preds, \n",
    "                          target_names=['negative/toxic', 'neutral', 'positive'],\n",
    "                          zero_division=0))\n",
    "\n",
    "# Log to runs_log.csv\n",
    "row = {\n",
    "    \"member\": \"baseline\",\n",
    "    \"model\": \"tfidf-logreg\",\n",
    "    \"num_train_epochs\": None,\n",
    "    \"per_device_train_batch_size\": None,\n",
    "    \"learning_rate\": None,\n",
    "    \"weight_decay\": None,\n",
    "    \"warmup_steps\": None,\n",
    "    \"lr_scheduler_type\": None,\n",
    "    \"gradient_accumulation_steps\": None,\n",
    "    \"max_seq_length\": None,\n",
    "    \"seed\": RANDOM_SEED,\n",
    "    \"fp16\": False,\n",
    "    \"accuracy\": acc_base,\n",
    "    \"precision\": prec_base,\n",
    "    \"recall\": rec_base,\n",
    "    \"f1_macro\": f1_base,\n",
    "    \"notes\": f\"TF-IDF + LogReg baseline with GridSearchCV. Best params: {grid_search.best_params_}\"\n",
    "}\n",
    "\n",
    "pd.DataFrame([row]).to_csv(\"runs_log.csv\", mode=\"a\",\n",
    "                           index=False, header=not os.path.exists(\"runs_log.csv\"))\n",
    "\n",
    "# Save baseline model\n",
    "os.makedirs(\"models\", exist_ok=True)\n",
    "import joblib\n",
    "joblib.dump(logreg, \"models/baseline_tfidf_logreg.joblib\")\n",
    "joblib.dump(tfidf, \"models/baseline_tfidf_vectorizer.joblib\")\n",
    "print(\"\\n✓ Baseline model saved to models/baseline_tfidf_logreg.joblib\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline Evaluation on Test Set\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`Purpose`**\n",
    "\n",
    "This cell creates visualizations to analyze and compare model performance. It generates plots showing confusion matrices, metrics comparisons, and class distributions.\n",
    "\n",
    "**`Input`**\n",
    "\n",
    "Requires evaluation results from previous cells, including predictions, true labels, and performance metrics for both baseline and BERT models.\n",
    "\n",
    "**`Output`**\n",
    "\n",
    "Saves visualization images to the exports directory, including confusion matrices, metrics comparison charts, and class distribution plots.\n",
    "\n",
    "**`Details`**\n",
    "\n",
    "Creates a grid of visualizations including confusion matrices for baseline and BERT models, side-by-side metrics comparison bar charts, and class distribution analysis. The visualizations help identify which classes are easier or harder to predict, where models make errors, and how performance varies across different sentiment categories. All plots are saved as high-resolution PNG files for inclusion in reports and presentations.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate baseline on test set (15%)\n",
    "# Load models if not already in memory (in case this cell is run independently)\n",
    "try:\n",
    "    # Check if tfidf and logreg are defined\n",
    "    _ = tfidf\n",
    "    _ = logreg\n",
    "    print(\"Using models from previous cell...\")\n",
    "except NameError:\n",
    "    # Try to load from saved files\n",
    "    import joblib\n",
    "    import os\n",
    "    model_path = \"models/baseline_tfidf_logreg.joblib\"\n",
    "    vectorizer_path = \"models/baseline_tfidf_vectorizer.joblib\"\n",
    "    \n",
    "    if os.path.exists(model_path) and os.path.exists(vectorizer_path):\n",
    "        print(\"Loading baseline models from disk...\")\n",
    "        tfidf = joblib.load(vectorizer_path)\n",
    "        logreg = joblib.load(model_path)\n",
    "        print(\"✓ Models loaded successfully\")\n",
    "    else:\n",
    "        raise NameError(\n",
    "            \"Baseline models not found. Please run Cell 12 (Baseline TF-IDF + Logistic Regression training) first to train and save the models.\"\n",
    "        )\n",
    "\n",
    "X_te = df_test['review'].tolist()\n",
    "y_te = df_test['label'].values\n",
    "X_te_tfidf = tfidf.transform(X_te)\n",
    "\n",
    "test_preds = logreg.predict(X_te_tfidf)\n",
    "\n",
    "# Calculate test metrics\n",
    "test_acc = accuracy_score(y_te, test_preds)\n",
    "test_prec = precision_score(y_te, test_preds, average='macro', zero_division=0)\n",
    "test_rec = recall_score(y_te, test_preds, average='macro', zero_division=0)\n",
    "test_f1 = f1_score(y_te, test_preds, average='macro', zero_division=0)\n",
    "\n",
    "print(\"Baseline Model Performance (Test Set):\")\n",
    "print({\n",
    "    \"model\": \"tfidf-logreg\",\n",
    "    \"accuracy\": test_acc,\n",
    "    \"precision\": test_prec,\n",
    "    \"recall\": test_rec,\n",
    "    \"f1_macro\": test_f1\n",
    "})\n",
    "\n",
    "print(\"\\nTest Set Classification Report:\")\n",
    "print(classification_report(y_te, test_preds, \n",
    "                          target_names=['negative/toxic', 'neutral', 'positive'],\n",
    "                          zero_division=0))\n",
    "\n",
    "# Save test predictions\n",
    "os.makedirs(\"exports\", exist_ok=True)\n",
    "pd.DataFrame({\n",
    "    'review': X_te,\n",
    "    'gold': y_te,\n",
    "    'pred': test_preds\n",
    "}).to_csv('exports/baseline_predictions_test.csv', index=False)\n",
    "\n",
    "# Confusion matrix\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "cm = confusion_matrix(y_te, test_preds, labels=[-1, 0, 1])\n",
    "fig, ax = plt.subplots(figsize=(6, 5))\n",
    "ConfusionMatrixDisplay(cm, display_labels=['negative/toxic', 'neutral', 'positive']).plot(ax=ax, colorbar=False)\n",
    "plt.title('Baseline Model - Test Set Confusion Matrix')\n",
    "plt.tight_layout()\n",
    "os.makedirs(\"exports/confusion_matrices\", exist_ok=True)\n",
    "plt.savefig('exports/confusion_matrices/baseline_cm_test.png', dpi=150)\n",
    "plt.close()\n",
    "print(\"\\n✓ Confusion matrix saved to exports/confusion_matrices/baseline_cm_test.png\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **BERT Model Initialization and Tokenization (per proposal Section V.C)**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`Purpose`**\n",
    "\n",
    "This block initializes the BERT-base-uncased model per proposal Section V.C for toxicity classification. It loads the BERT tokenizer (WordPiece tokenizer) and prepares the datasets for transformer fine-tuning by converting tweets into numerical input representations suitable for model processing.\n",
    "\n",
    "**`Input`**\n",
    "\n",
    "The inputs are the training, validation, and test DataFrames created earlier. The BERT tokenizer is loaded from the transformers library, and a maximum sequence length is specified to keep batch shapes uniform.\n",
    "\n",
    "**`Output`**\n",
    "\n",
    "The block prints the resolved model name and confirms tokenization completion. Three datasets.Dataset objects are produced with tensor columns input_ids, attention_mask, and label. A classification model with three output labels is created and moved to the detected device.\n",
    "\n",
    "**`Details`**\n",
    "\n",
    "The BERT tokenizer (WordPiece tokenizer) is loaded with the fast backend and wrapped in a function that applies truncation and padding to a fixed length of 128 tokens (standard for tweets). The pandas frames are converted into Dataset objects, tokenization is applied in batches for speed, and the dataset columns are formatted as PyTorch tensors. The model is loaded with a task-specific head sized to three classes and placed on CPU or GPU.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "import platform\n",
    "\n",
    "USE_GPU = torch.cuda.is_available()\n",
    "if USE_GPU:\n",
    "    print(f\"✓ GPU detected: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"  CUDA Version: {torch.version.cuda}\")\n",
    "    print(f\"  GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")\n",
    "    device = torch.device(\"cuda:0\")\n",
    "    NUM_WORKERS = 0 if platform.system() == 'Windows' else 4\n",
    "    PIN_MEMORY = True\n",
    "else:\n",
    "    print(\"⚠ No GPU detected, using CPU (training will be slow)\")\n",
    "    device = torch.device(\"cpu\")\n",
    "    NUM_WORKERS = 0\n",
    "    PIN_MEMORY = False\n",
    "\n",
    "# Model choice: bert-base-uncased (per proposal Section V.C)\n",
    "MODEL_NAME = \"bert-base-uncased\"\n",
    "print(f\"\\nUsing model: {MODEL_NAME}\")\n",
    "\n",
    "MAX_LEN = 128  # Standard for tweets\n",
    "\n",
    "# Load BERT tokenizer (WordPiece tokenizer per proposal)\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME, use_fast=True)\n",
    "\n",
    "def tokenize_fn(batch):\n",
    "    \"\"\"Tokenize tweets using BERT's WordPiece tokenizer (per proposal Section V.B)\"\"\"\n",
    "    return tokenizer(batch[\"review\"], truncation=True, padding=\"max_length\", max_length=MAX_LEN)\n",
    "\n",
    "print(\"\\nTokenizing datasets (this may take a moment)...\")\n",
    "# Map labels from proposal format (-1,0,1) to BERT format (0,1,2)\n",
    "# -1 (negative/toxic) → 0, 0 (neutral) → 1, 1 (positive) → 2\n",
    "label_mapping = {-1: 0, 0: 1, 1: 2}\n",
    "df_train_bert = df_train.copy()\n",
    "df_val_bert = df_val.copy()\n",
    "df_test_bert = df_test.copy()\n",
    "df_train_bert['label'] = df_train_bert['label'].map(label_mapping)\n",
    "df_val_bert['label'] = df_val_bert['label'].map(label_mapping)\n",
    "df_test_bert['label'] = df_test_bert['label'].map(label_mapping)\n",
    "\n",
    "ds_train = Dataset.from_pandas(df_train_bert[['review','label']].reset_index(drop=True))\n",
    "ds_val   = Dataset.from_pandas(df_val_bert[['review','label']].reset_index(drop=True))\n",
    "ds_test  = Dataset.from_pandas(df_test_bert[['review','label']].reset_index(drop=True))\n",
    "\n",
    "if platform.system() == 'Windows':\n",
    "    NUM_PROC_TOKENIZE = None\n",
    "    print(\"  Using single-process tokenization (Windows compatibility)\")\n",
    "else:\n",
    "    NUM_PROC_TOKENIZE = 4 if USE_GPU else 2\n",
    "    print(f\"  Using {NUM_PROC_TOKENIZE} processes for tokenization\")\n",
    "\n",
    "ds_train = ds_train.map(tokenize_fn, batched=True, num_proc=NUM_PROC_TOKENIZE, remove_columns=['review'])\n",
    "ds_val   = ds_val.map(tokenize_fn, batched=True, num_proc=NUM_PROC_TOKENIZE, remove_columns=['review'])\n",
    "ds_test  = ds_test.map(tokenize_fn, batched=True, num_proc=NUM_PROC_TOKENIZE, remove_columns=['review'])\n",
    "\n",
    "cols = ['input_ids','attention_mask','label']\n",
    "ds_train = ds_train.with_format(\"torch\", columns=cols)\n",
    "ds_val   = ds_val.with_format(\"torch\", columns=cols)\n",
    "ds_test  = ds_test.with_format(\"torch\", columns=cols)\n",
    "\n",
    "print(f\"✓ Datasets ready: train={len(ds_train)}, val={len(ds_val)}, test={len(ds_test)}\")\n",
    "\n",
    "# Initialize BERT model with 3 labels (negative/neutral/positive)\n",
    "num_labels = 3\n",
    "model = AutoModelForSequenceClassification.from_pretrained(MODEL_NAME, num_labels=num_labels)\n",
    "model = model.to(device)\n",
    "print(f\"✓ Model loaded on {device}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **BERT Training Arguments and Configuration (per proposal Section V.D)**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`Purpose`**\n",
    "\n",
    "This block defines how BERT training will proceed per proposal Section V.D. It establishes a metric function that reports accuracy, precision, recall, and F1-score, builds training arguments with AdamW optimizer and cross-entropy loss, and constructs a Trainer object that ties the model, data, tokenizer, arguments, and metrics together.\n",
    "\n",
    "**`Input`**\n",
    "\n",
    "Inputs include the tokenized datasets, the initialized model and tokenizer, and hyperparameters such as number of epochs, batch sizes, learning rate, weight decay, and evaluation cadence.\n",
    "\n",
    "**`Output`**\n",
    "\n",
    "The cell prints a confirmation that the trainer is ready and includes the active model name. Internally, it prepares all objects required for training and evaluation.\n",
    "\n",
    "**`Details`**\n",
    "\n",
    "A compute function converts raw model outputs into predicted labels and compares them with gold labels to obtain accuracy, precision, recall, and macro-F1 (target: >0.85 per proposal Section III). Training arguments are configured with AdamW optimizer, cross-entropy loss, linear warmup with learning rate scheduling, early stopping to prevent overfitting, and mixed-precision when GPU is available.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments, Trainer, EarlyStoppingCallback\n",
    "from sklearn.metrics import precision_score, recall_score\n",
    "import inspect\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    \"\"\"Compute metrics per proposal Section VI.A: accuracy, precision, recall, F1-score\"\"\"\n",
    "    preds = np.argmax(eval_pred.predictions, axis=1)\n",
    "    labels = eval_pred.label_ids\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    prec = precision_score(labels, preds, average='macro', zero_division=0)\n",
    "    rec = recall_score(labels, preds, average='macro', zero_division=0)\n",
    "    f1m = f1_score(labels, preds, average='macro', zero_division=0)\n",
    "    return {'accuracy': acc, 'precision': prec, 'recall': rec, 'f1_macro': f1m}\n",
    "\n",
    "if USE_GPU:\n",
    "    TRAIN_BATCH_SIZE = 32\n",
    "    EVAL_BATCH_SIZE = 64\n",
    "    USE_FP16 = True\n",
    "    GRADIENT_CHECKPOINTING = False\n",
    "else:\n",
    "    TRAIN_BATCH_SIZE = 8\n",
    "    EVAL_BATCH_SIZE = 16\n",
    "    USE_FP16 = False\n",
    "    GRADIENT_CHECKPOINTING = False\n",
    "\n",
    "sig = inspect.signature(TrainingArguments.__init__)\n",
    "argnames = set(sig.parameters.keys())\n",
    "\n",
    "def make_training_args(**overrides):\n",
    "    \"\"\"Create training arguments per proposal Section V.D\"\"\"\n",
    "    base_epochs = 3 if FAST_MODE else 4\n",
    "    total_steps = max(1, (len(ds_train) // max(1, TRAIN_BATCH_SIZE)) * base_epochs)\n",
    "    warmup_steps = max(25, int(total_steps * 0.1))\n",
    "\n",
    "    cfg = dict(\n",
    "        output_dir=f\"./checkpoints/bert-base/run1\",\n",
    "        num_train_epochs=base_epochs,\n",
    "        per_device_train_batch_size=TRAIN_BATCH_SIZE,\n",
    "        per_device_eval_batch_size=EVAL_BATCH_SIZE,\n",
    "        learning_rate=3e-5,  # Standard for BERT fine-tuning\n",
    "        weight_decay=0.01,\n",
    "        warmup_ratio=0.1,  # Linear warmup per proposal\n",
    "        lr_scheduler_type=\"linear\",  # Learning rate scheduling per proposal\n",
    "        gradient_accumulation_steps=1,\n",
    "        load_best_model_at_end=True,\n",
    "        metric_for_best_model=\"f1_macro\",  # Target: >0.85 per proposal\n",
    "        greater_is_better=True,\n",
    "        seed=RANDOM_SEED,\n",
    "        logging_steps=50,\n",
    "        eval_steps=100,\n",
    "        save_steps=200,\n",
    "        save_total_limit=2,\n",
    "        report_to=[],\n",
    "        optim=\"adamw_torch\",  # AdamW optimizer per proposal Section V.D\n",
    "        fp16=USE_FP16,\n",
    "        dataloader_num_workers=NUM_WORKERS,\n",
    "        dataloader_pin_memory=PIN_MEMORY,\n",
    "        remove_unused_columns=False,\n",
    "        gradient_checkpointing=GRADIENT_CHECKPOINTING,\n",
    "    )\n",
    "    cfg.update(overrides)\n",
    "\n",
    "    if \"evaluation_strategy\" in argnames:\n",
    "        cfg[\"evaluation_strategy\"] = cfg.get(\"evaluation_strategy\", \"steps\")\n",
    "    elif \"eval_strategy\" in argnames:\n",
    "        cfg[\"eval_strategy\"] = cfg.get(\"eval_strategy\", \"steps\")\n",
    "\n",
    "    if \"save_strategy\" in argnames:\n",
    "        cfg[\"save_strategy\"] = cfg.get(\"save_strategy\", \"steps\")\n",
    "\n",
    "    safe_cfg = {k:v for k,v in cfg.items() if k in argnames}\n",
    "    return TrainingArguments(**safe_cfg)\n",
    "\n",
    "training_args = make_training_args()\n",
    "\n",
    "if GRADIENT_CHECKPOINTING and hasattr(model, 'gradient_checkpointing_enable'):\n",
    "    model.gradient_checkpointing_enable()\n",
    "    print(\"✓ Gradient checkpointing enabled (saves memory)\")\n",
    "\n",
    "# Early stopping to prevent overfitting (per proposal)\n",
    "callbacks = [EarlyStoppingCallback(early_stopping_patience=2, early_stopping_threshold=0.001)]\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=ds_train,\n",
    "    eval_dataset=ds_val,\n",
    "    compute_metrics=compute_metrics,\n",
    "    tokenizer=tokenizer,\n",
    "    callbacks=callbacks,\n",
    ")\n",
    "\n",
    "print(f\"✓ Trainer ready on {device}\")\n",
    "print(f\"  Batch size: {TRAIN_BATCH_SIZE} (train), {EVAL_BATCH_SIZE} (eval)\")\n",
    "print(f\"  FP16: {USE_FP16}, Workers: {NUM_WORKERS}, Pin Memory: {PIN_MEMORY}\")\n",
    "print(f\"  Early stopping: patience=2\")\n",
    "print(f\"  Optimizer: AdamW, Loss: Cross-entropy, Scheduler: Linear warmup\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Automated Hyperparameter Tuning (per proposal Section V.C)\n",
    "\n",
    "**`Purpose`**\n",
    "\n",
    "Run Optuna-driven grid and random searches per proposal Section V.C for hyperparameter tuning and validation curve analysis to find optimum performance. The search explores learning rate, batch size, epochs, weight decay, and warmup ratio to identify the best configuration via validation macro-F1.\n",
    "\n",
    "**`Input`**\n",
    "\n",
    "Uses the tokenized datasets (`ds_train`, `ds_val`), global tokenizer/model selections, and shared helpers (`compute_metrics`, `make_training_args`). Configuration depends on `AUTO_TUNE_ENABLED`, search spaces, and trial limits.\n",
    "\n",
    "**`Output`**\n",
    "\n",
    "Writes per-strategy trial tables to `tuning/` directory, a combined summary, and logs the best configuration. The winning configuration is retrained, evaluated on validation and test splits, logged to `runs_log.csv`, and predictions exported.\n",
    "\n",
    "**`Details`**\n",
    "\n",
    "Defines a lightweight `WeightedTrainer` compatible with Optuna, registers helper functions to build Trainers for suggested hyperparameters. Optuna's `GridSampler` and `RandomSampler` explore the respective spaces, timing each trial and storing validation metrics.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Automated hyperparameter tuning configuration\n",
    "AUTO_TUNE_ENABLED = True\n",
    "\n",
    "GRID_SEARCH_SPACE = {\n",
    "    \"learning_rate\": [3e-5],  # Fixed to default (1 value)\n",
    "    \"per_device_train_batch_size\": [8, 16],  # 2 values\n",
    "    \"weight_decay\": [0.0, 0.01],  # 2 values\n",
    "    \"num_train_epochs\": [2, 3],  # 2 values\n",
    "}\n",
    "\n",
    "\n",
    "RANDOM_SEARCH_SPACE = {\n",
    "    \"learning_rate\": (\"log_uniform\", 2e-5, 5e-5),\n",
    "    \"per_device_train_batch_size\": (\"choice\", [8, 12, 16, 24, 32]),\n",
    "    \"weight_decay\": (\"uniform\", 0.0, 0.1),\n",
    "    \"num_train_epochs\": (\"int\", 2, 4),\n",
    "}\n",
    "\n",
    "RANDOM_TRIALS = 8\n",
    "MAX_AUTOTUNE_EPOCHS = 4\n",
    "\n",
    "print(\"Hyperparameter tuning configuration:\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`Purpose`**\n",
    "\n",
    "This cell configures the training arguments and sets up helper functions for BERT model fine-tuning. It defines hyperparameters, optimization settings, and evaluation metrics according to the proposal methodology.\n",
    "\n",
    "**`Input`**\n",
    "\n",
    "Uses global variables like MODEL_NAME, MAX_LEN, RANDOM_SEED, and device settings. Requires tokenizer and model to be initialized from previous cells.\n",
    "\n",
    "**`Output`**\n",
    "\n",
    "Creates training_args object and compute_metrics function. Prints configuration summary including optimizer settings, learning rate schedule, and training parameters.\n",
    "\n",
    "**`Details`**\n",
    "\n",
    "The cell sets up TrainingArguments with AdamW optimizer, linear learning rate warmup, cross-entropy loss, and early stopping callback. It configures evaluation strategy, logging, and checkpoint saving. The compute_metrics function calculates accuracy, precision, recall, and F1-macro scores for each evaluation step. All settings align with the proposal requirements for systematic model training and evaluation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import time\n",
    "from optuna.samplers import GridSampler, RandomSampler\n",
    "from pathlib import Path\n",
    "\n",
    "TUNING_DIR = Path(\"tuning\")\n",
    "TUNING_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "if AUTO_TUNE_ENABLED:\n",
    "    # Custom Trainer for Optuna compatibility\n",
    "    class WeightedTrainer(Trainer):\n",
    "        def __init__(self, *args, class_weights=None, **kwargs):\n",
    "            super().__init__(*args, **kwargs)\n",
    "            self.class_weights = class_weights\n",
    "\n",
    "    def build_trainer_for_trial(hparams, run_name):\n",
    "        \"\"\"Build trainer with suggested hyperparameters\"\"\"\n",
    "        trial_args = make_training_args(\n",
    "            output_dir=f\"./checkpoints/bert-base/{run_name}\",\n",
    "            learning_rate=hparams.get(\"learning_rate\", 3e-5),\n",
    "            per_device_train_batch_size=hparams.get(\"per_device_train_batch_size\", 16),\n",
    "            weight_decay=hparams.get(\"weight_decay\", 0.01),\n",
    "            num_train_epochs=min(hparams.get(\"num_train_epochs\", 3), MAX_AUTOTUNE_EPOCHS),\n",
    "            eval_strategy=\"epoch\",  # Enable evaluation for early stopping callback\n",
    "            save_strategy=\"epoch\",  # Must match eval_strategy for load_best_model_at_end\n",
    "        )\n",
    "        \n",
    "        # Create fresh model for each trial\n",
    "        trial_model = AutoModelForSequenceClassification.from_pretrained(MODEL_NAME, num_labels=3).to(device)\n",
    "        \n",
    "        trial_trainer = WeightedTrainer(\n",
    "            model=trial_model,\n",
    "            args=trial_args,\n",
    "            train_dataset=ds_train,\n",
    "            eval_dataset=ds_val,\n",
    "            compute_metrics=compute_metrics,\n",
    "            tokenizer=tokenizer,\n",
    "            callbacks=[EarlyStoppingCallback(early_stopping_patience=2, early_stopping_threshold=0.001)],\n",
    "        )\n",
    "        return trial_trainer, trial_args\n",
    "\n",
    "    def suggest_params(trial, strategy):\n",
    "        \"\"\"Suggest hyperparameters based on strategy\"\"\"\n",
    "        if strategy == \"grid\":\n",
    "            # Grid search: enumerate all combinations\n",
    "            lr_vals = GRID_SEARCH_SPACE[\"learning_rate\"]\n",
    "            bs_vals = GRID_SEARCH_SPACE[\"per_device_train_batch_size\"]\n",
    "            wd_vals = GRID_SEARCH_SPACE[\"weight_decay\"]\n",
    "            ep_vals = GRID_SEARCH_SPACE[\"num_train_epochs\"]\n",
    "            \n",
    "            # Use trial number to index into grid\n",
    "            trial_idx = trial.number\n",
    "            total_combos = len(lr_vals) * len(bs_vals) * len(wd_vals) * len(ep_vals)\n",
    "            if trial_idx >= total_combos:\n",
    "                raise optuna.TrialPruned()\n",
    "            \n",
    "            idx = trial_idx\n",
    "            lr_idx = idx % len(lr_vals)\n",
    "            idx //= len(lr_vals)\n",
    "            bs_idx = idx % len(bs_vals)\n",
    "            idx //= len(bs_vals)\n",
    "            wd_idx = idx % len(wd_vals)\n",
    "            idx //= len(wd_vals)\n",
    "            ep_idx = idx % len(ep_vals)\n",
    "            \n",
    "            return {\n",
    "                \"learning_rate\": lr_vals[lr_idx],\n",
    "                \"per_device_train_batch_size\": bs_vals[bs_idx],\n",
    "                \"weight_decay\": wd_vals[wd_idx],\n",
    "                \"num_train_epochs\": ep_vals[ep_idx],\n",
    "            }\n",
    "        else:  # random\n",
    "            return {\n",
    "                \"learning_rate\": trial.suggest_float(\"learning_rate\", 2e-5, 5e-5, log=True),\n",
    "                \"per_device_train_batch_size\": trial.suggest_categorical(\"per_device_train_batch_size\", [8, 12, 16, 24, 32]),\n",
    "                \"weight_decay\": trial.suggest_float(\"weight_decay\", 0.0, 0.1),\n",
    "                \"num_train_epochs\": trial.suggest_int(\"num_train_epochs\", 2, 4),\n",
    "            }\n",
    "\n",
    "    def objective(trial):\n",
    "        \"\"\"Optuna objective function\"\"\"\n",
    "        strategy = trial.study.sampler.__class__.__name__\n",
    "        hparams = suggest_params(trial, \"grid\" if \"Grid\" in strategy else \"random\")\n",
    "        \n",
    "        run_name = f\"trial_{trial.number}\"\n",
    "        trainer_obj, args_obj = build_trainer_for_trial(hparams, run_name)\n",
    "        \n",
    "        start_time = time.time()\n",
    "        trainer_obj.train()\n",
    "        train_time = time.time() - start_time\n",
    "        \n",
    "        eval_results = trainer_obj.evaluate()\n",
    "        f1_macro = eval_results.get(\"eval_f1_macro\", 0.0)\n",
    "        \n",
    "        # Note: Labels are in BERT format (0,1,2) during training, metrics are computed correctly\n",
    "        \n",
    "        # Cleanup\n",
    "        del trainer_obj\n",
    "        gc.collect()\n",
    "        if torch.cuda.is_available():\n",
    "            torch.cuda.empty_cache()\n",
    "        \n",
    "        trial.set_user_attr(\"train_time\", train_time)\n",
    "        trial.set_user_attr(\"accuracy\", eval_results.get(\"eval_accuracy\", 0.0))\n",
    "        trial.set_user_attr(\"precision\", eval_results.get(\"eval_precision\", 0.0))\n",
    "        trial.set_user_attr(\"recall\", eval_results.get(\"eval_recall\", 0.0))\n",
    "        \n",
    "        return f1_macro\n",
    "\n",
    "    # Run hyperparameter search\n",
    "    SEARCH_STRATEGIES = [\"grid\", \"random\"] if AUTO_TUNE_ENABLED else []\n",
    "    summary_rows = []\n",
    "    \n",
    "    for strategy in SEARCH_STRATEGIES:\n",
    "        \n",
    "        if strategy == \"grid\":\n",
    "            sampler = GridSampler(GRID_SEARCH_SPACE)\n",
    "            study = optuna.create_study(direction=\"maximize\", sampler=sampler)\n",
    "            # Grid search: run all combinations\n",
    "            total_trials = (len(GRID_SEARCH_SPACE[\"learning_rate\"]) * \n",
    "                          len(GRID_SEARCH_SPACE[\"per_device_train_batch_size\"]) *\n",
    "                          len(GRID_SEARCH_SPACE[\"weight_decay\"]) *\n",
    "                          len(GRID_SEARCH_SPACE[\"num_train_epochs\"]))\n",
    "            study.optimize(objective, n_trials=total_trials, show_progress_bar=True)\n",
    "        else:\n",
    "            sampler = RandomSampler(seed=RANDOM_SEED)\n",
    "            study = optuna.create_study(direction=\"maximize\", sampler=sampler)\n",
    "            study.optimize(objective, n_trials=RANDOM_TRIALS, show_progress_bar=True)\n",
    "        \n",
    "        # Save trial results\n",
    "        trials_df = pd.DataFrame([\n",
    "            {\n",
    "                \"trial\": t.number,\n",
    "                \"f1_macro\": t.value,\n",
    "                \"learning_rate\": t.params.get(\"learning_rate\"),\n",
    "                \"batch_size\": t.params.get(\"per_device_train_batch_size\"),\n",
    "                \"weight_decay\": t.params.get(\"weight_decay\"),\n",
    "                \"epochs\": t.params.get(\"num_train_epochs\"),\n",
    "                \"accuracy\": t.user_attrs.get(\"accuracy\", 0),\n",
    "                \"precision\": t.user_attrs.get(\"precision\", 0),\n",
    "                \"recall\": t.user_attrs.get(\"recall\", 0),\n",
    "                \"train_time\": t.user_attrs.get(\"train_time\", 0),\n",
    "            }\n",
    "            for t in study.trials if t.value is not None\n",
    "        ])\n",
    "        \n",
    "        # Best trial\n",
    "        if study.best_trial:\n",
    "            best_hparams = study.best_trial.params\n",
    "            \n",
    "            # Retrain with best params and evaluate on test\n",
    "            best_trainer.train()\n",
    "            \n",
    "            val_results = best_trainer.evaluate()\n",
    "            test_results = best_trainer.evaluate(eval_dataset=ds_test)\n",
    "            \n",
    "            # Save best model\n",
    "            best_trainer.save_model(best_ckpt_dir)\n",
    "            tokenizer.save_pretrained(best_ckpt_dir)\n",
    "            \n",
    "            summary_rows.append({\n",
    "                \"strategy\": strategy,\n",
    "                \"f1_macro_val\": val_results.get(\"eval_f1_macro\", 0),\n",
    "                \"f1_macro_test\": test_results.get(\"eval_f1_macro\", 0),\n",
    "                \"accuracy_val\": val_results.get(\"eval_accuracy\", 0),\n",
    "                \"accuracy_test\": test_results.get(\"eval_accuracy\", 0),\n",
    "                \"best_params\": str(best_hparams),\n",
    "            \n",
    "            # Log to runs_log.csv\n",
    "            row = {\n",
    "}\n",
    "                \"model\": MODEL_NAME,\n",
    "                \"num_train_epochs\": best_hparams.get(\"num_train_epochs\"),\n",
    "                \"per_device_train_batch_size\": best_hparams.get(\"per_device_train_batch_size\"),\n",
    "                \"learning_rate\": best_hparams.get(\"learning_rate\"),\n",
    "                \"weight_decay\": best_hparams.get(\"weight_decay\"),\n",
    "                \"warmup_steps\": None,\n",
    "                \"lr_scheduler_type\": \"linear\",\n",
    "                \"gradient_accumulation_steps\": 1,\n",
    "                \"max_seq_length\": MAX_LEN,\n",
    "                \"seed\": RANDOM_SEED,\n",
    "                \"fp16\": USE_FP16,\n",
    "                \"accuracy\": test_results.get(\"eval_accuracy\", 0),\n",
    "                \"precision\": test_results.get(\"eval_precision\", 0),\n",
    "                \"recall\": test_results.get(\"eval_recall\", 0),\n",
    "                \"f1_macro\": test_results.get(\"eval_f1_macro\", 0),\n",
    "            pd.DataFrame([row]).to_csv(\"runs_log.csv\", mode=\"a\", index=False, \n",
    "                                     header=not os.path.exists(\"runs_log.csv\"))\n",
    "    \n",
    "    # Save summary\n",
    "    if summary_rows:\n",
    "        summary_df = pd.DataFrame(summary_rows)\n",
    "        summary_df.to_csv(TUNING_DIR / \"strategy_summary.csv\", index=False)\n",
    "        print(summary_df)\n",
    "    \n",
    "    AUTO_TUNE_ENABLED = False  # Disable for subsequent cells\n",
    "else:\n",
    "    print(\"AUTO_TUNE_ENABLED is False. Skipping hyperparameter tuning.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **BERT Fine-tuning and Training**\n",
    "\n",
    "**`Purpose`**\n",
    "\n",
    "This cell performs the actual BERT model fine-tuning using either default hyperparameters or the best configuration from automated tuning. It trains the model with early stopping and saves the best checkpoint.\n",
    "\n",
    "**`Input`**\n",
    "\n",
    "Requires tokenized datasets (ds_train, ds_val), training arguments, model, tokenizer, and compute_metrics function. If hyperparameter tuning was performed, uses best parameters from the study.\n",
    "\n",
    "**`Output`**\n",
    "\n",
    "Trains the BERT model and saves the best checkpoint to disk. Prints training progress including loss and metrics for each epoch. Creates a trainer object and runs the training loop.\n",
    "\n",
    "**`Details`**\n",
    "\n",
    "The cell creates a Trainer object with the model, datasets, training arguments, and callbacks including early stopping. Training proceeds for the specified number of epochs with validation evaluation after each epoch. The best model checkpoint (based on validation F1-macro) is automatically saved. Training progress is logged and displayed, showing loss curves and metric improvements over time.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`Purpose`**\n",
    "\n",
    "This cell configures the hyperparameter search spaces for automated tuning using Optuna. It defines the parameter ranges for grid search and random search strategies.\n",
    "\n",
    "**`Input`**\n",
    "\n",
    "No direct inputs required. Uses global configuration variables.\n",
    "\n",
    "**`Output`**\n",
    "\n",
    "Prints the hyperparameter tuning configuration including search spaces, number of trials, and maximum epochs.\n",
    "\n",
    "**`Details`**\n",
    "\n",
    "Defines GRID_SEARCH_SPACE with fixed learning rate and varying batch sizes, weight decay, and epochs. Sets up RANDOM_SEARCH_SPACE with continuous ranges for learning rate and weight decay, and categorical choices for batch size and epochs. Configures the number of random trials and maximum training epochs to balance exploration with computational efficiency.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train BERT model (if not already trained via hyperparameter tuning)\n",
    "if not AUTO_TUNE_ENABLED or not os.path.exists(\"./checkpoints/bert-base/best_grid\"):\n",
    "    print(\"Training BERT model with default/configured parameters...\")\n",
    "    print(\"Fine-tuning process per proposal Section V.D:\")\n",
    "    print(\"  - Tokenization using BERT's WordPiece tokenizer\")\n",
    "    print(\"  - Convert tweets to input IDs and attention masks\")\n",
    "    print(\"  - Fine-tune with classification head for sentiment labeling\")\n",
    "    print(\"  - Optimizer: AdamW, Loss: Cross-entropy, Scheduler: Linear warmup\")\n",
    "    \n",
    "    trainer.train()\n",
    "    \n",
    "    # Evaluate on validation set\n",
    "    val_results = trainer.evaluate()\n",
    "    print(\"\\nValidation Results:\")\n",
    "    print(f\"  Accuracy: {val_results.get('eval_accuracy', 0):.4f}\")\n",
    "    print(f\"  Precision: {val_results.get('eval_precision', 0):.4f}\")\n",
    "    print(f\"  Recall: {val_results.get('eval_recall', 0):.4f}\")\n",
    "    print(f\"  F1-macro: {val_results.get('eval_f1_macro', 0):.4f}\")\n",
    "    \n",
    "    # Save best checkpoint\n",
    "    best_ckpt_dir = \"./checkpoints/bert-base/best\"\n",
    "    trainer.save_model(best_ckpt_dir)\n",
    "    tokenizer.save_pretrained(best_ckpt_dir)\n",
    "    print(f\"\\n✓ Best model saved to {best_ckpt_dir}\")\n",
    "else:\n",
    "    print(\"Using best model from hyperparameter tuning.\")\n",
    "    best_ckpt_dir = \"./checkpoints/bert-base/best_grid\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Model Evaluation and Baseline Comparison (per proposal Section VI)**\n",
    "\n",
    "**`Purpose`**\n",
    "\n",
    "This cell performs comprehensive evaluation of the trained BERT model on the test set. It generates detailed performance metrics, classification reports, and comparison with baseline models.\n",
    "\n",
    "**`Input`**\n",
    "\n",
    "Requires best_model and best_ckpt_dir from training cells. Needs ds_test dataset and baseline model results for comparison.\n",
    "\n",
    "**`Output`**\n",
    "\n",
    "Prints detailed performance metrics, generates confusion matrices, ROC-AUC and PR-AUC curves, and creates comparison tables. Exports results to CSV files for further analysis.\n",
    "\n",
    "**`Details`**\n",
    "\n",
    "The evaluation process tests the best BERT model on the held-out test set. It computes accuracy, precision, recall, and F1-macro scores for each class and overall. Generates confusion matrices to visualize classification performance. Creates ROC-AUC and PR-AUC curves for each sentiment class to analyze precision-recall trade-offs. Compares BERT results with baseline TF-IDF and Logistic Regression model to quantify improvements. All results are exported to files for documentation and reporting.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`Purpose`**\n",
    "\n",
    "This cell configures the training arguments and sets up helper functions for BERT model fine-tuning. It defines hyperparameters, optimization settings, and evaluation metrics according to the proposal methodology.\n",
    "\n",
    "**`Input`**\n",
    "\n",
    "Uses global variables like MODEL_NAME, MAX_LEN, RANDOM_SEED, and device settings. Requires tokenizer and model to be initialized from previous cells.\n",
    "\n",
    "**`Output`**\n",
    "\n",
    "Creates training_args object and compute_metrics function. Prints configuration summary including optimizer settings, learning rate schedule, and training parameters.\n",
    "\n",
    "**`Details`**\n",
    "\n",
    "The cell sets up TrainingArguments with AdamW optimizer, linear learning rate warmup, cross-entropy loss, and early stopping callback. It configures evaluation strategy, logging, and checkpoint saving. The compute_metrics function calculates accuracy, precision, recall, and F1-macro scores for each evaluation step. All settings align with the proposal requirements for systematic model training and evaluation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load best BERT model for evaluation\n",
    "from transformers import AutoModelForSequenceClassification\n",
    "\n",
    "best_model = AutoModelForSequenceClassification.from_pretrained(best_ckpt_dir).to(device)\n",
    "best_model.eval()\n",
    "\n",
    "# Create trainer with best model for evaluation\n",
    "eval_trainer = Trainer(\n",
    "    model=best_model,\n",
    "    args=training_args,\n",
    "    eval_dataset=ds_test,\n",
    "    compute_metrics=compute_metrics,\n",
    "    tokenizer=tokenizer,\n",
    ")\n",
    "\n",
    "# Evaluate on test set (15%)\n",
    "print(\"Evaluating BERT model on test set...\")\n",
    "test_results = eval_trainer.evaluate()\n",
    "\n",
    "print(\"\\nBERT Model Performance (Test Set) - per proposal Section VI.A:\")\n",
    "print(f\"  Accuracy: {test_results.get('eval_accuracy', 0):.4f}\")\n",
    "print(f\"  Precision: {test_results.get('eval_precision', 0):.4f}\")\n",
    "print(f\"  Recall: {test_results.get('eval_recall', 0):.4f}\")\n",
    "print(f\"  F1-macro: {test_results.get('eval_f1_macro', 0):.4f}\")\n",
    "\n",
    "# Generate predictions for detailed analysis\n",
    "test_predictions = eval_trainer.predict(ds_test)\n",
    "test_preds_bert = np.argmax(test_predictions.predictions, axis=1)\n",
    "test_labels_bert = test_predictions.label_ids\n",
    "\n",
    "# Map predictions back from BERT format (0,1,2) to proposal format (-1,0,1)\n",
    "reverse_mapping = {0: -1, 1: 0, 2: 1}\n",
    "test_preds = np.array([reverse_mapping[p] for p in test_preds_bert])\n",
    "test_labels = np.array([reverse_mapping[l] for l in test_labels_bert])\n",
    "\n",
    "# Classification report\n",
    "print(\"\\nTest Set Classification Report:\")\n",
    "print(classification_report(test_labels, test_preds, \n",
    "                          target_names=['negative/toxic', 'neutral', 'positive'],\n",
    "                          zero_division=0))\n",
    "\n",
    "# Confusion matrix\n",
    "cm_bert = confusion_matrix(test_labels, test_preds, labels=[-1, 0, 1])\n",
    "fig, ax = plt.subplots(figsize=(6, 5))\n",
    "ConfusionMatrixDisplay(cm_bert, display_labels=['negative/toxic', 'neutral', 'positive']).plot(ax=ax, colorbar=False)\n",
    "plt.title('BERT Model - Test Set Confusion Matrix')\n",
    "plt.tight_layout()\n",
    "plt.savefig('exports/confusion_matrices/bert_cm_test.png', dpi=150)\n",
    "plt.close()\n",
    "print(\"\\n✓ Confusion matrix saved to exports/confusion_matrices/bert_cm_test.png\")\n",
    "\n",
    "# Save test predictions\n",
    "test_df_results = pd.DataFrame({\n",
    "    'review': df_test['review'].tolist(),\n",
    "    'gold': test_labels,\n",
    "    'pred': test_preds\n",
    "})\n",
    "test_df_results.to_csv('exports/bert_predictions_test.csv', index=False)\n",
    "print(\"✓ Test predictions saved to exports/bert_predictions_test.csv\")\n",
    "\n",
    "# ROC-AUC and PR-AUC curves (per proposal Section III)\n",
    "from sklearn.metrics import roc_curve, auc, precision_recall_curve, roc_auc_score, average_precision_score\n",
    "from sklearn.preprocessing import label_binarize\n",
    "\n",
    "# Binarize labels for multi-class ROC\n",
    "y_test_bin = label_binarize(test_labels, classes=[-1, 0, 1])\n",
    "n_classes = 3\n",
    "test_probs = torch.softmax(torch.tensor(test_predictions.predictions), dim=-1).numpy()\n",
    "\n",
    "# Compute ROC and PR curves for each class\n",
    "# Note: test_probs columns are in BERT order (0=negative, 1=neutral, 2=positive)\n",
    "# which maps to proposal order: 0→-1, 1→0, 2→1\n",
    "fpr = dict()\n",
    "tpr = dict()\n",
    "roc_auc = dict()\n",
    "precision = dict()\n",
    "recall = dict()\n",
    "pr_auc = dict()\n",
    "\n",
    "# Map BERT probabilities to proposal label order\n",
    "bert_to_proposal = {0: 0, 1: 1, 2: 2}  # BERT index 0→proposal -1, index 1→proposal 0, index 2→proposal 1\n",
    "for i, class_name in enumerate(['negative/toxic', 'neutral', 'positive']):\n",
    "    class_idx = [-1, 0, 1][i]  # Proposal format\n",
    "    bert_idx = {-1: 0, 0: 1, 1: 2}[class_idx]  # BERT format index\n",
    "    y_true_class = (test_labels == class_idx).astype(int)\n",
    "    y_score_class = test_probs[:, bert_idx]  # Use BERT index for probabilities\n",
    "    \n",
    "    fpr[i], tpr[i], _ = roc_curve(y_true_class, y_score_class)\n",
    "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "    \n",
    "    precision[i], recall[i], _ = precision_recall_curve(y_true_class, y_score_class)\n",
    "    pr_auc[i] = average_precision_score(y_true_class, y_score_class)\n",
    "    \n",
    "    print(f\"\\n{class_name} (class {class_idx}):\")\n",
    "    print(f\"  ROC-AUC: {roc_auc[i]:.4f}\")\n",
    "    print(f\"  PR-AUC: {pr_auc[i]:.4f}\")\n",
    "\n",
    "# Plot ROC curves\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# ROC curves\n",
    "ax = axes[0]\n",
    "for i, class_name in enumerate(['negative/toxic', 'neutral', 'positive']):\n",
    "    ax.plot(fpr[i], tpr[i], label=f'{class_name} (AUC = {roc_auc[i]:.3f})')\n",
    "ax.plot([0, 1], [0, 1], 'k--', label='Random')\n",
    "ax.set_xlabel('False Positive Rate')\n",
    "ax.set_ylabel('True Positive Rate')\n",
    "ax.set_title('ROC Curves (per proposal Section III)')\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "# PR curves\n",
    "ax = axes[1]\n",
    "for i, class_name in enumerate(['negative/toxic', 'neutral', 'positive']):\n",
    "    ax.plot(recall[i], precision[i], label=f'{class_name} (AP = {pr_auc[i]:.3f})')\n",
    "ax.set_xlabel('Recall')\n",
    "ax.set_ylabel('Precision')\n",
    "ax.set_title('Precision-Recall Curves (per proposal Section III)')\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "os.makedirs(\"exports/roc_curves\", exist_ok=True)\n",
    "plt.savefig('exports/roc_curves/bert_roc_pr_curves.png', dpi=150)\n",
    "plt.close()\n",
    "print(\"\\n✓ ROC and PR curves saved to exports/roc_curves/bert_roc_pr_curves.png\")\n",
    "\n",
    "# Baseline vs BERT comparison (per proposal Section VI.B)\n",
    "comparison_df = pd.DataFrame({\n",
    "    'Model': ['Baseline (TF-IDF + LogReg)', 'BERT-base-uncased'],\n",
    "    'Accuracy': [test_acc, test_results.get('eval_accuracy', 0)],\n",
    "    'Precision': [test_prec, test_results.get('eval_precision', 0)],\n",
    "    'Recall': [test_rec, test_results.get('eval_recall', 0)],\n",
    "    'F1-macro': [test_f1, test_results.get('eval_f1_macro', 0)],\n",
    "})\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Baseline vs BERT Comparison (per proposal Section VI.B)\")\n",
    "print(\"=\"*60)\n",
    "print(comparison_df.to_string(index=False))\n",
    "comparison_df.to_csv('exports/model_comparison.csv', index=False)\n",
    "print(\"\\n✓ Model comparison saved to exports/model_comparison.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Visualization and Analysis**\n",
    "\n",
    "**`Purpose`**\n",
    "\n",
    "This cell creates visualizations to analyze and compare model performance. It generates plots showing confusion matrices, metrics comparisons, and class distributions.\n",
    "\n",
    "**`Input`**\n",
    "\n",
    "Requires evaluation results from previous cells, including predictions, true labels, and performance metrics for both baseline and BERT models.\n",
    "\n",
    "**`Output`**\n",
    "\n",
    "Saves visualization images to the exports directory, including confusion matrices, metrics comparison charts, and class distribution plots.\n",
    "\n",
    "**`Details`**\n",
    "\n",
    "Creates a grid of visualizations including confusion matrices for baseline and BERT models, side-by-side metrics comparison bar charts, and class distribution analysis. The visualizations help identify which classes are easier or harder to predict, where models make errors, and how performance varies across different sentiment categories. All plots are saved as high-resolution PNG files for inclusion in reports and presentations.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`Purpose`**\n",
    "\n",
    "This cell creates visualizations to analyze and compare model performance. It generates plots showing confusion matrices, metrics comparisons, and class distributions.\n",
    "\n",
    "**`Input`**\n",
    "\n",
    "Requires evaluation results from previous cells, including predictions, true labels, and performance metrics for both baseline and BERT models.\n",
    "\n",
    "**`Output`**\n",
    "\n",
    "Saves visualization images to the exports directory, including confusion matrices, metrics comparison charts, and class distribution plots.\n",
    "\n",
    "**`Details`**\n",
    "\n",
    "Creates a grid of visualizations including confusion matrices for baseline and BERT models, side-by-side metrics comparison bar charts, and class distribution analysis. The visualizations help identify which classes are easier or harder to predict, where models make errors, and how performance varies across different sentiment categories. All plots are saved as high-resolution PNG files for inclusion in reports and presentations.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create comprehensive visualization grid\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 12))\n",
    "\n",
    "# 1. Confusion matrices comparison\n",
    "ax = axes[0, 0]\n",
    "ConfusionMatrixDisplay(cm, display_labels=['negative/toxic', 'neutral', 'positive']).plot(ax=ax, colorbar=False)\n",
    "ax.set_title('Baseline Model - Test Set')\n",
    "\n",
    "ax = axes[0, 1]\n",
    "ConfusionMatrixDisplay(cm_bert, display_labels=['negative/toxic', 'neutral', 'positive']).plot(ax=ax, colorbar=False)\n",
    "ax.set_title('BERT Model - Test Set')\n",
    "\n",
    "# 2. Metrics comparison bar chart\n",
    "ax = axes[1, 0]\n",
    "metrics = ['Accuracy', 'Precision', 'Recall', 'F1-macro']\n",
    "baseline_vals = [test_acc, test_prec, test_rec, test_f1]\n",
    "bert_vals = [test_results.get('eval_accuracy', 0), \n",
    "             test_results.get('eval_precision', 0),\n",
    "             test_results.get('eval_recall', 0),\n",
    "             test_results.get('eval_f1_macro', 0)]\n",
    "\n",
    "x = np.arange(len(metrics))\n",
    "width = 0.35\n",
    "ax.bar(x - width/2, baseline_vals, width, label='Baseline', alpha=0.8)\n",
    "ax.bar(x + width/2, bert_vals, width, label='BERT', alpha=0.8)\n",
    "ax.set_ylabel('Score')\n",
    "ax.set_title('Model Comparison - Test Set Metrics')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(metrics)\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "# 3. Class distribution\n",
    "ax = axes[1, 1]\n",
    "label_counts = df_test['label'].value_counts().sort_index()\n",
    "labels = ['negative/toxic', 'neutral', 'positive']\n",
    "colors = ['#F87171', '#FBBF24', '#34D399']\n",
    "ax.bar(labels, [label_counts.get(-1, 0), label_counts.get(0, 0), label_counts.get(1, 0)], color=colors, alpha=0.8)\n",
    "ax.set_ylabel('Count')\n",
    "ax.set_title('Test Set Class Distribution')\n",
    "ax.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('exports/model_analysis_grid.png', dpi=150)\n",
    "plt.close()\n",
    "print(\"✓ Visualization grid saved to exports/model_analysis_grid.png\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Inference Examples and Model Testing (per proposal)**\n",
    "\n",
    "**`Purpose`**\n",
    "\n",
    "This cell demonstrates the trained model on sample tweets to showcase its ability to handle various types of social media text including toxic content, neutral statements, positive messages, and challenging cases like sarcasm.\n",
    "\n",
    "**`Input`**\n",
    "\n",
    "Requires best_model and best_tokenizer from previous cells. Uses predefined sample tweets representing different sentiment categories.\n",
    "\n",
    "**`Output`**\n",
    "\n",
    "Prints predictions for each sample tweet, showing the predicted sentiment label, confidence score, and probability distribution across all classes.\n",
    "\n",
    "**`Details`**\n",
    "\n",
    "Tests the model on carefully selected examples that represent the diversity of Twitter content. Includes clear toxic examples, neutral statements, positive messages, sarcastic or ambiguous cases, and informal language. For each example, the cell tokenizes the text, runs inference through the model, and maps the output back to proposal format (-1, 0, 1). Displays both the predicted class and the full probability distribution, allowing for analysis of model confidence and decision-making process.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`Purpose`**\n",
    "\n",
    "This cell initializes the BERT model and prepares the datasets for transformer-based training. It loads the pre-trained BERT tokenizer, converts text to numerical representations, and sets up the model architecture for sequence classification.\n",
    "\n",
    "**`Input`**\n",
    "\n",
    "Requires df_train, df_val, and df_test DataFrames with cleaned text in the review column and labels in the label column. The labels should be in proposal format (-1, 0, 1).\n",
    "\n",
    "**`Output`**\n",
    "\n",
    "Creates tokenized datasets (ds_train, ds_val, ds_test) ready for PyTorch training. Initializes the BERT model on the specified device (CPU or GPU) and prints confirmation messages.\n",
    "\n",
    "**`Details`**\n",
    "\n",
    "The cell maps labels from proposal format (-1, 0, 1) to BERT format (0, 1, 2) for compatibility with the model. It uses BERT WordPiece tokenizer to convert text into input IDs and attention masks. The tokenization process handles text truncation and padding to a maximum length of 128 tokens, which is standard for Twitter posts. The datasets are formatted for PyTorch with appropriate column selection and tensor formatting.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Smoke test with sample tweets (per proposal: demonstrate context-aware understanding)\n",
    "sample_tweets = [\n",
    "    (\"Toxic example\", \"This is absolutely disgusting! People like you should be banned from social media. Horrible!\"),\n",
    "    (\"Neutral example\", \"Just finished my morning coffee. Weather is okay today, nothing special.\"),\n",
    "    (\"Positive example\", \"So grateful for all the support today! Amazing community, thank you everyone! 🙏\"),\n",
    "    (\"Sarcastic/Toxic\", \"Oh wonderful, another day of dealing with this nonsense. Just perfect...\"),\n",
    "    (\"Informal positive\", \"This made my day! So happy right now! Best news ever! 🔥\"),\n",
    "]\n",
    "\n",
    "print(\"Testing BERT model on sample tweets (per proposal: handles sarcasm, informal language):\\n\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Load model and tokenizer if not already loaded\n",
    "try:\n",
    "    # Check if best_model exists and is on the correct device\n",
    "    _ = best_model\n",
    "    best_model = best_model.to(device)\n",
    "    best_model.eval()  # Ensure eval mode\n",
    "except NameError:\n",
    "    # Load model if not already loaded\n",
    "    from transformers import AutoModelForSequenceClassification\n",
    "    best_model = AutoModelForSequenceClassification.from_pretrained(best_ckpt_dir).to(device)\n",
    "    best_model.eval()\n",
    "\n",
    "best_tokenizer = AutoTokenizer.from_pretrained(best_ckpt_dir, use_fast=True)\n",
    "\n",
    "for label, tweet in sample_tweets:\n",
    "    # Tokenize\n",
    "    inputs = best_tokenizer(tweet, return_tensors=\"pt\", truncation=True, padding=True, max_length=128).to(device)\n",
    "    \n",
    "    # Predict\n",
    "    with torch.no_grad():\n",
    "        outputs = best_model(**inputs)\n",
    "        probs = torch.softmax(outputs.logits, dim=-1)[0].cpu().numpy()\n",
    "        pred_bert = np.argmax(probs)  # BERT format: 0, 1, 2\n",
    "    \n",
    "    # Map prediction from BERT format (0,1,2) to proposal format (-1,0,1)\n",
    "    bert_to_proposal = {0: -1, 1: 0, 2: 1}\n",
    "    pred = bert_to_proposal[pred_bert]\n",
    "    \n",
    "    # Map prediction to label name\n",
    "    label_map = {-1: \"negative/toxic\", 0: \"neutral\", 1: \"positive\"}\n",
    "    pred_label = label_map.get(pred, \"unknown\")\n",
    "    confidence = probs[pred_bert] * 100\n",
    "    \n",
    "    # Map probabilities to proposal format for display\n",
    "    prob_map = {0: -1, 1: 0, 2: 1}  # BERT index → proposal label\n",
    "    probs_proposal = {label_map[prob_map[i]]: float(probs[i]) for i in range(3)}\n",
    "    \n",
    "    print(f\"\\n{label}:\")\n",
    "    print(f\"  Tweet: \\\"{tweet}\\\"\")\n",
    "    print(f\"  Prediction: {pred_label} (confidence: {confidence:.2f}%)\")\n",
    "    print(f\"  Probabilities: negative/toxic={probs_proposal['negative/toxic']:.3f}, neutral={probs_proposal['neutral']:.3f}, positive={probs_proposal['positive']:.3f}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"✓ Inference examples completed\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Export and Deployment Preparation**\n",
    "\n",
    "**`Purpose`**\n",
    "\n",
    "This cell prepares all artifacts for deployment and documentation. It exports model weights, experiment logs, model cards, and summary reports in various formats.\n",
    "\n",
    "**`Input`**\n",
    "\n",
    "Requires best_model, best_ckpt_dir, and all evaluation results from previous cells. Needs runs_log.csv and other experiment outputs.\n",
    "\n",
    "**`Output`**\n",
    "\n",
    "Creates quantized model weights, consolidated experiment logs in CSV and Excel formats, model card JSON file, and comprehensive summary report. All files are saved to the exports directory.\n",
    "\n",
    "**`Details`**\n",
    "\n",
    "The export process saves quantized PyTorch model weights for lightweight deployment. Consolidates all experiment runs into a single CSV and Excel file with all hyperparameters and metrics. Generates a model card in JSON format containing metadata, performance metrics, and configuration details. Creates a text summary report with key findings, model comparisons, and target achievement status. All exports are organized in the exports directory for easy access and sharing.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`Purpose`**\n",
    "\n",
    "This cell creates visualizations to analyze and compare model performance. It generates plots showing confusion matrices, metrics comparisons, and class distributions.\n",
    "\n",
    "**`Input`**\n",
    "\n",
    "Requires evaluation results from previous cells, including predictions, true labels, and performance metrics for both baseline and BERT models.\n",
    "\n",
    "**`Output`**\n",
    "\n",
    "Saves visualization images to the exports directory, including confusion matrices, metrics comparison charts, and class distribution plots.\n",
    "\n",
    "**`Details`**\n",
    "\n",
    "Creates a grid of visualizations including confusion matrices for baseline and BERT models, side-by-side metrics comparison bar charts, and class distribution analysis. The visualizations help identify which classes are easier or harder to predict, where models make errors, and how performance varies across different sentiment categories. All plots are saved as high-resolution PNG files for inclusion in reports and presentations.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export artifacts for deployment\n",
    "print(\"Exporting artifacts for deployment...\")\n",
    "\n",
    "# 0. Ensure full model is saved (pytorch_model.bin)\n",
    "print(\"\\n0. Ensuring full model is saved...\")\n",
    "full_model_path = Path(best_ckpt_dir) / \"pytorch_model.bin\"\n",
    "if not full_model_path.exists():\n",
    "    print(\"   Full model not found, saving it now...\")\n",
    "    best_model.save_pretrained(best_ckpt_dir)\n",
    "    print(f\"   Full model saved to {best_ckpt_dir}\")\n",
    "else:\n",
    "    print(f\"   Full model already exists at {full_model_path}\")\n",
    "\n",
    "# 1. Save quantized model weights (for lightweight deployment)\n",
    "print(\"\\n1. Saving quantized model weights...\")\n",
    "try:\n",
    "    quantized_model = torch.quantization.quantize_dynamic(\n",
    "        best_model.cpu(), {torch.nn.Linear}, dtype=torch.qint8\n",
    "    )\n",
    "    quantized_path = Path(best_ckpt_dir) / 'pytorch_model_quantized.bin'\n",
    "    torch.save(quantized_model.state_dict(), quantized_path)\n",
    "    print(f\"   ✓ Quantized model saved to {quantized_path}\")\n",
    "except Exception as e:\n",
    "    print(f\"   ⚠ Quantization failed: {e}\")\n",
    "\n",
    "# 2. Export consolidated experiment logs\n",
    "print(\"\\n2. Exporting consolidated experiment logs...\")\n",
    "if os.path.exists(\"runs_log.csv\"):\n",
    "    runs_df = pd.read_csv(\"runs_log.csv\")\n",
    "    runs_df.to_csv(\"exports/experiment_runs_all.csv\", index=False)\n",
    "    print(\"   ✓ Experiment logs exported to exports/experiment_runs_all.csv\")\n",
    "    \n",
    "    # Generate Excel summary if openpyxl available\n",
    "    try:\n",
    "        runs_df.to_excel(\"exports/experiment_runs_all.xlsx\", index=False)\n",
    "        print(\"   ✓ Excel summary exported to exports/experiment_runs_all.xlsx\")\n",
    "    except:\n",
    "        print(\"   ⚠ Excel export skipped (openpyxl not available)\")\n",
    "\n",
    "# 3. Generate model card information\n",
    "print(\"\\n3. Generating model card...\")\n",
    "model_card = {\n",
    "    \"model_name\": MODEL_NAME,\n",
    "    \"task\": \"Toxic Comment Detection on Twitter\",\n",
    "    \"num_labels\": 3,\n",
    "    \"labels\": [\"negative/toxic (-1)\", \"neutral (0)\", \"positive (1)\"],\n",
    "    \"dataset\": \"mteb/tweet_sentiment_extraction\",\n",
    "    \"training_split\": \"70%\",\n",
    "    \"validation_split\": \"15%\",\n",
    "    \"test_split\": \"15%\",\n",
    "    \"max_sequence_length\": MAX_LEN,\n",
    "    \"optimizer\": \"AdamW\",\n",
    "    \"loss\": \"Cross-entropy\",\n",
    "    \"scheduler\": \"Linear warmup\",\n",
    "    \"best_test_accuracy\": float(test_results.get('eval_accuracy', 0)),\n",
    "    \"best_test_f1_macro\": float(test_results.get('eval_f1_macro', 0)),\n",
    "    \"baseline_accuracy\": float(test_acc),\n",
    "    \"baseline_f1_macro\": float(test_f1),\n",
    "    \"improvement\": f\"{((test_results.get('eval_f1_macro', 0) - test_f1) / test_f1 * 100):.2f}%\",\n",
    "}\n",
    "\n",
    "with open(\"exports/model_card.json\", \"w\") as f:\n",
    "    json.dump(model_card, f, indent=2)\n",
    "print(\"   ✓ Model card saved to exports/model_card.json\")\n",
    "\n",
    "# 4. Create summary report\n",
    "print(\"\\n4. Creating summary report...\")\n",
    "summary_text = f\"\"\"\n",
    "Twitter Toxicity Detection Project - Summary Report\n",
    "==================================================\n",
    "\n",
    "Dataset: mteb/tweet_sentiment_extraction\n",
    "Total samples: {len(df)}\n",
    "Train/Val/Test split: 70%/15%/15%\n",
    "\n",
    "Baseline Model (TF-IDF + Logistic Regression):\n",
    "  - Accuracy: {test_acc:.4f}\n",
    "  - Precision: {test_prec:.4f}\n",
    "  - Recall: {test_rec:.4f}\n",
    "  - F1-macro: {test_f1:.4f}\n",
    "\n",
    "BERT Model (bert-base-uncased):\n",
    "  - Accuracy: {test_results.get('eval_accuracy', 0):.4f}\n",
    "  - Precision: {test_results.get('eval_precision', 0):.4f}\n",
    "  - Recall: {test_results.get('eval_recall', 0):.4f}\n",
    "  - F1-macro: {test_results.get('eval_f1_macro', 0):.4f}\n",
    "\n",
    "Improvement over baseline:\n",
    "  - F1-macro improvement: {((test_results.get('eval_f1_macro', 0) - test_f1) / test_f1 * 100):.2f}%\n",
    "\n",
    "Target F1-macro (per proposal): >0.85\n",
    "Achieved F1-macro: {test_results.get('eval_f1_macro', 0):.4f}\n",
    "Target met: {'✓ YES' if test_results.get('eval_f1_macro', 0) > 0.85 else '✗ NO'}\n",
    "\n",
    "All artifacts exported to:\n",
    "  - Model checkpoints: {best_ckpt_dir}\n",
    "  - Predictions: exports/\n",
    "  - Visualizations: exports/confusion_matrices/, exports/roc_curves/\n",
    "  - Logs: runs_log.csv, exports/experiment_runs_all.csv\n",
    "\"\"\"\n",
    "\n",
    "with open(\"exports/summary_report.txt\", \"w\") as f:\n",
    "    f.write(summary_text)\n",
    "print(summary_text)\n",
    "print(\"\\n✓ Summary report saved to exports/summary_report.txt\")\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"✓ All exports completed successfully!\")\n",
    "print(\"=\"*70)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold\n",
    "from sklearn.metrics import classification_report, precision_score, recall_score\n",
    "\n",
    "# TF-IDF vectorization (per proposal: Term Frequency-Inverse Document Frequency method)\n",
    "tfidf = TfidfVectorizer(\n",
    "    max_features=50000,\n",
    "    ngram_range=(1,2),  # Word 1-2 ngrams to capture phrases\n",
    "    lowercase=True\n",
    ")\n",
    "\n",
    "# Prepare data\n",
    "X_tr = df_train['review'].tolist()\n",
    "y_tr = df_train['label'].values\n",
    "X_va = df_val['review'].tolist()\n",
    "y_va = df_val['label'].values\n",
    "\n",
    "# Transform text to TF-IDF vectors\n",
    "print(\"Fitting TF-IDF vectorizer...\")\n",
    "X_tr_tfidf = tfidf.fit_transform(X_tr)\n",
    "X_va_tfidf = tfidf.transform(X_va)\n",
    "\n",
    "# Hyperparameter tuning with grid search and cross-validation (per proposal Section VI.B)\n",
    "print(\"\\nPerforming hyperparameter tuning with GridSearchCV...\")\n",
    "param_grid = {\n",
    "    'C': [0.5, 1.0, 2.0, 4.0],\n",
    "    'class_weight': [None, 'balanced', {-1: 1.2, 0: 0.8, 1: 1.2}],  # Custom: reduce neutral bias\n",
    "    'max_iter': [1000, 2000]\n",
    "}\n",
    "\n",
    "logreg_base = LogisticRegression(random_state=RANDOM_SEED)\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=RANDOM_SEED)\n",
    "\n",
    "grid_search = GridSearchCV(\n",
    "    logreg_base, \n",
    "    param_grid=param_grid, \n",
    "    cv=skf, \n",
    "    scoring='f1_macro',\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "grid_search.fit(X_tr_tfidf, y_tr)\n",
    "print(f\"\\nBest parameters: {grid_search.best_params_}\")\n",
    "print(f\"Best CV score (F1-macro): {grid_search.best_score_:.4f}\")\n",
    "\n",
    "# Train final model with best parameters\n",
    "logreg = grid_search.best_estimator_\n",
    "preds = logreg.predict(X_va_tfidf)\n",
    "\n",
    "# Calculate metrics (per proposal Section VI.A)\n",
    "acc_base = accuracy_score(y_va, preds)\n",
    "prec_base = precision_score(y_va, preds, average='macro', zero_division=0)\n",
    "rec_base = recall_score(y_va, preds, average='macro', zero_division=0)\n",
    "f1_base = f1_score(y_va, preds, average='macro', zero_division=0)\n",
    "\n",
    "print(\"\\nBaseline Model Performance (Validation Set):\")\n",
    "print({\n",
    "    \"model\": \"tfidf-logreg\",\n",
    "    \"accuracy\": acc_base,\n",
    "    \"precision\": prec_base,\n",
    "    \"recall\": rec_base,\n",
    "    \"f1_macro\": f1_base\n",
    "})\n",
    "\n",
    "# Classification report\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_va, preds, \n",
    "                          target_names=['negative/toxic', 'neutral', 'positive'],\n",
    "                          zero_division=0))\n",
    "\n",
    "# Log to runs_log.csv\n",
    "row = {\n",
    "    \"member\": \"baseline\",\n",
    "    \"model\": \"tfidf-logreg\",\n",
    "    \"num_train_epochs\": None,\n",
    "    \"per_device_train_batch_size\": None,\n",
    "    \"learning_rate\": None,\n",
    "    \"weight_decay\": None,\n",
    "    \"warmup_steps\": None,\n",
    "    \"lr_scheduler_type\": None,\n",
    "    \"gradient_accumulation_steps\": None,\n",
    "    \"max_seq_length\": None,\n",
    "    \"seed\": RANDOM_SEED,\n",
    "    \"fp16\": False,\n",
    "    \"accuracy\": acc_base,\n",
    "    \"precision\": prec_base,\n",
    "    \"recall\": rec_base,\n",
    "    \"f1_macro\": f1_base,\n",
    "    \"notes\": f\"TF-IDF + LogReg baseline with GridSearchCV. Best params: {grid_search.best_params_}\"\n",
    "}\n",
    "\n",
    "pd.DataFrame([row]).to_csv(\"runs_log.csv\", mode=\"a\",\n",
    "                           index=False, header=not os.path.exists(\"runs_log.csv\"))\n",
    "\n",
    "# Save baseline model\n",
    "os.makedirs(\"models\", exist_ok=True)\n",
    "import joblib\n",
    "joblib.dump(logreg, \"models/baseline_tfidf_logreg.joblib\")\n",
    "joblib.dump(tfidf, \"models/baseline_tfidf_vectorizer.joblib\")\n",
    "print(\"\\n✓ Baseline model saved to models/baseline_tfidf_logreg.joblib\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wirMD1MxrU9C"
   },
   "source": [
    "# **Fast Mode Configuration (Optional)**\n",
    "\n",
    "**`Purpose`**\n",
    "\n",
    "This cell provides an option to reduce the training dataset size for faster experimentation and development. When enabled, it uses a subset of the training data while keeping validation and test sets intact for reliable evaluation.\n",
    "\n",
    "**`Input`**\n",
    "\n",
    "Requires df_train, df_val, and df_test DataFrames from previous cells. The FAST_MODE flag controls whether data reduction is applied.\n",
    "\n",
    "**`Output`**\n",
    "\n",
    "Prints the reduced dataset sizes and percentages. If FAST_MODE is disabled, confirms that full datasets will be used.\n",
    "\n",
    "**`Details`**\n",
    "\n",
    "When FAST_MODE is True, the training data is randomly sampled to 40% of its original size using a fixed random seed for reproducibility. Validation and test sets remain unchanged to ensure fair evaluation. This allows for quicker iteration during development while maintaining the ability to run full experiments when needed.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "toLXqiqirU9C"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`Purpose`**\n",
    "\n",
    "This cell provides an option to reduce the training dataset size for faster experimentation and development. When enabled, it uses a subset of the training data while keeping validation and test sets intact for reliable evaluation.\n",
    "\n",
    "**`Input`**\n",
    "\n",
    "Requires df_train, df_val, and df_test DataFrames from previous cells. The FAST_MODE flag controls whether data reduction is applied.\n",
    "\n",
    "**`Output`**\n",
    "\n",
    "Prints the reduced dataset sizes and percentages. If FAST_MODE is disabled, confirms that full datasets will be used.\n",
    "\n",
    "**`Details`**\n",
    "\n",
    "When FAST_MODE is True, the training data is randomly sampled to 40% of its original size using a fixed random seed for reproducibility. Validation and test sets remain unchanged to ensure fair evaluation. This allows for quicker iteration during development while maintaining the ability to run full experiments when needed.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BHsurDXcrU9C",
    "outputId": "424247b5-c09e-4681-d76f-0e2b0d6e1a98"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FAST_MODE disabled: using full train/val/test splits\n"
     ]
    }
   ],
   "source": [
    "FAST_MODE = True  # Set to True for faster training (40% data), False for full dataset\n",
    "TRAIN_FRACTION = 0.40 if FAST_MODE else 1.0\n",
    "VAL_FRACTION = 1.0  # Keep full validation/test by default\n",
    "\n",
    "if FAST_MODE and TRAIN_FRACTION < 1.0:\n",
    "    df_train = (df_train\n",
    "                .sample(frac=TRAIN_FRACTION, random_state=RANDOM_SEED)\n",
    "                .sort_values('id')\n",
    "                .reset_index(drop=True))\n",
    "    if VAL_FRACTION < 1.0:\n",
    "        df_val = (df_val\n",
    "                  .sample(frac=VAL_FRACTION, random_state=RANDOM_SEED)\n",
    "                  .sort_values('id')\n",
    "                  .reset_index(drop=True))\n",
    "        df_test = (df_test\n",
    "                   .sample(frac=VAL_FRACTION, random_state=RANDOM_SEED)\n",
    "                   .sort_values('id')\n",
    "                   .reset_index(drop=True))\n",
    "    print(f\"[FAST_MODE ENABLED] Using {TRAIN_FRACTION*100:.0f}% of training data\\n  Train: {len(df_train)} samples{len(df_train)} (~{TRAIN_FRACTION*100:.0f}%), val={len(df_val)}, test={len(df_test)}\")\n",
    "else:\n",
    "    print(\"FAST_MODE disabled: using full train/val/test splits\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SKK7B6rTrU9C"
   },
   "source": [
    "# **Baseline TF-IDF + Logistic Regression (per proposal Section V.C)**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "29E3mZ-QrU9C"
   },
   "source": [
    "**`Purpose`**\n",
    "\n",
    "This block builds a baseline model using TF-IDF vectorization and Logistic Regression as a reference point per proposal Section V.C. The baseline model acts as a foundation for measuring improvements from more complex deep learning methods. It uses traditional machine learning techniques that are simple, interpretable, and computationally efficient.\n",
    "\n",
    "**`Input`**\n",
    "\n",
    "The inputs are the train_df and val_df frames created earlier. Only the review and label columns are used. The TF-IDF vectorizer is configured with word 1-2 ngrams and a vocabulary limit to cap memory and training time. The labels are taken directly as integer classes (-1, 0, 1).\n",
    "\n",
    "**`Output`**\n",
    "\n",
    "The block prints a compact dictionary that contains baseline accuracy, precision, recall, and F1-score (per proposal Section VI.A). It also appends a structured row to runs_log.csv so that the baseline appears in the experiment ledger with model name, scores, and notes. These outputs provide both an on-screen summary and a durable record for later tables and charts.\n",
    "\n",
    "**`Details`**\n",
    "\n",
    "A TF-IDF vectorizer is fit on the training text and applied to the validation text, producing sparse matrices. A Logistic Regression model is trained with hyperparameter tuning via grid search and cross-validation (per proposal Section VI.B). Predictions for the validation set are compared against the gold labels to compute accuracy, precision, recall, and F1-score, where macro-F1 treats all classes equally. The metrics are printed and then written to the log file with consistent column names.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "r8R3yKMVrU9C",
    "outputId": "cf943d0e-962e-43b5-b236-4329be20423b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting TF-IDF vectorizer...\n",
      "\n",
      "Performing hyperparameter tuning with GridSearchCV...\n",
      "Fitting 5 folds for each of 48 candidates, totalling 240 fits\n",
      "\n",
      "Best parameters: {'C': 1.0, 'class_weight': 'balanced', 'max_iter': 2000, 'penalty': 'l1'}\n",
      "Best CV score (F1-macro): 0.6579\n",
      "\n",
      "Baseline Model Performance (Validation Set):\n",
      "{'model': 'tfidf-logreg', 'accuracy': 0.6745960502692998, 'precision': 0.6856959388663061, 'recall': 0.6677298814979974, 'f1_macro': 0.6736792486942251}\n",
      "\n",
      "Classification Report:\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "negative/toxic       0.68      0.59      0.63      1288\n",
      "       neutral       0.62      0.73      0.67      1764\n",
      "      positive       0.76      0.69      0.72      1404\n",
      "\n",
      "      accuracy                           0.67      4456\n",
      "     macro avg       0.69      0.67      0.67      4456\n",
      "  weighted avg       0.68      0.67      0.67      4456\n",
      "\n",
      "\n",
      "✓ Baseline model saved to models/baseline_tfidf_logreg.joblib\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold\n",
    "from sklearn.metrics import classification_report, precision_score, recall_score\n",
    "\n",
    "# TF-IDF vectorization (per proposal: Term Frequency-Inverse Document Frequency method)\n",
    "# Enhanced settings for better accuracy\n",
    "tfidf = TfidfVectorizer(\n",
    "    max_features=100000,  # Increased from 50000 to capture more features\n",
    "    ngram_range=(1,3),  # Expanded to 1-3 ngrams to capture more context\n",
    "    lowercase=True,\n",
    "    min_df=2,  # Ignore terms that appear in fewer than 2 documents\n",
    "    max_df=0.95,  # Ignore terms that appear in more than 95% of documents\n",
    "    sublinear_tf=True  # Apply sublinear tf scaling (1 + log(tf))\n",
    ")\n",
    "\n",
    "# Prepare data\n",
    "X_tr = df_train['review'].tolist()\n",
    "y_tr = df_train['label'].values\n",
    "X_va = df_val['review'].tolist()\n",
    "y_va = df_val['label'].values\n",
    "\n",
    "# Transform text to TF-IDF vectors\n",
    "print(\"Fitting TF-IDF vectorizer...\")\n",
    "X_tr_tfidf = tfidf.fit_transform(X_tr)\n",
    "X_va_tfidf = tfidf.transform(X_va)\n",
    "\n",
    "# Hyperparameter tuning with grid search and cross-validation (per proposal Section VI.B)\n",
    "# Expanded search space for better accuracy\n",
    "print(\"\\nPerforming hyperparameter tuning with GridSearchCV...\")\n",
    "# Use liblinear which supports both l1 and l2 penalties\n",
    "param_grid = {\n",
    "    'C': [0.1, 0.5, 1.0, 2.0, 4.0, 8.0],  # Expanded C range\n",
    "    'class_weight': [None, 'balanced', {-1: 1.2, 0: 0.8, 1: 1.2}],  # Custom: reduce neutral bias\n",
    "    'max_iter': [2000, 3000],  # Increased iterations\n",
    "    'penalty': ['l1', 'l2']  # Try both regularization types\n",
    "}\n",
    "\n",
    "logreg_base = LogisticRegression(solver='liblinear', random_state=RANDOM_SEED)\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=RANDOM_SEED)\n",
    "\n",
    "grid_search = GridSearchCV(\n",
    "    logreg_base,\n",
    "    param_grid=param_grid,\n",
    "    cv=skf,\n",
    "    scoring='f1_macro',\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "grid_search.fit(X_tr_tfidf, y_tr)\n",
    "print(f\"\\nBest parameters: {grid_search.best_params_}\")\n",
    "print(f\"Best CV score (F1-macro): {grid_search.best_score_:.4f}\")\n",
    "\n",
    "# Train final model with best parameters\n",
    "logreg = grid_search.best_estimator_\n",
    "preds = logreg.predict(X_va_tfidf)\n",
    "\n",
    "# Calculate metrics (per proposal Section VI.A)\n",
    "acc_base = accuracy_score(y_va, preds)\n",
    "prec_base = precision_score(y_va, preds, average='macro', zero_division=0)\n",
    "rec_base = recall_score(y_va, preds, average='macro', zero_division=0)\n",
    "f1_base = f1_score(y_va, preds, average='macro', zero_division=0)\n",
    "\n",
    "print(\"\\nBaseline Model Performance (Validation Set):\")\n",
    "print({\n",
    "    \"model\": \"tfidf-logreg\",\n",
    "    \"accuracy\": acc_base,\n",
    "    \"precision\": prec_base,\n",
    "    \"recall\": rec_base,\n",
    "    \"f1_macro\": f1_base\n",
    "})\n",
    "\n",
    "# Classification report\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_va, preds,\n",
    "                          target_names=['negative/toxic', 'neutral', 'positive'],\n",
    "                          zero_division=0))\n",
    "\n",
    "# Log to runs_log.csv\n",
    "row = {\n",
    "    \"member\": \"baseline\",\n",
    "    \"model\": \"tfidf-logreg\",\n",
    "    \"num_train_epochs\": None,\n",
    "    \"per_device_train_batch_size\": None,\n",
    "    \"learning_rate\": None,\n",
    "    \"weight_decay\": None,\n",
    "    \"warmup_steps\": None,\n",
    "    \"lr_scheduler_type\": None,\n",
    "    \"gradient_accumulation_steps\": None,\n",
    "    \"max_seq_length\": None,\n",
    "    \"seed\": RANDOM_SEED,\n",
    "    \"fp16\": False,\n",
    "    \"accuracy\": acc_base,\n",
    "    \"precision\": prec_base,\n",
    "    \"recall\": rec_base,\n",
    "    \"f1_macro\": f1_base,\n",
    "    \"notes\": f\"TF-IDF + LogReg baseline with GridSearchCV. Best params: {grid_search.best_params_}\"\n",
    "}\n",
    "\n",
    "pd.DataFrame([row]).to_csv(\"runs_log.csv\", mode=\"a\",\n",
    "                           index=False, header=not os.path.exists(\"runs_log.csv\"))\n",
    "\n",
    "# Save baseline model\n",
    "os.makedirs(\"models\", exist_ok=True)\n",
    "import joblib\n",
    "joblib.dump(logreg, \"models/baseline_tfidf_logreg.joblib\")\n",
    "joblib.dump(tfidf, \"models/baseline_tfidf_vectorizer.joblib\")\n",
    "print(\"\\n✓ Baseline model saved to models/baseline_tfidf_logreg.joblib\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9XvcBD5xrU9C"
   },
   "source": [
    "# Baseline Evaluation on Test Set\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`Purpose`**\n",
    "\n",
    "This cell creates visualizations to analyze and compare model performance. It generates plots showing confusion matrices, metrics comparisons, and class distributions.\n",
    "\n",
    "**`Input`**\n",
    "\n",
    "Requires evaluation results from previous cells, including predictions, true labels, and performance metrics for both baseline and BERT models.\n",
    "\n",
    "**`Output`**\n",
    "\n",
    "Saves visualization images to the exports directory, including confusion matrices, metrics comparison charts, and class distribution plots.\n",
    "\n",
    "**`Details`**\n",
    "\n",
    "Creates a grid of visualizations including confusion matrices for baseline and BERT models, side-by-side metrics comparison bar charts, and class distribution analysis. The visualizations help identify which classes are easier or harder to predict, where models make errors, and how performance varies across different sentiment categories. All plots are saved as high-resolution PNG files for inclusion in reports and presentations.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1WaDs7nxrU9D",
    "outputId": "6140ec48-d299-4475-8fa7-11fcd1ccd6dc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using models from previous cell...\n",
      "Baseline Model Performance (Test Set):\n",
      "{'model': 'tfidf-logreg', 'accuracy': 0.6568364611260054, 'precision': 0.6697405245796803, 'recall': 0.6501692273785475, 'f1_macro': 0.6562920690025043}\n",
      "\n",
      "Test Set Classification Report:\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "negative/toxic       0.69      0.56      0.62      1292\n",
      "       neutral       0.60      0.70      0.65      1781\n",
      "      positive       0.72      0.69      0.70      1403\n",
      "\n",
      "      accuracy                           0.66      4476\n",
      "     macro avg       0.67      0.65      0.66      4476\n",
      "  weighted avg       0.66      0.66      0.66      4476\n",
      "\n",
      "\n",
      "✓ Confusion matrix saved to exports/confusion_matrices/baseline_cm_test.png\n"
     ]
    }
   ],
   "source": [
    "# Evaluate baseline on test set (15%)\n",
    "# Load models if not already in memory (in case this cell is run independently)\n",
    "try:\n",
    "    # Check if tfidf and logreg are defined\n",
    "    _ = tfidf\n",
    "    _ = logreg\n",
    "    print(\"Using models from previous cell...\")\n",
    "except NameError:\n",
    "    # Try to load from saved files\n",
    "    import joblib\n",
    "    import os\n",
    "    model_path = \"models/baseline_tfidf_logreg.joblib\"\n",
    "    vectorizer_path = \"models/baseline_tfidf_vectorizer.joblib\"\n",
    "\n",
    "    if os.path.exists(model_path) and os.path.exists(vectorizer_path):\n",
    "        print(\"Loading baseline models from disk...\")\n",
    "        tfidf = joblib.load(vectorizer_path)\n",
    "        logreg = joblib.load(model_path)\n",
    "        print(\"✓ Models loaded successfully\")\n",
    "    else:\n",
    "        raise NameError(\n",
    "            \"Baseline models not found. Please run Cell 12 (Baseline TF-IDF + Logistic Regression training) first to train and save the models.\"\n",
    "        )\n",
    "\n",
    "X_te = df_test['review'].tolist()\n",
    "y_te = df_test['label'].values\n",
    "X_te_tfidf = tfidf.transform(X_te)\n",
    "\n",
    "test_preds = logreg.predict(X_te_tfidf)\n",
    "\n",
    "# Calculate test metrics\n",
    "test_acc = accuracy_score(y_te, test_preds)\n",
    "test_prec = precision_score(y_te, test_preds, average='macro', zero_division=0)\n",
    "test_rec = recall_score(y_te, test_preds, average='macro', zero_division=0)\n",
    "test_f1 = f1_score(y_te, test_preds, average='macro', zero_division=0)\n",
    "\n",
    "print(\"Baseline Model Performance (Test Set):\")\n",
    "print({\n",
    "    \"model\": \"tfidf-logreg\",\n",
    "    \"accuracy\": test_acc,\n",
    "    \"precision\": test_prec,\n",
    "    \"recall\": test_rec,\n",
    "    \"f1_macro\": test_f1\n",
    "})\n",
    "\n",
    "print(\"\\nTest Set Classification Report:\")\n",
    "print(classification_report(y_te, test_preds,\n",
    "                          target_names=['negative/toxic', 'neutral', 'positive'],\n",
    "                          zero_division=0))\n",
    "\n",
    "# Save test predictions\n",
    "os.makedirs(\"exports\", exist_ok=True)\n",
    "pd.DataFrame({\n",
    "    'review': X_te,\n",
    "    'gold': y_te,\n",
    "    'pred': test_preds\n",
    "}).to_csv('exports/baseline_predictions_test.csv', index=False)\n",
    "\n",
    "# Confusion matrix\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "cm = confusion_matrix(y_te, test_preds, labels=[-1, 0, 1])\n",
    "fig, ax = plt.subplots(figsize=(6, 5))\n",
    "ConfusionMatrixDisplay(cm, display_labels=['negative/toxic', 'neutral', 'positive']).plot(ax=ax, colorbar=False)\n",
    "plt.title('Baseline Model - Test Set Confusion Matrix')\n",
    "plt.tight_layout()\n",
    "os.makedirs(\"exports/confusion_matrices\", exist_ok=True)\n",
    "plt.savefig('exports/confusion_matrices/baseline_cm_test.png', dpi=150)\n",
    "plt.close()\n",
    "print(\"\\n✓ Confusion matrix saved to exports/confusion_matrices/baseline_cm_test.png\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rAVqaDxBrU9D"
   },
   "source": [
    "# **BERT Model Initialization and Tokenization (per proposal Section V.C)**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ybWpnWBNrU9D"
   },
   "source": [
    "**`Purpose`**\n",
    "\n",
    "This block initializes the BERT-base-uncased model per proposal Section V.C for toxicity classification. It loads the BERT tokenizer (WordPiece tokenizer) and prepares the datasets for transformer fine-tuning by converting tweets into numerical input representations suitable for model processing.\n",
    "\n",
    "**`Input`**\n",
    "\n",
    "The inputs are the training, validation, and test DataFrames created earlier. The BERT tokenizer is loaded from the transformers library, and a maximum sequence length is specified to keep batch shapes uniform.\n",
    "\n",
    "**`Output`**\n",
    "\n",
    "The block prints the resolved model name and confirms tokenization completion. Three datasets.Dataset objects are produced with tensor columns input_ids, attention_mask, and label. A classification model with three output labels is created and moved to the detected device.\n",
    "\n",
    "**`Details`**\n",
    "\n",
    "The BERT tokenizer (WordPiece tokenizer) is loaded with the fast backend and wrapped in a function that applies truncation and padding to a fixed length of 128 tokens (standard for tweets). The pandas frames are converted into Dataset objects, tokenization is applied in batches for speed, and the dataset columns are formatted as PyTorch tensors. The model is loaded with a task-specific head sized to three classes and placed on CPU or GPU.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 605,
     "referenced_widgets": [
      "d2a541df69dd421d80d822515bd66f00",
      "2d99b9709dcf44fc8ad70b8151856761",
      "69e62eb154b143d796173107b250c0e7",
      "2fa7525f360f4a12ad56f719c960d391",
      "c746523a9b6747258829bbca9355b40d",
      "6ef4e485fef54637bf4e2ab59d66afdc",
      "0add817e35ad42bbab69c8df677074fd",
      "6e66a64d8c3d4fbc9c74355d833fd43d",
      "6790a5b05142492294d338374f5fe13a",
      "20a4d2f288a946d59b2abbd527b16725",
      "05ee02e4e9c34660aa2253f431afebe5",
      "ed80558000a3482480bbe8e3eb5aed8d",
      "bc3e22eee5134962b6cc39bd8b21d7eb",
      "1385652be2b94ea3acfd770c482a1c09",
      "01ef638e5c834442a7df6eb482e6eabe",
      "3994702573114f769a0d9a198f92f171",
      "2c9692150c094beea21579c402929a36",
      "c714306a078b48b09c735bea1faca6bb",
      "592fcf7c164f4fb582e7da9c120df830",
      "5011e8d5bfa840e693ff755f679c4949",
      "48c873ccd5404aedae9a2be61fc75251",
      "d41eec1669cf43279fd6d5d0d1076e9e",
      "90ab613b3b624d46bf45fcf2df6d59e2",
      "6e112e696581414581107c568d10a82e",
      "d48ac83f82684e8c96bad0a706f99085",
      "68ae8ab436484779a78934fa062d3127",
      "3c0f9dcc2cbe4252b1c39245f6bd4589",
      "9a2461e9940844288d2a7c96db0d7af0",
      "5dac98a7dba74453a4cd63dd32cf8b7a",
      "1dbc6094440b4c389cedf5840a8df303",
      "cd2343445c174513b92d4f092b31ffbc",
      "ceaa9911f2d24e40bd9a61148b285dca",
      "1e60153836664c0a8d94ff6d40d7b455",
      "ed20fb47113a442ba114336f0cc1385b",
      "2a71cb9ead9c4660912a83915e3a004d",
      "f58244183ec34ee9b89780f17c80d8fc",
      "f0800777b7f3433daeb9be423b3082d7",
      "0725eba54f914c09a11321b3c1ce7158",
      "72faafc1be3f4e06bb8d911ca745d6ca",
      "8b9cf2cc40624be2af3da921cfcda85c",
      "41a4dda526af438a867868d4d0e2ecc3",
      "66aa9b031f2d466cb028e7d1a988a334",
      "2a901157bac841cba142a53ef8db104d",
      "4c0212891d2b4bedbe1cc4bd46feccf9",
      "02bcdd2ebc104be8b3e6e6801431262d",
      "6375b0b5785a4044a32aa77db2f4cc9e",
      "1c64b0c6949d4ca2b579f31bbcb26891",
      "2174b3ed85704c68943ea85930b46fab",
      "3944f39576424f4297e610922dec1a41",
      "49dcba06428b4a34a0fe21bba33a9e85",
      "7644cba2fe7242009763044425ddf983",
      "c995c35a8ed748348680748bd4e0145f",
      "e4b57f53a56145768649c282dfed5b60",
      "ad5a77baa60d484ab940fde14b18ad69",
      "90422d84af634c89a381f42e38dde580",
      "8dcac8bb7c8a492ba81b06f450f6bef2",
      "3690e706ab0c4f0284885b617bd3f3cd",
      "3482898f69b943359aead475a01edd8f",
      "6987189acc5a4d64994dec627c5ca644",
      "6b1522afa5b248659e4588248b9a088e",
      "e6345fec97384532bf6d4e8b6baad545",
      "f171347a89b34a34be72f3c82aebdb72",
      "5f26412e6e7d496ba84af74d2e02c228",
      "c614d2c21ef44384a02e6200b1e30375",
      "641111002729406aa78fe8792cbe1353",
      "024abc2b0aa94b5ca82127aacd16803f",
      "8c32f2fe4d7e49529f523d3767263416",
      "420574e52fbd4c83bdf731420ffc40aa",
      "01061f1be3264906821b55a06b7ec61f",
      "2ba82704bbca4de191533066ecf8b198",
      "95c1f573a17d42688183d0e6d1a4a830",
      "56e0917a55744610a2cbfe4f8cc242b7",
      "e2121e30822e4d5c84fc90fd8618482c",
      "84f2d4e9d2bb4945b99932644e95fad5",
      "b63980dabc074e67b782f20b4c974ed9",
      "353caf9e97294963a5d9123c8fb6e626",
      "1541d6b691ca416a82b9d3f5df04ff44",
      "4da13c46da08482891005ceca080fcd1",
      "7b7a8070562342c49e1ef3541374a401",
      "8c4cfbf6f2334a7aab3947c2b4a83de6",
      "4645ccd1ddc04905aee0165c4123dbe5",
      "8843302f462649089b8a69eab12e0cf6",
      "d7d8a3ba39984840899556f069897798",
      "777289d5ac9c465b961de0aa6a9f400d",
      "ee47697c2ccf4155a65961e772d1ab36",
      "d5d77cceb0ef4ee8a022afe7d57aabec",
      "3b098d9b903046398aca4569a864750f",
      "2f54402871514ff59722de5cc23e6cda"
     ]
    },
    "id": "Ci5ellMgrU9D",
    "outputId": "4c418468-18c8-473d-ef87-4b127dfd5414"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ GPU detected: Tesla T4\n",
      "  CUDA Version: 12.6\n",
      "  GPU Memory: 15.83 GB\n",
      "\n",
      "Using model: bert-base-uncased\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
      "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
      "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
      "You will be able to reuse this secret in all of your notebooks.\n",
      "Please note that authentication is recommended but still optional to access public models or datasets.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d2a541df69dd421d80d822515bd66f00",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed80558000a3482480bbe8e3eb5aed8d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "90ab613b3b624d46bf45fcf2df6d59e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed20fb47113a442ba114336f0cc1385b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tokenizing datasets (this may take a moment)...\n",
      "  Using 4 processes for tokenization\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "02bcdd2ebc104be8b3e6e6801431262d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=4):   0%|          | 0/20824 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8dcac8bb7c8a492ba81b06f450f6bef2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=4):   0%|          | 0/4456 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c32f2fe4d7e49529f523d3767263416",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=4):   0%|          | 0/4476 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Datasets ready: train=20824, val=4456, test=4476\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4da13c46da08482891005ceca080fcd1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Model loaded on cuda:0\n"
     ]
    }
   ],
   "source": [
    "from datasets import Dataset\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "import platform\n",
    "\n",
    "USE_GPU = torch.cuda.is_available()\n",
    "if USE_GPU:\n",
    "    print(f\"✓ GPU detected: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"  CUDA Version: {torch.version.cuda}\")\n",
    "    print(f\"  GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")\n",
    "    device = torch.device(\"cuda:0\")\n",
    "    NUM_WORKERS = 0 if platform.system() == 'Windows' else 4\n",
    "    PIN_MEMORY = True\n",
    "else:\n",
    "    print(\"⚠ No GPU detected, using CPU (training will be slow)\")\n",
    "    device = torch.device(\"cpu\")\n",
    "    NUM_WORKERS = 0\n",
    "    PIN_MEMORY = False\n",
    "\n",
    "# Model choice: bert-base-uncased (per proposal Section V.C)\n",
    "MODEL_NAME = \"bert-base-uncased\"\n",
    "print(f\"\\nUsing model: {MODEL_NAME}\")\n",
    "\n",
    "MAX_LEN = 128  # Standard for tweets\n",
    "\n",
    "# Load BERT tokenizer (WordPiece tokenizer per proposal)\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME, use_fast=True)\n",
    "\n",
    "def tokenize_fn(batch):\n",
    "    \"\"\"Tokenize tweets using BERT's WordPiece tokenizer (per proposal Section V.B)\"\"\"\n",
    "    return tokenizer(batch[\"review\"], truncation=True, padding=\"max_length\", max_length=MAX_LEN)\n",
    "\n",
    "print(\"\\nTokenizing datasets (this may take a moment)...\")\n",
    "# Map labels from proposal format (-1,0,1) to BERT format (0,1,2)\n",
    "# -1 (negative/toxic) → 0, 0 (neutral) → 1, 1 (positive) → 2\n",
    "label_mapping = {-1: 0, 0: 1, 1: 2}\n",
    "df_train_bert = df_train.copy()\n",
    "df_val_bert = df_val.copy()\n",
    "df_test_bert = df_test.copy()\n",
    "df_train_bert['label'] = df_train_bert['label'].map(label_mapping)\n",
    "df_val_bert['label'] = df_val_bert['label'].map(label_mapping)\n",
    "df_test_bert['label'] = df_test_bert['label'].map(label_mapping)\n",
    "\n",
    "ds_train = Dataset.from_pandas(df_train_bert[['review','label']].reset_index(drop=True))\n",
    "ds_val   = Dataset.from_pandas(df_val_bert[['review','label']].reset_index(drop=True))\n",
    "ds_test  = Dataset.from_pandas(df_test_bert[['review','label']].reset_index(drop=True))\n",
    "\n",
    "if platform.system() == 'Windows':\n",
    "    NUM_PROC_TOKENIZE = None\n",
    "    print(\"  Using single-process tokenization (Windows compatibility)\")\n",
    "else:\n",
    "    NUM_PROC_TOKENIZE = 4 if USE_GPU else 2\n",
    "    print(f\"  Using {NUM_PROC_TOKENIZE} processes for tokenization\")\n",
    "\n",
    "ds_train = ds_train.map(tokenize_fn, batched=True, num_proc=NUM_PROC_TOKENIZE, remove_columns=['review'])\n",
    "ds_val   = ds_val.map(tokenize_fn, batched=True, num_proc=NUM_PROC_TOKENIZE, remove_columns=['review'])\n",
    "ds_test  = ds_test.map(tokenize_fn, batched=True, num_proc=NUM_PROC_TOKENIZE, remove_columns=['review'])\n",
    "\n",
    "cols = ['input_ids','attention_mask','label']\n",
    "ds_train = ds_train.with_format(\"torch\", columns=cols)\n",
    "ds_val   = ds_val.with_format(\"torch\", columns=cols)\n",
    "ds_test  = ds_test.with_format(\"torch\", columns=cols)\n",
    "\n",
    "print(f\"✓ Datasets ready: train={len(ds_train)}, val={len(ds_val)}, test={len(ds_test)}\")\n",
    "\n",
    "# Initialize BERT model with 3 labels (negative/neutral/positive)\n",
    "num_labels = 3\n",
    "model = AutoModelForSequenceClassification.from_pretrained(MODEL_NAME, num_labels=num_labels)\n",
    "model = model.to(device)\n",
    "print(f\"✓ Model loaded on {device}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OCQl7kvHrU9D"
   },
   "source": [
    "# **BERT Training Arguments and Configuration (per proposal Section V.D)**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7qVyL2JTrU9D"
   },
   "source": [
    "**`Purpose`**\n",
    "\n",
    "This block defines how BERT training will proceed per proposal Section V.D. It establishes a metric function that reports accuracy, precision, recall, and F1-score, builds training arguments with AdamW optimizer and cross-entropy loss, and constructs a Trainer object that ties the model, data, tokenizer, arguments, and metrics together.\n",
    "\n",
    "**`Input`**\n",
    "\n",
    "Inputs include the tokenized datasets, the initialized model and tokenizer, and hyperparameters such as number of epochs, batch sizes, learning rate, weight decay, and evaluation cadence.\n",
    "\n",
    "**`Output`**\n",
    "\n",
    "The cell prints a confirmation that the trainer is ready and includes the active model name. Internally, it prepares all objects required for training and evaluation.\n",
    "\n",
    "**`Details`**\n",
    "\n",
    "A compute function converts raw model outputs into predicted labels and compares them with gold labels to obtain accuracy, precision, recall, and macro-F1 (target: >0.85 per proposal Section III). Training arguments are configured with AdamW optimizer, cross-entropy loss, linear warmup with learning rate scheduling, early stopping to prevent overfitting, and mixed-precision when GPU is available.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "S_3uxB8-rU9D",
    "outputId": "81ed16c3-39a7-4b8b-d289-25653ebe7842"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Trainer ready on cuda:0\n",
      "  Batch size: 32 (train), 64 (eval)\n",
      "  FP16: True, Workers: 4, Pin Memory: True\n",
      "  Early stopping: patience=2\n",
      "  Optimizer: AdamW, Loss: Cross-entropy, Scheduler: Linear warmup\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipython-input-1103589661.py:83: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    }
   ],
   "source": [
    "from transformers import TrainingArguments, Trainer, EarlyStoppingCallback\n",
    "from sklearn.metrics import precision_score, recall_score\n",
    "import inspect\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    \"\"\"Compute metrics per proposal Section VI.A: accuracy, precision, recall, F1-score\"\"\"\n",
    "    preds = np.argmax(eval_pred.predictions, axis=1)\n",
    "    labels = eval_pred.label_ids\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    prec = precision_score(labels, preds, average='macro', zero_division=0)\n",
    "    rec = recall_score(labels, preds, average='macro', zero_division=0)\n",
    "    f1m = f1_score(labels, preds, average='macro', zero_division=0)\n",
    "    return {'accuracy': acc, 'precision': prec, 'recall': rec, 'f1_macro': f1m}\n",
    "\n",
    "if USE_GPU:\n",
    "    TRAIN_BATCH_SIZE = 32\n",
    "    EVAL_BATCH_SIZE = 64\n",
    "    USE_FP16 = True\n",
    "    GRADIENT_CHECKPOINTING = False\n",
    "else:\n",
    "    TRAIN_BATCH_SIZE = 8\n",
    "    EVAL_BATCH_SIZE = 16\n",
    "    USE_FP16 = False\n",
    "    GRADIENT_CHECKPOINTING = False\n",
    "\n",
    "sig = inspect.signature(TrainingArguments.__init__)\n",
    "argnames = set(sig.parameters.keys())\n",
    "\n",
    "def make_training_args(**overrides):\n",
    "    \"\"\"Create training arguments per proposal Section V.D\"\"\"\n",
    "    base_epochs = 3 if FAST_MODE else 4\n",
    "    total_steps = max(1, (len(ds_train) // max(1, TRAIN_BATCH_SIZE)) * base_epochs)\n",
    "    warmup_steps = max(25, int(total_steps * 0.1))\n",
    "\n",
    "    cfg = dict(\n",
    "        output_dir=f\"./checkpoints/bert-base/run1\",\n",
    "        num_train_epochs=base_epochs,\n",
    "        per_device_train_batch_size=TRAIN_BATCH_SIZE,\n",
    "        per_device_eval_batch_size=EVAL_BATCH_SIZE,\n",
    "        learning_rate=3e-5,  # Standard for BERT fine-tuning\n",
    "        weight_decay=0.01,\n",
    "        warmup_ratio=0.1,  # Linear warmup per proposal\n",
    "        lr_scheduler_type=\"linear\",  # Learning rate scheduling per proposal\n",
    "        gradient_accumulation_steps=1,\n",
    "        load_best_model_at_end=True,\n",
    "        metric_for_best_model=\"f1_macro\",  # Target: >0.85 per proposal\n",
    "        greater_is_better=True,\n",
    "        seed=RANDOM_SEED,\n",
    "        logging_steps=50,\n",
    "        eval_steps=100,\n",
    "        save_steps=200,\n",
    "        save_total_limit=2,\n",
    "        report_to=[],\n",
    "        optim=\"adamw_torch\",  # AdamW optimizer per proposal Section V.D\n",
    "        fp16=USE_FP16,\n",
    "        dataloader_num_workers=NUM_WORKERS,\n",
    "        dataloader_pin_memory=PIN_MEMORY,\n",
    "        remove_unused_columns=False,\n",
    "        gradient_checkpointing=GRADIENT_CHECKPOINTING,\n",
    "    )\n",
    "    cfg.update(overrides)\n",
    "\n",
    "    if \"evaluation_strategy\" in argnames:\n",
    "        cfg[\"evaluation_strategy\"] = cfg.get(\"evaluation_strategy\", \"steps\")\n",
    "    elif \"eval_strategy\" in argnames:\n",
    "        cfg[\"eval_strategy\"] = cfg.get(\"eval_strategy\", \"steps\")\n",
    "\n",
    "    if \"save_strategy\" in argnames:\n",
    "        cfg[\"save_strategy\"] = cfg.get(\"save_strategy\", \"steps\")\n",
    "\n",
    "    safe_cfg = {k:v for k,v in cfg.items() if k in argnames}\n",
    "    return TrainingArguments(**safe_cfg)\n",
    "\n",
    "training_args = make_training_args()\n",
    "\n",
    "if GRADIENT_CHECKPOINTING and hasattr(model, 'gradient_checkpointing_enable'):\n",
    "    model.gradient_checkpointing_enable()\n",
    "    print(\"✓ Gradient checkpointing enabled (saves memory)\")\n",
    "\n",
    "# Early stopping to prevent overfitting (per proposal)\n",
    "callbacks = [EarlyStoppingCallback(early_stopping_patience=2, early_stopping_threshold=0.001)]\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=ds_train,\n",
    "    eval_dataset=ds_val,\n",
    "    compute_metrics=compute_metrics,\n",
    "    tokenizer=tokenizer,\n",
    "    callbacks=callbacks,\n",
    ")\n",
    "\n",
    "print(f\"✓ Trainer ready on {device}\")\n",
    "print(f\"  Batch size: {TRAIN_BATCH_SIZE} (train), {EVAL_BATCH_SIZE} (eval)\")\n",
    "print(f\"  FP16: {USE_FP16}, Workers: {NUM_WORKERS}, Pin Memory: {PIN_MEMORY}\")\n",
    "print(f\"  Early stopping: patience=2\")\n",
    "print(f\"  Optimizer: AdamW, Loss: Cross-entropy, Scheduler: Linear warmup\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yYCS7tM-rU9D"
   },
   "source": [
    "# Automated Hyperparameter Tuning (per proposal Section V.C)\n",
    "\n",
    "**`Purpose`**\n",
    "\n",
    "Run Optuna-driven grid and random searches per proposal Section V.C for hyperparameter tuning and validation curve analysis to find optimum performance. The search explores learning rate, batch size, epochs, weight decay, and warmup ratio to identify the best configuration via validation macro-F1.\n",
    "\n",
    "**`Input`**\n",
    "\n",
    "Uses the tokenized datasets (`ds_train`, `ds_val`), global tokenizer/model selections, and shared helpers (`compute_metrics`, `make_training_args`). Configuration depends on `AUTO_TUNE_ENABLED`, search spaces, and trial limits.\n",
    "\n",
    "**`Output`**\n",
    "\n",
    "Writes per-strategy trial tables to `tuning/` directory, a combined summary, and logs the best configuration. The winning configuration is retrained, evaluated on validation and test splits, logged to `runs_log.csv`, and predictions exported.\n",
    "\n",
    "**`Details`**\n",
    "\n",
    "Defines a lightweight `WeightedTrainer` compatible with Optuna, registers helper functions to build Trainers for suggested hyperparameters. Optuna's `GridSampler` and `RandomSampler` explore the respective spaces, timing each trial and storing validation metrics.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ti3boiefrU9E",
    "outputId": "469bf6e9-0c7a-4e11-df17-eda7e11e7a2e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hyperparameter tuning configuration:\n"
     ]
    }
   ],
   "source": [
    "# Automated hyperparameter tuning configuration\n",
    "AUTO_TUNE_ENABLED = True\n",
    "\n",
    "GRID_SEARCH_SPACE = {\n",
    "    \"learning_rate\": [3e-5],  # Fixed to default (1 value)\n",
    "    \"per_device_train_batch_size\": [8, 16],  # 2 values\n",
    "    \"weight_decay\": [0.0, 0.01],  # 2 values\n",
    "    \"num_train_epochs\": [2, 3],  # 2 values\n",
    "}\n",
    "\n",
    "\n",
    "RANDOM_SEARCH_SPACE = {\n",
    "    \"learning_rate\": (\"log_uniform\", 2e-5, 5e-5),\n",
    "    \"per_device_train_batch_size\": (\"choice\", [8, 12, 16, 24, 32]),\n",
    "    \"weight_decay\": (\"uniform\", 0.0, 0.1),\n",
    "    \"num_train_epochs\": (\"int\", 2, 4),\n",
    "}\n",
    "\n",
    "RANDOM_TRIALS = 8\n",
    "MAX_AUTOTUNE_EPOCHS = 4\n",
    "\n",
    "print(\"Hyperparameter tuning configuration:\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`Purpose`**\n",
    "\n",
    "This cell configures the training arguments and sets up helper functions for BERT model fine-tuning. It defines hyperparameters, optimization settings, and evaluation metrics according to the proposal methodology.\n",
    "\n",
    "**`Input`**\n",
    "\n",
    "Uses global variables like MODEL_NAME, MAX_LEN, RANDOM_SEED, and device settings. Requires tokenizer and model to be initialized from previous cells.\n",
    "\n",
    "**`Output`**\n",
    "\n",
    "Creates training_args object and compute_metrics function. Prints configuration summary including optimizer settings, learning rate schedule, and training parameters.\n",
    "\n",
    "**`Details`**\n",
    "\n",
    "The cell sets up TrainingArguments with AdamW optimizer, linear learning rate warmup, cross-entropy loss, and early stopping callback. It configures evaluation strategy, logging, and checkpoint saving. The compute_metrics function calculates accuracy, precision, recall, and F1-macro scores for each evaluation step. All settings align with the proposal requirements for systematic model training and evaluation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "94fca5264bcf42feabb645991c452cc0",
      "a42525bed52e44968f8c45014a16c9ce",
      "76d6af9e9b1944688bc550637c32ecf4",
      "18a1e518241744839008bff493c8a2ba",
      "176b3270800242048de2262786725784",
      "8ec4783bf7094fd7b8e6ae84434a2a9b",
      "132a8c01960147fabf3e8ed9008ddc24",
      "0877274d6940467185bdcde8e66e4445",
      "309fad11a1d9404e8af271b43684f290",
      "d42ca8c15acc425e93227911e17de5e2",
      "67b8f531fdbc446b8e779cb099483011",
      "d1a15337dde6446e907625dd3ffd7be7",
      "9fc97a958c76476c851e9c2ef9049958",
      "d093dcde45ae4c48b9d209ba74638cb9",
      "c625e49517fa416d8345ab6d6d4cb70f",
      "8a9699b56b6c447c8d115bc970999110",
      "2dffa283c55c420e9591a13729563b81",
      "01edd4ed2ee6453794b184ef8588874e",
      "9789c1bd2d3e4c6eb7f187213ff16a1b",
      "32f7de03cadc4aca83b6f2b4f48338a6",
      "a3b0195ba0c94cbeadbd4ce118d8c794",
      "497f58f9ecef43fbbb35f49e460d49be"
     ]
    },
    "id": "-Xr7l0NtrU9E",
    "outputId": "39dbdeff-f8e5-466b-9644-ad699d466547"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-14 02:00:02,593] A new study created in memory with name: no-name-0c00466c-c606-4801-adcd-6fdd55e6e0cc\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Hyperparameter search: GRID ===\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "94fca5264bcf42feabb645991c452cc0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/tmp/ipython-input-1389719146.py:13: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `WeightedTrainer.__init__`. Use `processing_class` instead.\n",
      "  super().__init__(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='5206' max='5206' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [5206/5206 08:02, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.767200</td>\n",
       "      <td>0.765782</td>\n",
       "      <td>0.688061</td>\n",
       "      <td>0.711502</td>\n",
       "      <td>0.676981</td>\n",
       "      <td>0.686318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.650600</td>\n",
       "      <td>0.785695</td>\n",
       "      <td>0.684022</td>\n",
       "      <td>0.693116</td>\n",
       "      <td>0.680676</td>\n",
       "      <td>0.685470</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='70' max='70' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [70/70 00:06]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-14 02:08:14,545] Trial 0 finished with value: 0.686318040786818 and parameters: {}. Best is trial 0 with value: 0.686318040786818.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/tmp/ipython-input-1389719146.py:13: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `WeightedTrainer.__init__`. Use `processing_class` instead.\n",
      "  super().__init__(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2604' max='2604' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2604/2604 05:30, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.792200</td>\n",
       "      <td>0.757295</td>\n",
       "      <td>0.690081</td>\n",
       "      <td>0.714489</td>\n",
       "      <td>0.678347</td>\n",
       "      <td>0.687326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.688700</td>\n",
       "      <td>0.760651</td>\n",
       "      <td>0.690305</td>\n",
       "      <td>0.697378</td>\n",
       "      <td>0.687718</td>\n",
       "      <td>0.691598</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='70' max='70' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [70/70 00:06]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-14 02:13:54,123] Trial 1 finished with value: 0.6915982710100357 and parameters: {}. Best is trial 1 with value: 0.6915982710100357.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/tmp/ipython-input-1389719146.py:13: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `WeightedTrainer.__init__`. Use `processing_class` instead.\n",
      "  super().__init__(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='5206' max='5206' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [5206/5206 08:21, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.770500</td>\n",
       "      <td>0.757406</td>\n",
       "      <td>0.688510</td>\n",
       "      <td>0.713059</td>\n",
       "      <td>0.677379</td>\n",
       "      <td>0.686390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.641500</td>\n",
       "      <td>0.773878</td>\n",
       "      <td>0.686939</td>\n",
       "      <td>0.695041</td>\n",
       "      <td>0.684057</td>\n",
       "      <td>0.688386</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='70' max='70' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [70/70 00:06]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-14 02:22:24,701] Trial 2 finished with value: 0.6883864658141992 and parameters: {}. Best is trial 1 with value: 0.6915982710100357.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/tmp/ipython-input-1389719146.py:13: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `WeightedTrainer.__init__`. Use `processing_class` instead.\n",
      "  super().__init__(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2604' max='2604' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2604/2604 05:42, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.791100</td>\n",
       "      <td>0.755417</td>\n",
       "      <td>0.691876</td>\n",
       "      <td>0.720507</td>\n",
       "      <td>0.679262</td>\n",
       "      <td>0.689153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.684000</td>\n",
       "      <td>0.765129</td>\n",
       "      <td>0.684022</td>\n",
       "      <td>0.691886</td>\n",
       "      <td>0.681685</td>\n",
       "      <td>0.685765</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='70' max='70' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [70/70 00:06]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-14 02:28:15,641] Trial 3 finished with value: 0.689152955641206 and parameters: {}. Best is trial 1 with value: 0.6915982710100357.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/tmp/ipython-input-1389719146.py:13: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `WeightedTrainer.__init__`. Use `processing_class` instead.\n",
      "  super().__init__(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='7809' max='7809' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [7809/7809 12:00, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.777400</td>\n",
       "      <td>0.779778</td>\n",
       "      <td>0.677962</td>\n",
       "      <td>0.710988</td>\n",
       "      <td>0.662848</td>\n",
       "      <td>0.672782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.692100</td>\n",
       "      <td>0.773547</td>\n",
       "      <td>0.683124</td>\n",
       "      <td>0.691260</td>\n",
       "      <td>0.681064</td>\n",
       "      <td>0.685171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.476500</td>\n",
       "      <td>0.879501</td>\n",
       "      <td>0.679982</td>\n",
       "      <td>0.686968</td>\n",
       "      <td>0.677829</td>\n",
       "      <td>0.681485</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='70' max='70' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [70/70 00:06]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-14 02:40:25,323] Trial 4 finished with value: 0.6851706730005169 and parameters: {}. Best is trial 1 with value: 0.6915982710100357.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/tmp/ipython-input-1389719146.py:13: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `WeightedTrainer.__init__`. Use `processing_class` instead.\n",
      "  super().__init__(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3906' max='3906' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3906/3906 08:18, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.801000</td>\n",
       "      <td>0.764471</td>\n",
       "      <td>0.688285</td>\n",
       "      <td>0.717557</td>\n",
       "      <td>0.675213</td>\n",
       "      <td>0.684520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.696700</td>\n",
       "      <td>0.765712</td>\n",
       "      <td>0.688285</td>\n",
       "      <td>0.691973</td>\n",
       "      <td>0.688181</td>\n",
       "      <td>0.689811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.508600</td>\n",
       "      <td>0.842903</td>\n",
       "      <td>0.680206</td>\n",
       "      <td>0.685223</td>\n",
       "      <td>0.679583</td>\n",
       "      <td>0.681995</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='70' max='70' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [70/70 00:06]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-14 02:48:52,863] Trial 5 finished with value: 0.6898113084926939 and parameters: {}. Best is trial 1 with value: 0.6915982710100357.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/tmp/ipython-input-1389719146.py:13: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `WeightedTrainer.__init__`. Use `processing_class` instead.\n",
      "  super().__init__(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='7809' max='7809' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [7809/7809 12:33, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.767400</td>\n",
       "      <td>0.763650</td>\n",
       "      <td>0.684695</td>\n",
       "      <td>0.702080</td>\n",
       "      <td>0.675880</td>\n",
       "      <td>0.683534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.702900</td>\n",
       "      <td>0.768822</td>\n",
       "      <td>0.686490</td>\n",
       "      <td>0.696638</td>\n",
       "      <td>0.682142</td>\n",
       "      <td>0.687464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.490300</td>\n",
       "      <td>0.900347</td>\n",
       "      <td>0.678411</td>\n",
       "      <td>0.683737</td>\n",
       "      <td>0.677011</td>\n",
       "      <td>0.679861</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='70' max='70' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [70/70 00:06]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-14 03:01:35,392] Trial 6 finished with value: 0.6874641641377398 and parameters: {}. Best is trial 1 with value: 0.6915982710100357.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/tmp/ipython-input-1389719146.py:13: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `WeightedTrainer.__init__`. Use `processing_class` instead.\n",
      "  super().__init__(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3906' max='3906' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3906/3906 08:32, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.803100</td>\n",
       "      <td>0.759196</td>\n",
       "      <td>0.690305</td>\n",
       "      <td>0.716507</td>\n",
       "      <td>0.678341</td>\n",
       "      <td>0.688032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.687800</td>\n",
       "      <td>0.767889</td>\n",
       "      <td>0.689632</td>\n",
       "      <td>0.693950</td>\n",
       "      <td>0.688740</td>\n",
       "      <td>0.690839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.489000</td>\n",
       "      <td>0.848269</td>\n",
       "      <td>0.677289</td>\n",
       "      <td>0.682557</td>\n",
       "      <td>0.676265</td>\n",
       "      <td>0.678885</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='70' max='70' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [70/70 00:06]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-14 03:10:16,414] Trial 7 finished with value: 0.6908388799360564 and parameters: {}. Best is trial 1 with value: 0.6915982710100357.\n",
      "Saved grid trials to tuning/grid_trials.csv\n",
      "\n",
      "Best grid trial: F1-macro = 0.6916\n",
      "Best params: {}\n",
      "\n",
      "Retraining with best grid configuration...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/tmp/ipython-input-1389719146.py:13: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `WeightedTrainer.__init__`. Use `processing_class` instead.\n",
      "  super().__init__(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3906' max='3906' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3906/3906 08:30, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.803100</td>\n",
       "      <td>0.759196</td>\n",
       "      <td>0.690305</td>\n",
       "      <td>0.716507</td>\n",
       "      <td>0.678341</td>\n",
       "      <td>0.688032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.687800</td>\n",
       "      <td>0.767889</td>\n",
       "      <td>0.689632</td>\n",
       "      <td>0.693950</td>\n",
       "      <td>0.688740</td>\n",
       "      <td>0.690839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.489000</td>\n",
       "      <td>0.848269</td>\n",
       "      <td>0.677289</td>\n",
       "      <td>0.682557</td>\n",
       "      <td>0.676265</td>\n",
       "      <td>0.678885</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='140' max='70' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [70/70 00:13]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-14 03:19:03,121] A new study created in memory with name: no-name-0e197e03-9586-4164-aa3e-7e7164d8fec0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Hyperparameter search: RANDOM ===\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d1a15337dde6446e907625dd3ffd7be7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/tmp/ipython-input-1389719146.py:13: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `WeightedTrainer.__init__`. Use `processing_class` instead.\n",
      "  super().__init__(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='10412' max='10412' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [10412/10412 16:35, Epoch 4/4]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.764800</td>\n",
       "      <td>0.773396</td>\n",
       "      <td>0.680655</td>\n",
       "      <td>0.698380</td>\n",
       "      <td>0.670936</td>\n",
       "      <td>0.677155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.707800</td>\n",
       "      <td>0.767613</td>\n",
       "      <td>0.691876</td>\n",
       "      <td>0.698626</td>\n",
       "      <td>0.689903</td>\n",
       "      <td>0.693421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.491300</td>\n",
       "      <td>0.912909</td>\n",
       "      <td>0.671005</td>\n",
       "      <td>0.675108</td>\n",
       "      <td>0.671296</td>\n",
       "      <td>0.673027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.395100</td>\n",
       "      <td>1.265033</td>\n",
       "      <td>0.661131</td>\n",
       "      <td>0.664985</td>\n",
       "      <td>0.661545</td>\n",
       "      <td>0.663111</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='70' max='70' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [70/70 00:06]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-14 03:35:47,441] Trial 0 finished with value: 0.6934212564921293 and parameters: {'learning_rate': 2.8188664052384835e-05, 'per_device_train_batch_size': 8, 'weight_decay': 0.005808361216819946, 'num_train_epochs': 4}. Best is trial 0 with value: 0.6934212564921293.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/tmp/ipython-input-1389719146.py:13: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `WeightedTrainer.__init__`. Use `processing_class` instead.\n",
      "  super().__init__(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2604' max='2604' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2604/2604 05:39, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.776300</td>\n",
       "      <td>0.759027</td>\n",
       "      <td>0.690305</td>\n",
       "      <td>0.713224</td>\n",
       "      <td>0.679785</td>\n",
       "      <td>0.689096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.691700</td>\n",
       "      <td>0.764395</td>\n",
       "      <td>0.692549</td>\n",
       "      <td>0.701980</td>\n",
       "      <td>0.689366</td>\n",
       "      <td>0.694224</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='70' max='70' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [70/70 00:06]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-14 03:41:35,802] Trial 1 finished with value: 0.6942237582250611 and parameters: {'learning_rate': 3.469266868719914e-05, 'per_device_train_batch_size': 16, 'weight_decay': 0.018182496720710064, 'num_train_epochs': 2}. Best is trial 1 with value: 0.6942237582250611.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/tmp/ipython-input-1389719146.py:13: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `WeightedTrainer.__init__`. Use `processing_class` instead.\n",
      "  super().__init__(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2604' max='2604' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2604/2604 07:06, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.807000</td>\n",
       "      <td>0.751196</td>\n",
       "      <td>0.691427</td>\n",
       "      <td>0.711291</td>\n",
       "      <td>0.681258</td>\n",
       "      <td>0.689522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.755146</td>\n",
       "      <td>0.688285</td>\n",
       "      <td>0.693525</td>\n",
       "      <td>0.686847</td>\n",
       "      <td>0.689626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.554600</td>\n",
       "      <td>0.812691</td>\n",
       "      <td>0.684022</td>\n",
       "      <td>0.689397</td>\n",
       "      <td>0.682801</td>\n",
       "      <td>0.685528</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='70' max='70' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [70/70 00:06]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-14 03:48:50,986] Trial 2 finished with value: 0.6896256738801562 and parameters: {'learning_rate': 2.6430182166924245e-05, 'per_device_train_batch_size': 24, 'weight_decay': 0.029214464853521818, 'num_train_epochs': 3}. Best is trial 1 with value: 0.6942237582250611.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/tmp/ipython-input-1389719146.py:13: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `WeightedTrainer.__init__`. Use `processing_class` instead.\n",
      "  super().__init__(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='5206' max='5206' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [5206/5206 08:15, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.766600</td>\n",
       "      <td>0.760756</td>\n",
       "      <td>0.687388</td>\n",
       "      <td>0.706898</td>\n",
       "      <td>0.677721</td>\n",
       "      <td>0.684791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.669400</td>\n",
       "      <td>0.776649</td>\n",
       "      <td>0.690978</td>\n",
       "      <td>0.699606</td>\n",
       "      <td>0.687463</td>\n",
       "      <td>0.692133</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='70' max='70' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [70/70 00:06]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-14 03:57:14,946] Trial 3 finished with value: 0.692133038590431 and parameters: {'learning_rate': 3.037515404772984e-05, 'per_device_train_batch_size': 8, 'weight_decay': 0.06075448519014384, 'num_train_epochs': 2}. Best is trial 1 with value: 0.6942237582250611.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/tmp/ipython-input-1389719146.py:13: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `WeightedTrainer.__init__`. Use `processing_class` instead.\n",
      "  super().__init__(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='5208' max='5208' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [5208/5208 09:26, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.824500</td>\n",
       "      <td>0.750815</td>\n",
       "      <td>0.691876</td>\n",
       "      <td>0.718329</td>\n",
       "      <td>0.679977</td>\n",
       "      <td>0.689344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.711000</td>\n",
       "      <td>0.772949</td>\n",
       "      <td>0.684695</td>\n",
       "      <td>0.688492</td>\n",
       "      <td>0.684994</td>\n",
       "      <td>0.686569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.523200</td>\n",
       "      <td>0.829339</td>\n",
       "      <td>0.681329</td>\n",
       "      <td>0.687041</td>\n",
       "      <td>0.680042</td>\n",
       "      <td>0.683012</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='70' max='70' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [70/70 00:06]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-14 04:06:49,743] Trial 4 finished with value: 0.689343887800082 and parameters: {'learning_rate': 2.1228368952944975e-05, 'per_device_train_batch_size': 12, 'weight_decay': 0.0684233026512157, 'num_train_epochs': 3}. Best is trial 1 with value: 0.6942237582250611.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/tmp/ipython-input-1389719146.py:13: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `WeightedTrainer.__init__`. Use `processing_class` instead.\n",
      "  super().__init__(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3906' max='3906' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3906/3906 08:31, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.792000</td>\n",
       "      <td>0.753606</td>\n",
       "      <td>0.692325</td>\n",
       "      <td>0.723231</td>\n",
       "      <td>0.679316</td>\n",
       "      <td>0.689797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.705200</td>\n",
       "      <td>0.763157</td>\n",
       "      <td>0.686715</td>\n",
       "      <td>0.690550</td>\n",
       "      <td>0.686057</td>\n",
       "      <td>0.687997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.528700</td>\n",
       "      <td>0.816514</td>\n",
       "      <td>0.676391</td>\n",
       "      <td>0.682376</td>\n",
       "      <td>0.674289</td>\n",
       "      <td>0.677565</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='70' max='70' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [70/70 00:06]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-14 04:15:29,660] Trial 5 finished with value: 0.6897974939572982 and parameters: {'learning_rate': 2.2366286923412623e-05, 'per_device_train_batch_size': 16, 'weight_decay': 0.031171107608941095, 'num_train_epochs': 3}. Best is trial 1 with value: 0.6942237582250611.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/tmp/ipython-input-1389719146.py:13: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `WeightedTrainer.__init__`. Use `processing_class` instead.\n",
      "  super().__init__(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6944' max='6944' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6944/6944 12:31, Epoch 4/4]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.849700</td>\n",
       "      <td>0.761959</td>\n",
       "      <td>0.687163</td>\n",
       "      <td>0.719809</td>\n",
       "      <td>0.672758</td>\n",
       "      <td>0.682561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.710700</td>\n",
       "      <td>0.755114</td>\n",
       "      <td>0.685592</td>\n",
       "      <td>0.692780</td>\n",
       "      <td>0.682432</td>\n",
       "      <td>0.686265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.498600</td>\n",
       "      <td>0.872393</td>\n",
       "      <td>0.677289</td>\n",
       "      <td>0.681913</td>\n",
       "      <td>0.676130</td>\n",
       "      <td>0.678635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.357100</td>\n",
       "      <td>1.066213</td>\n",
       "      <td>0.666068</td>\n",
       "      <td>0.671531</td>\n",
       "      <td>0.664999</td>\n",
       "      <td>0.667796</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='70' max='70' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [70/70 00:06]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-14 04:28:09,573] Trial 6 finished with value: 0.686264883533798 and parameters: {'learning_rate': 3.300561952272884e-05, 'per_device_train_batch_size': 12, 'weight_decay': 0.05978999788110852, 'num_train_epochs': 4}. Best is trial 1 with value: 0.6942237582250611.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/tmp/ipython-input-1389719146.py:13: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `WeightedTrainer.__init__`. Use `processing_class` instead.\n",
      "  super().__init__(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2604' max='2604' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2604/2604 07:03, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.795400</td>\n",
       "      <td>0.758698</td>\n",
       "      <td>0.690530</td>\n",
       "      <td>0.716944</td>\n",
       "      <td>0.677268</td>\n",
       "      <td>0.686352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.640300</td>\n",
       "      <td>0.752620</td>\n",
       "      <td>0.690754</td>\n",
       "      <td>0.697886</td>\n",
       "      <td>0.688076</td>\n",
       "      <td>0.691977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.569100</td>\n",
       "      <td>0.798181</td>\n",
       "      <td>0.690530</td>\n",
       "      <td>0.698597</td>\n",
       "      <td>0.687222</td>\n",
       "      <td>0.691540</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='70' max='70' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [70/70 00:06]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-11-14 04:35:21,398] Trial 7 finished with value: 0.6919773122878455 and parameters: {'learning_rate': 2.1689258392227166e-05, 'per_device_train_batch_size': 24, 'weight_decay': 0.08287375091519295, 'num_train_epochs': 3}. Best is trial 1 with value: 0.6942237582250611.\n",
      "Saved random trials to tuning/random_trials.csv\n",
      "\n",
      "Best random trial: F1-macro = 0.6942\n",
      "Best params: {'learning_rate': 3.469266868719914e-05, 'per_device_train_batch_size': 16, 'weight_decay': 0.018182496720710064, 'num_train_epochs': 2}\n",
      "\n",
      "Retraining with best random configuration...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/tmp/ipython-input-1389719146.py:13: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `WeightedTrainer.__init__`. Use `processing_class` instead.\n",
      "  super().__init__(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2604' max='2604' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2604/2604 05:39, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.798900</td>\n",
       "      <td>0.757794</td>\n",
       "      <td>0.691203</td>\n",
       "      <td>0.716875</td>\n",
       "      <td>0.679419</td>\n",
       "      <td>0.689009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.692900</td>\n",
       "      <td>0.760415</td>\n",
       "      <td>0.688510</td>\n",
       "      <td>0.697486</td>\n",
       "      <td>0.685272</td>\n",
       "      <td>0.689998</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='140' max='70' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [70/70 00:13]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✓ Saved strategy summary to tuning/strategy_summary.csv\n",
      "  strategy  f1_macro_val  f1_macro_test  accuracy_val  accuracy_test  \\\n",
      "0     grid      0.690839       0.674435      0.689632       0.673369   \n",
      "1   random      0.689998       0.677551      0.688510       0.676497   \n",
      "\n",
      "                                         best_params  \n",
      "0                                                 {}  \n",
      "1  {'learning_rate': 3.469266868719914e-05, 'per_...  \n"
     ]
    }
   ],
   "source": [
    "import gc\n",
    "import time\n",
    "from optuna.samplers import GridSampler, RandomSampler\n",
    "from pathlib import Path\n",
    "\n",
    "TUNING_DIR = Path(\"tuning\")\n",
    "TUNING_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "if AUTO_TUNE_ENABLED:\n",
    "    # Custom Trainer for Optuna compatibility\n",
    "    class WeightedTrainer(Trainer):\n",
    "        def __init__(self, *args, class_weights=None, **kwargs):\n",
    "            super().__init__(*args, **kwargs)\n",
    "            self.class_weights = class_weights\n",
    "\n",
    "    def build_trainer_for_trial(hparams, run_name):\n",
    "        \"\"\"Build trainer with suggested hyperparameters\"\"\"\n",
    "        trial_args = make_training_args(\n",
    "            output_dir=f\"./checkpoints/bert-base/{run_name}\",\n",
    "            learning_rate=hparams.get(\"learning_rate\", 3e-5),\n",
    "            per_device_train_batch_size=hparams.get(\"per_device_train_batch_size\", 16),\n",
    "            weight_decay=hparams.get(\"weight_decay\", 0.01),\n",
    "            num_train_epochs=min(hparams.get(\"num_train_epochs\", 3), MAX_AUTOTUNE_EPOCHS),\n",
    "            eval_strategy=\"epoch\",  # Enable evaluation for early stopping callback\n",
    "            save_strategy=\"epoch\",  # Must match eval_strategy for load_best_model_at_end\n",
    "        )\n",
    "\n",
    "        # Create fresh model for each trial\n",
    "        trial_model = AutoModelForSequenceClassification.from_pretrained(MODEL_NAME, num_labels=3).to(device)\n",
    "\n",
    "        trial_trainer = WeightedTrainer(\n",
    "            model=trial_model,\n",
    "            args=trial_args,\n",
    "            train_dataset=ds_train,\n",
    "            eval_dataset=ds_val,\n",
    "            compute_metrics=compute_metrics,\n",
    "            tokenizer=tokenizer,\n",
    "            callbacks=[EarlyStoppingCallback(early_stopping_patience=2, early_stopping_threshold=0.001)],\n",
    "        )\n",
    "        return trial_trainer, trial_args\n",
    "\n",
    "    def suggest_params(trial, strategy):\n",
    "        \"\"\"Suggest hyperparameters based on strategy\"\"\"\n",
    "        if strategy == \"grid\":\n",
    "            # Grid search: enumerate all combinations\n",
    "            lr_vals = GRID_SEARCH_SPACE[\"learning_rate\"]\n",
    "            bs_vals = GRID_SEARCH_SPACE[\"per_device_train_batch_size\"]\n",
    "            wd_vals = GRID_SEARCH_SPACE[\"weight_decay\"]\n",
    "            ep_vals = GRID_SEARCH_SPACE[\"num_train_epochs\"]\n",
    "\n",
    "            # Use trial number to index into grid\n",
    "            trial_idx = trial.number\n",
    "            total_combos = len(lr_vals) * len(bs_vals) * len(wd_vals) * len(ep_vals)\n",
    "            if trial_idx >= total_combos:\n",
    "                raise optuna.TrialPruned()\n",
    "\n",
    "            idx = trial_idx\n",
    "            lr_idx = idx % len(lr_vals)\n",
    "            idx //= len(lr_vals)\n",
    "            bs_idx = idx % len(bs_vals)\n",
    "            idx //= len(bs_vals)\n",
    "            wd_idx = idx % len(wd_vals)\n",
    "            idx //= len(wd_vals)\n",
    "            ep_idx = idx % len(ep_vals)\n",
    "\n",
    "            return {\n",
    "                \"learning_rate\": lr_vals[lr_idx],\n",
    "                \"per_device_train_batch_size\": bs_vals[bs_idx],\n",
    "                \"weight_decay\": wd_vals[wd_idx],\n",
    "                \"num_train_epochs\": ep_vals[ep_idx],\n",
    "            }\n",
    "        else:  # random\n",
    "            return {\n",
    "                \"learning_rate\": trial.suggest_float(\"learning_rate\", 2e-5, 5e-5, log=True),\n",
    "                \"per_device_train_batch_size\": trial.suggest_categorical(\"per_device_train_batch_size\", [8, 12, 16, 24, 32]),\n",
    "                \"weight_decay\": trial.suggest_float(\"weight_decay\", 0.0, 0.1),\n",
    "                \"num_train_epochs\": trial.suggest_int(\"num_train_epochs\", 2, 4),\n",
    "            }\n",
    "\n",
    "    def objective(trial):\n",
    "        \"\"\"Optuna objective function\"\"\"\n",
    "        strategy = trial.study.sampler.__class__.__name__\n",
    "        hparams = suggest_params(trial, \"grid\" if \"Grid\" in strategy else \"random\")\n",
    "\n",
    "        run_name = f\"trial_{trial.number}\"\n",
    "        trainer_obj, args_obj = build_trainer_for_trial(hparams, run_name)\n",
    "\n",
    "        start_time = time.time()\n",
    "        trainer_obj.train()\n",
    "        train_time = time.time() - start_time\n",
    "\n",
    "        eval_results = trainer_obj.evaluate()\n",
    "        f1_macro = eval_results.get(\"eval_f1_macro\", 0.0)\n",
    "\n",
    "        # Note: Labels are in BERT format (0,1,2) during training, metrics are computed correctly\n",
    "\n",
    "        # Cleanup\n",
    "        del trainer_obj\n",
    "        gc.collect()\n",
    "        if torch.cuda.is_available():\n",
    "            torch.cuda.empty_cache()\n",
    "\n",
    "        trial.set_user_attr(\"train_time\", train_time)\n",
    "        trial.set_user_attr(\"accuracy\", eval_results.get(\"eval_accuracy\", 0.0))\n",
    "        trial.set_user_attr(\"precision\", eval_results.get(\"eval_precision\", 0.0))\n",
    "        trial.set_user_attr(\"recall\", eval_results.get(\"eval_recall\", 0.0))\n",
    "\n",
    "        return f1_macro\n",
    "\n",
    "    # Run hyperparameter search\n",
    "    SEARCH_STRATEGIES = [\"grid\", \"random\"] if AUTO_TUNE_ENABLED else []\n",
    "    summary_rows = []\n",
    "\n",
    "    for strategy in SEARCH_STRATEGIES:\n",
    "        print(f\"\\n=== Hyperparameter search: {strategy.upper()} ===\")\n",
    "\n",
    "        if strategy == \"grid\":\n",
    "            sampler = GridSampler(GRID_SEARCH_SPACE)\n",
    "            study = optuna.create_study(direction=\"maximize\", sampler=sampler)\n",
    "            # Grid search: run all combinations\n",
    "            total_trials = (len(GRID_SEARCH_SPACE[\"learning_rate\"]) *\n",
    "                          len(GRID_SEARCH_SPACE[\"per_device_train_batch_size\"]) *\n",
    "                          len(GRID_SEARCH_SPACE[\"weight_decay\"]) *\n",
    "                          len(GRID_SEARCH_SPACE[\"num_train_epochs\"]))\n",
    "            study.optimize(objective, n_trials=total_trials, show_progress_bar=True)\n",
    "        else:\n",
    "            sampler = RandomSampler(seed=RANDOM_SEED)\n",
    "            study = optuna.create_study(direction=\"maximize\", sampler=sampler)\n",
    "            study.optimize(objective, n_trials=RANDOM_TRIALS, show_progress_bar=True)\n",
    "\n",
    "        # Save trial results\n",
    "        trials_df = pd.DataFrame([\n",
    "            {\n",
    "                \"trial\": t.number,\n",
    "                \"f1_macro\": t.value,\n",
    "                \"learning_rate\": t.params.get(\"learning_rate\"),\n",
    "                \"batch_size\": t.params.get(\"per_device_train_batch_size\"),\n",
    "                \"weight_decay\": t.params.get(\"weight_decay\"),\n",
    "                \"epochs\": t.params.get(\"num_train_epochs\"),\n",
    "                \"accuracy\": t.user_attrs.get(\"accuracy\", 0),\n",
    "                \"precision\": t.user_attrs.get(\"precision\", 0),\n",
    "                \"recall\": t.user_attrs.get(\"recall\", 0),\n",
    "                \"train_time\": t.user_attrs.get(\"train_time\", 0),\n",
    "            }\n",
    "            for t in study.trials if t.value is not None\n",
    "        ])\n",
    "\n",
    "        trials_df.to_csv(TUNING_DIR / f\"{strategy}_trials.csv\", index=False)\n",
    "        print(f\"Saved {strategy} trials to {TUNING_DIR / f'{strategy}_trials.csv'}\")\n",
    "\n",
    "        # Best trial\n",
    "        if study.best_trial:\n",
    "            best_hparams = study.best_trial.params\n",
    "            print(f\"\\nBest {strategy} trial: F1-macro = {study.best_trial.value:.4f}\")\n",
    "            print(f\"Best params: {best_hparams}\")\n",
    "\n",
    "            # Retrain with best params and evaluate on test\n",
    "            print(f\"\\nRetraining with best {strategy} configuration...\")\n",
    "            best_trainer, _ = build_trainer_for_trial(best_hparams, f\"best_{strategy}\")\n",
    "            best_trainer.train()\n",
    "\n",
    "            val_results = best_trainer.evaluate()\n",
    "            test_results = best_trainer.evaluate(eval_dataset=ds_test)\n",
    "\n",
    "            # Save best model\n",
    "            best_ckpt_dir = f\"./checkpoints/bert-base/best_{strategy}\"\n",
    "            best_trainer.save_model(best_ckpt_dir)\n",
    "            tokenizer.save_pretrained(best_ckpt_dir)\n",
    "\n",
    "            summary_rows.append({\n",
    "                \"strategy\": strategy,\n",
    "                \"f1_macro_val\": val_results.get(\"eval_f1_macro\", 0),\n",
    "                \"f1_macro_test\": test_results.get(\"eval_f1_macro\", 0),\n",
    "                \"accuracy_val\": val_results.get(\"eval_accuracy\", 0),\n",
    "                \"accuracy_test\": test_results.get(\"eval_accuracy\", 0),\n",
    "                \"best_params\": str(best_hparams),\n",
    "            })\n",
    "\n",
    "            # Log to runs_log.csv\n",
    "            row = {\n",
    "                \"member\": f\"bert-{strategy}\",\n",
    "                \"model\": MODEL_NAME,\n",
    "                \"num_train_epochs\": best_hparams.get(\"num_train_epochs\"),\n",
    "                \"per_device_train_batch_size\": best_hparams.get(\"per_device_train_batch_size\"),\n",
    "                \"learning_rate\": best_hparams.get(\"learning_rate\"),\n",
    "                \"weight_decay\": best_hparams.get(\"weight_decay\"),\n",
    "                \"warmup_steps\": None,\n",
    "                \"lr_scheduler_type\": \"linear\",\n",
    "                \"gradient_accumulation_steps\": 1,\n",
    "                \"max_seq_length\": MAX_LEN,\n",
    "                \"seed\": RANDOM_SEED,\n",
    "                \"fp16\": USE_FP16,\n",
    "                \"accuracy\": test_results.get(\"eval_accuracy\", 0),\n",
    "                \"precision\": test_results.get(\"eval_precision\", 0),\n",
    "                \"recall\": test_results.get(\"eval_recall\", 0),\n",
    "                \"f1_macro\": test_results.get(\"eval_f1_macro\", 0),\n",
    "                \"notes\": f\"Best {strategy} search. Params: {best_hparams}\",\n",
    "            }\n",
    "            pd.DataFrame([row]).to_csv(\"runs_log.csv\", mode=\"a\", index=False,\n",
    "                                     header=not os.path.exists(\"runs_log.csv\"))\n",
    "\n",
    "    # Save summary\n",
    "    if summary_rows:\n",
    "        summary_df = pd.DataFrame(summary_rows)\n",
    "        summary_df.to_csv(TUNING_DIR / \"strategy_summary.csv\", index=False)\n",
    "        print(f\"\\n✓ Saved strategy summary to {TUNING_DIR / 'strategy_summary.csv'}\")\n",
    "        print(summary_df)\n",
    "\n",
    "    AUTO_TUNE_ENABLED = False  # Disable for subsequent cells\n",
    "else:\n",
    "    print(\"AUTO_TUNE_ENABLED is False. Skipping hyperparameter tuning.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VKPbFDqtrU9E"
   },
   "source": [
    "# **BERT Fine-tuning and Training**\n",
    "\n",
    "**`Purpose`**\n",
    "\n",
    "This cell performs the actual BERT model fine-tuning using either default hyperparameters or the best configuration from automated tuning. It trains the model with early stopping and saves the best checkpoint.\n",
    "\n",
    "**`Input`**\n",
    "\n",
    "Requires tokenized datasets (ds_train, ds_val), training arguments, model, tokenizer, and compute_metrics function. If hyperparameter tuning was performed, uses best parameters from the study.\n",
    "\n",
    "**`Output`**\n",
    "\n",
    "Trains the BERT model and saves the best checkpoint to disk. Prints training progress including loss and metrics for each epoch. Creates a trainer object and runs the training loop.\n",
    "\n",
    "**`Details`**\n",
    "\n",
    "The cell creates a Trainer object with the model, datasets, training arguments, and callbacks including early stopping. Training proceeds for the specified number of epochs with validation evaluation after each epoch. The best model checkpoint (based on validation F1-macro) is automatically saved. Training progress is logged and displayed, showing loss curves and metric improvements over time.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`Purpose`**\n",
    "\n",
    "This cell configures the hyperparameter search spaces for automated tuning using Optuna. It defines the parameter ranges for grid search and random search strategies.\n",
    "\n",
    "**`Input`**\n",
    "\n",
    "No direct inputs required. Uses global configuration variables.\n",
    "\n",
    "**`Output`**\n",
    "\n",
    "Prints the hyperparameter tuning configuration including search spaces, number of trials, and maximum epochs.\n",
    "\n",
    "**`Details`**\n",
    "\n",
    "Defines GRID_SEARCH_SPACE with fixed learning rate and varying batch sizes, weight decay, and epochs. Sets up RANDOM_SEARCH_SPACE with continuous ranges for learning rate and weight decay, and categorical choices for batch size and epochs. Configures the number of random trials and maximum training epochs to balance exploration with computational efficiency.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 452
    },
    "id": "cTk2l2XlrU9E",
    "outputId": "197ab6de-9169-4225-ad77-bde9721bd419"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training BERT model with default/configured parameters...\n",
      "Fine-tuning process per proposal Section V.D:\n",
      "  - Tokenization using BERT's WordPiece tokenizer\n",
      "  - Convert tweets to input IDs and attention masks\n",
      "  - Fine-tune with classification head for sentiment labeling\n",
      "  - Optimizer: AdamW, Loss: Cross-entropy, Scheduler: Linear warmup\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='300' max='2604' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 300/2604 01:15 < 09:44, 3.94 it/s, Epoch 0/4]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.685700</td>\n",
       "      <td>0.760716</td>\n",
       "      <td>0.686041</td>\n",
       "      <td>0.691137</td>\n",
       "      <td>0.687115</td>\n",
       "      <td>0.688662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.648500</td>\n",
       "      <td>0.786035</td>\n",
       "      <td>0.679084</td>\n",
       "      <td>0.686960</td>\n",
       "      <td>0.676102</td>\n",
       "      <td>0.679751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.604800</td>\n",
       "      <td>0.788078</td>\n",
       "      <td>0.684470</td>\n",
       "      <td>0.690830</td>\n",
       "      <td>0.680619</td>\n",
       "      <td>0.683608</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='140' max='70' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [70/70 32:30]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='70' max='70' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [70/70 00:06]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation Results:\n",
      "  Accuracy: 0.6845\n",
      "  Precision: 0.6908\n",
      "  Recall: 0.6806\n",
      "  F1-macro: 0.6836\n",
      "\n",
      "✓ Best model saved to ./checkpoints/bert-base/best\n"
     ]
    }
   ],
   "source": [
    "# Train BERT model (if not already trained via hyperparameter tuning)\n",
    "if not AUTO_TUNE_ENABLED or not os.path.exists(\"./checkpoints/bert-base/best_grid\"):\n",
    "    print(\"Training BERT model with default/configured parameters...\")\n",
    "    print(\"Fine-tuning process per proposal Section V.D:\")\n",
    "    print(\"  - Tokenization using BERT's WordPiece tokenizer\")\n",
    "    print(\"  - Convert tweets to input IDs and attention masks\")\n",
    "    print(\"  - Fine-tune with classification head for sentiment labeling\")\n",
    "    print(\"  - Optimizer: AdamW, Loss: Cross-entropy, Scheduler: Linear warmup\")\n",
    "\n",
    "    trainer.train()\n",
    "\n",
    "    # Evaluate on validation set\n",
    "    val_results = trainer.evaluate()\n",
    "    print(\"\\nValidation Results:\")\n",
    "    print(f\"  Accuracy: {val_results.get('eval_accuracy', 0):.4f}\")\n",
    "    print(f\"  Precision: {val_results.get('eval_precision', 0):.4f}\")\n",
    "    print(f\"  Recall: {val_results.get('eval_recall', 0):.4f}\")\n",
    "    print(f\"  F1-macro: {val_results.get('eval_f1_macro', 0):.4f}\")\n",
    "\n",
    "    # Save best checkpoint\n",
    "    best_ckpt_dir = \"./checkpoints/bert-base/best\"\n",
    "    trainer.save_model(best_ckpt_dir)\n",
    "    tokenizer.save_pretrained(best_ckpt_dir)\n",
    "    print(f\"\\n✓ Best model saved to {best_ckpt_dir}\")\n",
    "else:\n",
    "    print(\"Using best model from hyperparameter tuning.\")\n",
    "    best_ckpt_dir = \"./checkpoints/bert-base/best_grid\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0hK-GrAerU9E"
   },
   "source": [
    "# **Model Evaluation and Baseline Comparison (per proposal Section VI)**\n",
    "\n",
    "**`Purpose`**\n",
    "\n",
    "This cell performs comprehensive evaluation of the trained BERT model on the test set. It generates detailed performance metrics, classification reports, and comparison with baseline models.\n",
    "\n",
    "**`Input`**\n",
    "\n",
    "Requires best_model and best_ckpt_dir from training cells. Needs ds_test dataset and baseline model results for comparison.\n",
    "\n",
    "**`Output`**\n",
    "\n",
    "Prints detailed performance metrics, generates confusion matrices, ROC-AUC and PR-AUC curves, and creates comparison tables. Exports results to CSV files for further analysis.\n",
    "\n",
    "**`Details`**\n",
    "\n",
    "The evaluation process tests the best BERT model on the held-out test set. It computes accuracy, precision, recall, and F1-macro scores for each class and overall. Generates confusion matrices to visualize classification performance. Creates ROC-AUC and PR-AUC curves for each sentiment class to analyze precision-recall trade-offs. Compares BERT results with baseline TF-IDF and Logistic Regression model to quantify improvements. All results are exported to files for documentation and reporting.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`Purpose`**\n",
    "\n",
    "This cell configures the training arguments and sets up helper functions for BERT model fine-tuning. It defines hyperparameters, optimization settings, and evaluation metrics according to the proposal methodology.\n",
    "\n",
    "**`Input`**\n",
    "\n",
    "Uses global variables like MODEL_NAME, MAX_LEN, RANDOM_SEED, and device settings. Requires tokenizer and model to be initialized from previous cells.\n",
    "\n",
    "**`Output`**\n",
    "\n",
    "Creates training_args object and compute_metrics function. Prints configuration summary including optimizer settings, learning rate schedule, and training parameters.\n",
    "\n",
    "**`Details`**\n",
    "\n",
    "The cell sets up TrainingArguments with AdamW optimizer, linear learning rate warmup, cross-entropy loss, and early stopping callback. It configures evaluation strategy, logging, and checkpoint saving. The compute_metrics function calculates accuracy, precision, recall, and F1-macro scores for each evaluation step. All settings align with the proposal requirements for systematic model training and evaluation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 833
    },
    "id": "FgSH8xPfrU9E",
    "outputId": "8f865e00-d79e-4283-f378-595ebfb3980e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating BERT model on test set...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipython-input-1700016497.py:8: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  eval_trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "BERT Model Performance (Test Set) - per proposal Section VI.A:\n",
      "  Accuracy: 0.6772\n",
      "  Precision: 0.6877\n",
      "  Recall: 0.6721\n",
      "  F1-macro: 0.6765\n",
      "\n",
      "Test Set Classification Report:\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "negative/toxic       0.72      0.58      0.64      1292\n",
      "       neutral       0.63      0.70      0.66      1781\n",
      "      positive       0.71      0.74      0.73      1403\n",
      "\n",
      "      accuracy                           0.68      4476\n",
      "     macro avg       0.69      0.67      0.68      4476\n",
      "  weighted avg       0.68      0.68      0.68      4476\n",
      "\n",
      "\n",
      "✓ Confusion matrix saved to exports/confusion_matrices/bert_cm_test.png\n",
      "✓ Test predictions saved to exports/bert_predictions_test.csv\n",
      "\n",
      "negative/toxic (class -1):\n",
      "  ROC-AUC: 0.8400\n",
      "  PR-AUC: 0.7330\n",
      "\n",
      "neutral (class 0):\n",
      "  ROC-AUC: 0.7823\n",
      "  PR-AUC: 0.6573\n",
      "\n",
      "positive (class 1):\n",
      "  ROC-AUC: 0.8769\n",
      "  PR-AUC: 0.8018\n",
      "\n",
      "✓ ROC and PR curves saved to exports/roc_curves/bert_roc_pr_curves.png\n",
      "\n",
      "============================================================\n",
      "Baseline vs BERT Comparison (per proposal Section VI.B)\n",
      "============================================================\n",
      "                     Model  Accuracy  Precision   Recall  F1-macro\n",
      "Baseline (TF-IDF + LogReg)  0.656836   0.669741 0.650169  0.656292\n",
      "         BERT-base-uncased  0.677167   0.687735 0.672147  0.676473\n",
      "\n",
      "✓ Model comparison saved to exports/model_comparison.csv\n"
     ]
    }
   ],
   "source": [
    "# Load best BERT model for evaluation\n",
    "from transformers import AutoModelForSequenceClassification\n",
    "\n",
    "best_model = AutoModelForSequenceClassification.from_pretrained(best_ckpt_dir).to(device)\n",
    "best_model.eval()\n",
    "\n",
    "# Create trainer with best model for evaluation\n",
    "eval_trainer = Trainer(\n",
    "    model=best_model,\n",
    "    args=training_args,\n",
    "    eval_dataset=ds_test,\n",
    "    compute_metrics=compute_metrics,\n",
    "    tokenizer=tokenizer,\n",
    ")\n",
    "\n",
    "# Evaluate on test set (15%)\n",
    "print(\"Evaluating BERT model on test set...\")\n",
    "test_results = eval_trainer.evaluate()\n",
    "\n",
    "print(\"\\nBERT Model Performance (Test Set) - per proposal Section VI.A:\")\n",
    "print(f\"  Accuracy: {test_results.get('eval_accuracy', 0):.4f}\")\n",
    "print(f\"  Precision: {test_results.get('eval_precision', 0):.4f}\")\n",
    "print(f\"  Recall: {test_results.get('eval_recall', 0):.4f}\")\n",
    "print(f\"  F1-macro: {test_results.get('eval_f1_macro', 0):.4f}\")\n",
    "\n",
    "# Generate predictions for detailed analysis\n",
    "test_predictions = eval_trainer.predict(ds_test)\n",
    "test_preds_bert = np.argmax(test_predictions.predictions, axis=1)\n",
    "test_labels_bert = test_predictions.label_ids\n",
    "\n",
    "# Map predictions back from BERT format (0,1,2) to proposal format (-1,0,1)\n",
    "reverse_mapping = {0: -1, 1: 0, 2: 1}\n",
    "test_preds = np.array([reverse_mapping[p] for p in test_preds_bert])\n",
    "test_labels = np.array([reverse_mapping[l] for l in test_labels_bert])\n",
    "\n",
    "# Classification report\n",
    "print(\"\\nTest Set Classification Report:\")\n",
    "print(classification_report(test_labels, test_preds,\n",
    "                          target_names=['negative/toxic', 'neutral', 'positive'],\n",
    "                          zero_division=0))\n",
    "\n",
    "# Confusion matrix\n",
    "cm_bert = confusion_matrix(test_labels, test_preds, labels=[-1, 0, 1])\n",
    "fig, ax = plt.subplots(figsize=(6, 5))\n",
    "ConfusionMatrixDisplay(cm_bert, display_labels=['negative/toxic', 'neutral', 'positive']).plot(ax=ax, colorbar=False)\n",
    "plt.title('BERT Model - Test Set Confusion Matrix')\n",
    "plt.tight_layout()\n",
    "plt.savefig('exports/confusion_matrices/bert_cm_test.png', dpi=150)\n",
    "plt.close()\n",
    "print(\"\\n✓ Confusion matrix saved to exports/confusion_matrices/bert_cm_test.png\")\n",
    "\n",
    "# Save test predictions\n",
    "test_df_results = pd.DataFrame({\n",
    "    'review': df_test['review'].tolist(),\n",
    "    'gold': test_labels,\n",
    "    'pred': test_preds\n",
    "})\n",
    "test_df_results.to_csv('exports/bert_predictions_test.csv', index=False)\n",
    "print(\"✓ Test predictions saved to exports/bert_predictions_test.csv\")\n",
    "\n",
    "# ROC-AUC and PR-AUC curves (per proposal Section III)\n",
    "from sklearn.metrics import roc_curve, auc, precision_recall_curve, roc_auc_score, average_precision_score\n",
    "from sklearn.preprocessing import label_binarize\n",
    "\n",
    "# Binarize labels for multi-class ROC\n",
    "y_test_bin = label_binarize(test_labels, classes=[-1, 0, 1])\n",
    "n_classes = 3\n",
    "test_probs = torch.softmax(torch.tensor(test_predictions.predictions), dim=-1).numpy()\n",
    "\n",
    "# Compute ROC and PR curves for each class\n",
    "# Note: test_probs columns are in BERT order (0=negative, 1=neutral, 2=positive)\n",
    "# which maps to proposal order: 0→-1, 1→0, 2→1\n",
    "fpr = dict()\n",
    "tpr = dict()\n",
    "roc_auc = dict()\n",
    "precision = dict()\n",
    "recall = dict()\n",
    "pr_auc = dict()\n",
    "\n",
    "# Map BERT probabilities to proposal label order\n",
    "bert_to_proposal = {0: 0, 1: 1, 2: 2}  # BERT index 0→proposal -1, index 1→proposal 0, index 2→proposal 1\n",
    "for i, class_name in enumerate(['negative/toxic', 'neutral', 'positive']):\n",
    "    class_idx = [-1, 0, 1][i]  # Proposal format\n",
    "    bert_idx = {-1: 0, 0: 1, 1: 2}[class_idx]  # BERT format index\n",
    "    y_true_class = (test_labels == class_idx).astype(int)\n",
    "    y_score_class = test_probs[:, bert_idx]  # Use BERT index for probabilities\n",
    "\n",
    "    fpr[i], tpr[i], _ = roc_curve(y_true_class, y_score_class)\n",
    "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "    precision[i], recall[i], _ = precision_recall_curve(y_true_class, y_score_class)\n",
    "    pr_auc[i] = average_precision_score(y_true_class, y_score_class)\n",
    "\n",
    "    print(f\"\\n{class_name} (class {class_idx}):\")\n",
    "    print(f\"  ROC-AUC: {roc_auc[i]:.4f}\")\n",
    "    print(f\"  PR-AUC: {pr_auc[i]:.4f}\")\n",
    "\n",
    "# Plot ROC curves\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# ROC curves\n",
    "ax = axes[0]\n",
    "for i, class_name in enumerate(['negative/toxic', 'neutral', 'positive']):\n",
    "    ax.plot(fpr[i], tpr[i], label=f'{class_name} (AUC = {roc_auc[i]:.3f})')\n",
    "ax.plot([0, 1], [0, 1], 'k--', label='Random')\n",
    "ax.set_xlabel('False Positive Rate')\n",
    "ax.set_ylabel('True Positive Rate')\n",
    "ax.set_title('ROC Curves (per proposal Section III)')\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "# PR curves\n",
    "ax = axes[1]\n",
    "for i, class_name in enumerate(['negative/toxic', 'neutral', 'positive']):\n",
    "    ax.plot(recall[i], precision[i], label=f'{class_name} (AP = {pr_auc[i]:.3f})')\n",
    "ax.set_xlabel('Recall')\n",
    "ax.set_ylabel('Precision')\n",
    "ax.set_title('Precision-Recall Curves (per proposal Section III)')\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "os.makedirs(\"exports/roc_curves\", exist_ok=True)\n",
    "plt.savefig('exports/roc_curves/bert_roc_pr_curves.png', dpi=150)\n",
    "plt.close()\n",
    "print(\"\\n✓ ROC and PR curves saved to exports/roc_curves/bert_roc_pr_curves.png\")\n",
    "\n",
    "# Baseline vs BERT comparison (per proposal Section VI.B)\n",
    "comparison_df = pd.DataFrame({\n",
    "    'Model': ['Baseline (TF-IDF + LogReg)', 'BERT-base-uncased'],\n",
    "    'Accuracy': [test_acc, test_results.get('eval_accuracy', 0)],\n",
    "    'Precision': [test_prec, test_results.get('eval_precision', 0)],\n",
    "    'Recall': [test_rec, test_results.get('eval_recall', 0)],\n",
    "    'F1-macro': [test_f1, test_results.get('eval_f1_macro', 0)],\n",
    "})\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Baseline vs BERT Comparison (per proposal Section VI.B)\")\n",
    "print(\"=\"*60)\n",
    "print(comparison_df.to_string(index=False))\n",
    "comparison_df.to_csv('exports/model_comparison.csv', index=False)\n",
    "print(\"\\n✓ Model comparison saved to exports/model_comparison.csv\")\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "01061f1be3264906821b55a06b7ec61f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_84f2d4e9d2bb4945b99932644e95fad5",
      "max": 4476,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_b63980dabc074e67b782f20b4c974ed9",
      "value": 4476
     }
    },
    "01edd4ed2ee6453794b184ef8588874e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "01ef638e5c834442a7df6eb482e6eabe": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_48c873ccd5404aedae9a2be61fc75251",
      "placeholder": "​",
      "style": "IPY_MODEL_d41eec1669cf43279fd6d5d0d1076e9e",
      "value": " 570/570 [00:00&lt;00:00, 61.8kB/s]"
     }
    },
    "024abc2b0aa94b5ca82127aacd16803f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "02bcdd2ebc104be8b3e6e6801431262d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_6375b0b5785a4044a32aa77db2f4cc9e",
       "IPY_MODEL_1c64b0c6949d4ca2b579f31bbcb26891",
       "IPY_MODEL_2174b3ed85704c68943ea85930b46fab"
      ],
      "layout": "IPY_MODEL_3944f39576424f4297e610922dec1a41"
     }
    },
    "05ee02e4e9c34660aa2253f431afebe5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "0725eba54f914c09a11321b3c1ce7158": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0877274d6940467185bdcde8e66e4445": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0add817e35ad42bbab69c8df677074fd": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "132a8c01960147fabf3e8ed9008ddc24": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "1385652be2b94ea3acfd770c482a1c09": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_592fcf7c164f4fb582e7da9c120df830",
      "max": 570,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_5011e8d5bfa840e693ff755f679c4949",
      "value": 570
     }
    },
    "1541d6b691ca416a82b9d3f5df04ff44": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "176b3270800242048de2262786725784": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "18a1e518241744839008bff493c8a2ba": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d42ca8c15acc425e93227911e17de5e2",
      "placeholder": "​",
      "style": "IPY_MODEL_67b8f531fdbc446b8e779cb099483011",
      "value": " 8/8 [1:10:13&lt;00:00, 574.41s/it]"
     }
    },
    "1c64b0c6949d4ca2b579f31bbcb26891": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c995c35a8ed748348680748bd4e0145f",
      "max": 20824,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_e4b57f53a56145768649c282dfed5b60",
      "value": 20824
     }
    },
    "1dbc6094440b4c389cedf5840a8df303": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1e60153836664c0a8d94ff6d40d7b455": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "20a4d2f288a946d59b2abbd527b16725": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2174b3ed85704c68943ea85930b46fab": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ad5a77baa60d484ab940fde14b18ad69",
      "placeholder": "​",
      "style": "IPY_MODEL_90422d84af634c89a381f42e38dde580",
      "value": " 20824/20824 [00:01&lt;00:00, 20711.76 examples/s]"
     }
    },
    "2a71cb9ead9c4660912a83915e3a004d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_72faafc1be3f4e06bb8d911ca745d6ca",
      "placeholder": "​",
      "style": "IPY_MODEL_8b9cf2cc40624be2af3da921cfcda85c",
      "value": "tokenizer.json: 100%"
     }
    },
    "2a901157bac841cba142a53ef8db104d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2ba82704bbca4de191533066ecf8b198": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_353caf9e97294963a5d9123c8fb6e626",
      "placeholder": "​",
      "style": "IPY_MODEL_1541d6b691ca416a82b9d3f5df04ff44",
      "value": " 4476/4476 [00:00&lt;00:00, 3647.07 examples/s]"
     }
    },
    "2c9692150c094beea21579c402929a36": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2d99b9709dcf44fc8ad70b8151856761": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_6ef4e485fef54637bf4e2ab59d66afdc",
      "placeholder": "​",
      "style": "IPY_MODEL_0add817e35ad42bbab69c8df677074fd",
      "value": "tokenizer_config.json: 100%"
     }
    },
    "2dffa283c55c420e9591a13729563b81": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2f54402871514ff59722de5cc23e6cda": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "2fa7525f360f4a12ad56f719c960d391": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_20a4d2f288a946d59b2abbd527b16725",
      "placeholder": "​",
      "style": "IPY_MODEL_05ee02e4e9c34660aa2253f431afebe5",
      "value": " 48.0/48.0 [00:00&lt;00:00, 5.46kB/s]"
     }
    },
    "309fad11a1d9404e8af271b43684f290": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "32f7de03cadc4aca83b6f2b4f48338a6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "3482898f69b943359aead475a01edd8f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5f26412e6e7d496ba84af74d2e02c228",
      "max": 4456,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_c614d2c21ef44384a02e6200b1e30375",
      "value": 4456
     }
    },
    "353caf9e97294963a5d9123c8fb6e626": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3690e706ab0c4f0284885b617bd3f3cd": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e6345fec97384532bf6d4e8b6baad545",
      "placeholder": "​",
      "style": "IPY_MODEL_f171347a89b34a34be72f3c82aebdb72",
      "value": "Map (num_proc=4): 100%"
     }
    },
    "3944f39576424f4297e610922dec1a41": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3994702573114f769a0d9a198f92f171": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3b098d9b903046398aca4569a864750f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3c0f9dcc2cbe4252b1c39245f6bd4589": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "41a4dda526af438a867868d4d0e2ecc3": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "420574e52fbd4c83bdf731420ffc40aa": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_56e0917a55744610a2cbfe4f8cc242b7",
      "placeholder": "​",
      "style": "IPY_MODEL_e2121e30822e4d5c84fc90fd8618482c",
      "value": "Map (num_proc=4): 100%"
     }
    },
    "4645ccd1ddc04905aee0165c4123dbe5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_3b098d9b903046398aca4569a864750f",
      "placeholder": "​",
      "style": "IPY_MODEL_2f54402871514ff59722de5cc23e6cda",
      "value": " 440M/440M [00:01&lt;00:00, 285MB/s]"
     }
    },
    "48c873ccd5404aedae9a2be61fc75251": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "497f58f9ecef43fbbb35f49e460d49be": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "49dcba06428b4a34a0fe21bba33a9e85": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4c0212891d2b4bedbe1cc4bd46feccf9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "4da13c46da08482891005ceca080fcd1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_7b7a8070562342c49e1ef3541374a401",
       "IPY_MODEL_8c4cfbf6f2334a7aab3947c2b4a83de6",
       "IPY_MODEL_4645ccd1ddc04905aee0165c4123dbe5"
      ],
      "layout": "IPY_MODEL_8843302f462649089b8a69eab12e0cf6"
     }
    },
    "5011e8d5bfa840e693ff755f679c4949": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "56e0917a55744610a2cbfe4f8cc242b7": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "592fcf7c164f4fb582e7da9c120df830": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5dac98a7dba74453a4cd63dd32cf8b7a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "5f26412e6e7d496ba84af74d2e02c228": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6375b0b5785a4044a32aa77db2f4cc9e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_49dcba06428b4a34a0fe21bba33a9e85",
      "placeholder": "​",
      "style": "IPY_MODEL_7644cba2fe7242009763044425ddf983",
      "value": "Map (num_proc=4): 100%"
     }
    },
    "641111002729406aa78fe8792cbe1353": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "66aa9b031f2d466cb028e7d1a988a334": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "6790a5b05142492294d338374f5fe13a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "67b8f531fdbc446b8e779cb099483011": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "68ae8ab436484779a78934fa062d3127": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ceaa9911f2d24e40bd9a61148b285dca",
      "placeholder": "​",
      "style": "IPY_MODEL_1e60153836664c0a8d94ff6d40d7b455",
      "value": " 232k/232k [00:00&lt;00:00, 1.10MB/s]"
     }
    },
    "6987189acc5a4d64994dec627c5ca644": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_641111002729406aa78fe8792cbe1353",
      "placeholder": "​",
      "style": "IPY_MODEL_024abc2b0aa94b5ca82127aacd16803f",
      "value": " 4456/4456 [00:00&lt;00:00, 13597.23 examples/s]"
     }
    },
    "69e62eb154b143d796173107b250c0e7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_6e66a64d8c3d4fbc9c74355d833fd43d",
      "max": 48,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_6790a5b05142492294d338374f5fe13a",
      "value": 48
     }
    },
    "6b1522afa5b248659e4588248b9a088e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6e112e696581414581107c568d10a82e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_9a2461e9940844288d2a7c96db0d7af0",
      "placeholder": "​",
      "style": "IPY_MODEL_5dac98a7dba74453a4cd63dd32cf8b7a",
      "value": "vocab.txt: 100%"
     }
    },
    "6e66a64d8c3d4fbc9c74355d833fd43d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6ef4e485fef54637bf4e2ab59d66afdc": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "72faafc1be3f4e06bb8d911ca745d6ca": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7644cba2fe7242009763044425ddf983": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "76d6af9e9b1944688bc550637c32ecf4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0877274d6940467185bdcde8e66e4445",
      "max": 8,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_309fad11a1d9404e8af271b43684f290",
      "value": 8
     }
    },
    "777289d5ac9c465b961de0aa6a9f400d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "7b7a8070562342c49e1ef3541374a401": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d7d8a3ba39984840899556f069897798",
      "placeholder": "​",
      "style": "IPY_MODEL_777289d5ac9c465b961de0aa6a9f400d",
      "value": "model.safetensors: 100%"
     }
    },
    "84f2d4e9d2bb4945b99932644e95fad5": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8843302f462649089b8a69eab12e0cf6": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8a9699b56b6c447c8d115bc970999110": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8b9cf2cc40624be2af3da921cfcda85c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "8c32f2fe4d7e49529f523d3767263416": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_420574e52fbd4c83bdf731420ffc40aa",
       "IPY_MODEL_01061f1be3264906821b55a06b7ec61f",
       "IPY_MODEL_2ba82704bbca4de191533066ecf8b198"
      ],
      "layout": "IPY_MODEL_95c1f573a17d42688183d0e6d1a4a830"
     }
    },
    "8c4cfbf6f2334a7aab3947c2b4a83de6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ee47697c2ccf4155a65961e772d1ab36",
      "max": 440449768,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_d5d77cceb0ef4ee8a022afe7d57aabec",
      "value": 440449768
     }
    },
    "8dcac8bb7c8a492ba81b06f450f6bef2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_3690e706ab0c4f0284885b617bd3f3cd",
       "IPY_MODEL_3482898f69b943359aead475a01edd8f",
       "IPY_MODEL_6987189acc5a4d64994dec627c5ca644"
      ],
      "layout": "IPY_MODEL_6b1522afa5b248659e4588248b9a088e"
     }
    },
    "8ec4783bf7094fd7b8e6ae84434a2a9b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "90422d84af634c89a381f42e38dde580": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "90ab613b3b624d46bf45fcf2df6d59e2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_6e112e696581414581107c568d10a82e",
       "IPY_MODEL_d48ac83f82684e8c96bad0a706f99085",
       "IPY_MODEL_68ae8ab436484779a78934fa062d3127"
      ],
      "layout": "IPY_MODEL_3c0f9dcc2cbe4252b1c39245f6bd4589"
     }
    },
    "94fca5264bcf42feabb645991c452cc0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_a42525bed52e44968f8c45014a16c9ce",
       "IPY_MODEL_76d6af9e9b1944688bc550637c32ecf4",
       "IPY_MODEL_18a1e518241744839008bff493c8a2ba"
      ],
      "layout": "IPY_MODEL_176b3270800242048de2262786725784"
     }
    },
    "95c1f573a17d42688183d0e6d1a4a830": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9789c1bd2d3e4c6eb7f187213ff16a1b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9a2461e9940844288d2a7c96db0d7af0": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9fc97a958c76476c851e9c2ef9049958": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_2dffa283c55c420e9591a13729563b81",
      "placeholder": "​",
      "style": "IPY_MODEL_01edd4ed2ee6453794b184ef8588874e",
      "value": "Best trial: 1. Best value: 0.694224: 100%"
     }
    },
    "a3b0195ba0c94cbeadbd4ce118d8c794": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a42525bed52e44968f8c45014a16c9ce": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_8ec4783bf7094fd7b8e6ae84434a2a9b",
      "placeholder": "​",
      "style": "IPY_MODEL_132a8c01960147fabf3e8ed9008ddc24",
      "value": "Best trial: 1. Best value: 0.691598: 100%"
     }
    },
    "ad5a77baa60d484ab940fde14b18ad69": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b63980dabc074e67b782f20b4c974ed9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "bc3e22eee5134962b6cc39bd8b21d7eb": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_2c9692150c094beea21579c402929a36",
      "placeholder": "​",
      "style": "IPY_MODEL_c714306a078b48b09c735bea1faca6bb",
      "value": "config.json: 100%"
     }
    },
    "c614d2c21ef44384a02e6200b1e30375": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "c625e49517fa416d8345ab6d6d4cb70f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a3b0195ba0c94cbeadbd4ce118d8c794",
      "placeholder": "​",
      "style": "IPY_MODEL_497f58f9ecef43fbbb35f49e460d49be",
      "value": " 8/8 [1:16:18&lt;00:00, 551.87s/it]"
     }
    },
    "c714306a078b48b09c735bea1faca6bb": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "c746523a9b6747258829bbca9355b40d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c995c35a8ed748348680748bd4e0145f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "cd2343445c174513b92d4f092b31ffbc": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "ceaa9911f2d24e40bd9a61148b285dca": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d093dcde45ae4c48b9d209ba74638cb9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_9789c1bd2d3e4c6eb7f187213ff16a1b",
      "max": 8,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_32f7de03cadc4aca83b6f2b4f48338a6",
      "value": 8
     }
    },
    "d1a15337dde6446e907625dd3ffd7be7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_9fc97a958c76476c851e9c2ef9049958",
       "IPY_MODEL_d093dcde45ae4c48b9d209ba74638cb9",
       "IPY_MODEL_c625e49517fa416d8345ab6d6d4cb70f"
      ],
      "layout": "IPY_MODEL_8a9699b56b6c447c8d115bc970999110"
     }
    },
    "d2a541df69dd421d80d822515bd66f00": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_2d99b9709dcf44fc8ad70b8151856761",
       "IPY_MODEL_69e62eb154b143d796173107b250c0e7",
       "IPY_MODEL_2fa7525f360f4a12ad56f719c960d391"
      ],
      "layout": "IPY_MODEL_c746523a9b6747258829bbca9355b40d"
     }
    },
    "d41eec1669cf43279fd6d5d0d1076e9e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "d42ca8c15acc425e93227911e17de5e2": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d48ac83f82684e8c96bad0a706f99085": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_1dbc6094440b4c389cedf5840a8df303",
      "max": 231508,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_cd2343445c174513b92d4f092b31ffbc",
      "value": 231508
     }
    },
    "d5d77cceb0ef4ee8a022afe7d57aabec": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "d7d8a3ba39984840899556f069897798": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e2121e30822e4d5c84fc90fd8618482c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "e4b57f53a56145768649c282dfed5b60": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "e6345fec97384532bf6d4e8b6baad545": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ed20fb47113a442ba114336f0cc1385b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_2a71cb9ead9c4660912a83915e3a004d",
       "IPY_MODEL_f58244183ec34ee9b89780f17c80d8fc",
       "IPY_MODEL_f0800777b7f3433daeb9be423b3082d7"
      ],
      "layout": "IPY_MODEL_0725eba54f914c09a11321b3c1ce7158"
     }
    },
    "ed80558000a3482480bbe8e3eb5aed8d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_bc3e22eee5134962b6cc39bd8b21d7eb",
       "IPY_MODEL_1385652be2b94ea3acfd770c482a1c09",
       "IPY_MODEL_01ef638e5c834442a7df6eb482e6eabe"
      ],
      "layout": "IPY_MODEL_3994702573114f769a0d9a198f92f171"
     }
    },
    "ee47697c2ccf4155a65961e772d1ab36": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f0800777b7f3433daeb9be423b3082d7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_2a901157bac841cba142a53ef8db104d",
      "placeholder": "​",
      "style": "IPY_MODEL_4c0212891d2b4bedbe1cc4bd46feccf9",
      "value": " 466k/466k [00:00&lt;00:00, 40.3MB/s]"
     }
    },
    "f171347a89b34a34be72f3c82aebdb72": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "f58244183ec34ee9b89780f17c80d8fc": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_41a4dda526af438a867868d4d0e2ecc3",
      "max": 466062,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_66aa9b031f2d466cb028e7d1a988a334",
      "value": 466062
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
